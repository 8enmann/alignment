https://medium.com/@paulfchristiano/the-golden-rule-bbd085801f22
https://ai-alignment.com/handling-adversarial-errors-4ed438af8bdd
https://ai-alignment.com/thoughts-on-reward-engineering-82b193ec03f6
https://ai-alignment.com/adversarial-collaboration-629092c83c74
https://ai-alignment.com/alba-on-github-5636ef510907
https://ai-alignment.com/alba-an-explicit-proposal-for-aligned-ai-17a55f60bbcf
https://ai-alignment.com/semi-supervised-reinforcement-learning-cf7d5375197f
https://ai-alignment.com/alphago-zero-and-capability-amplification-ede767bb8446
https://ai-alignment.com/delegating-to-a-mixed-crowd-dda2b8e22cd8
https://ai-alignment.com/abstract-approval-direction-dc5a3864c092
https://ai-alignment.com/modeling-ai-control-with-humans-6d285c1a114d
https://ai-alignment.com/clarifying-ai-alignment-cec47cd69dd6
https://ai-alignment.com/scalable-ai-control-7db2436feee7
https://ai-alignment.com/stable-self-improvement-as-an-ai-safety-problem-46e2a44e73e
https://ai-alignment.com/sympathizing-with-ai-e11a4bf5ef6e
https://ai-alignment.com/training-robust-corrigibility-ce0e0a3b9b4d
https://ai-alignment.com/extracting-information-97cd956f2c17
https://ai-alignment.com/safe-automated-assistants-aa69edd46a57
https://ai-alignment.com/security-amplification-f4931419f903
https://medium.com/@paulfchristiano/of-arguments-and-wagers-ee16a0e84cf7
https://ai-alignment.com/implementing-our-considered-judgment-6c715a239b3e
https://ai-alignment.com/efficient-and-safely-scalable-8218fa8a871f
https://ai-alignment.com/the-easy-goal-inference-problem-is-still-hard-fad030e0a876
https://ai-alignment.com/ambitious-vs-narrow-value-learning-99bd0c59847e
https://medium.com/@paulfchristiano/followers
https://ai-alignment.com/adequate-oversight-25fadf1edce9
https://ai-alignment.com/some-thoughts-on-training-highly-reliable-models-2c78c17e266d
https://ai-alignment.com/the-informed-oversight-problem-1b51b4f66b35
https://ai-alignment.com/a-possible-stance-for-ai-control-research-fe9cf717fc1b
https://ai-alignment.com/the-steering-problem-a3543e65c5c4
https://ai-alignment.com/optimizing-with-comparisons-c02b8c0d7877
https://ai-alignment.com/problem-safe-ai-from-episodic-rl-3bddc1c98a99
https://ai-alignment.com/universality-and-security-amplification-551b314a3bab
https://ai-alignment.com/an-unaligned-benchmark-b49ad992940b
https://ai-alignment.com/strong-hch-bedb0dc08d4e
https://ai-alignment.com/consider-a-machine-that-does-exactly-what-its-user-would-tell-it-to-do-8e3fd1cf5de6
https://ai-alignment.com/concrete-approval-directed-agents-89e247df7f1b
https://ai-alignment.com/benign-model-free-rl-4aae8c97e385
https://ai-alignment.com/imitation-rl-613d70146409
https://ai-alignment.com/research-directions-in-ai-control-ef6f666d2062
https://medium.com/@paulfchristiano/the-last-captcha-c0e368acde56
https://ai-alignment.com/informed-oversight-18fcb5d3d1e1
https://ai-alignment.com/ai-safety-vs-control-vs-alignment-2a4b42a863cc
https://ai-alignment.com/aligned-search-366f983742e9
https://ai-alignment.com/a-formalization-of-indirect-normativity-7e44db640160
https://medium.com/@paulfchristiano/of-simulations-and-inductive-definitions-3a9841e45546
https://ai-alignment.com/optimization-and-goals-ca524f745852
https://medium.com/@paulfchristiano/responses
https://ai-alignment.com/counterfactual-oversight-vs-training-data-a7a1d247801
https://ai-alignment.com/policy-amplification-6a70cbee4f34
https://ai-alignment.com/corrigibility-3039e668638
https://medium.com/@paulfchristiano/normative-uncertainty-f15d0bc67351
https://ai-alignment.com/universality-and-model-based-rl-b08701394ddd
https://ai-alignment.com/approval-maximizing-representations-56ee6a6a1fe6
https://ai-alignment.com/the-reward-engineering-problem-30285c779450
https://medium.com/@paulfchristiano/perfect-delegation-35b30ca74f94
https://ai-alignment.com/irl-and-voi-a7e3d97d27c9
https://ai-alignment.com/ai-control-on-the-cheap-3425b148daf0
https://ai-alignment.com/universality-and-consequentialism-within-hch-c0bee00365bd
https://ai-alignment.com/learning-with-catastrophes-59387b55cc30
https://ai-alignment.com/turning-reflection-up-to-11-1bd6171afd21
https://medium.com/@paulfchristiano/flattening-arguments-between-rl-agents-96d36c68d0e3
https://ai-alignment.com/meta-execution-27ba9b34d377
https://medium.com/@paulfchristiano/approaches-to-reward-learning-4881a87ce054
https://ai-alignment.com/online-guarantees-and-ai-control-924a7d9dcd46
https://ai-alignment.com/hard-core-subproblems-8948463455ef
https://ai-alignment.com/semi-supervised-learning-from-side-information-483d5db474a2
https://ai-alignment.com/active-learning-for-opaque-powerful-predictors-94724b3adf06
https://ai-alignment.com/challenges-for-safe-ai-from-rl-924b4b2ae8b9
https://ai-alignment.com/human-arguments-and-ai-control-bc99c043a5ec
https://ai-alignment.com/elaborations-of-apprenticeship-learning-eb93a53ae3ca
https://ai-alignment.com/of-humans-and-universality-thresholds-24b473e0c898
https://medium.com/@paulfchristiano/warning-technical-uninteresting-unpolished-c8f0771915bd
https://medium.com/@paulfchristiano
https://ai-alignment.com/benign-ai-e4eb6ec6d68e
https://medium.com/@paulfchristiano/following
https://ai-alignment.com/technical-and-social-approaches-to-ai-safety-5e225ca30c46
https://ai-alignment.com/handling-errors-with-arguments-1f34a04ccbff
https://ai-alignment.com/adversarial-vs-active-learning-38940ecc7ca3
https://medium.com/@paulfchristiano/highlights
https://ai-alignment.com/prosaic-ai-control-b959644d79c2
https://ai-alignment.com/indirect-decision-theory-ce5407800790
https://ai-alignment.com/on-heterogeneous-objectives-b38d0e003399
https://ai-alignment.com/learning-and-logic-e96bd41b1ab5
https://medium.com/@paulfchristiano/three-impacts-of-machine-intelligence-6285c8d85376
https://ai-alignment.com/handling-destructive-technology-85800a12d99
https://ai-alignment.com/counterfactual-human-in-the-loop-a7822e36f399
https://ai-alignment.com/implicit-extortion-3c80c45af1e3
https://ai-alignment.com/directions-and-desiderata-for-ai-control-b60fca0da8f4
https://ai-alignment.com/act-based-agents-8ec926c79e9c
https://medium.com/@paulfchristiano/certificates-of-impact-34fa4621481e
https://ai-alignment.com/in-defense-of-maximization-edcabd8a0d6f
https://ai-alignment.com/reliability-amplification-a96efa115687
https://ai-alignment.com/techniques-for-optimizing-worst-case-performance-39eafec74b99
https://medium.com/@paulfchristiano/a-productivity-paradox-8373b87c2d30
https://ai-alignment.com/steps-towards-safe-ai-from-episodic-rl-ffb4b6a80363
https://ai-alignment.com/humans-consulting-hch-f893f6051455
https://ai-alignment.com/ignoring-computational-limits-with-reflective-oracles-e00ab71c7c8
https://medium.com/@paulfchristiano/has-recommended
https://ai-alignment.com/safe-ai-from-question-answering-fc5a168923f7
https://medium.com/@paulfchristiano/my-short-term-agenda-e096219c760b
https://medium.com/@paulfchristiano/recent-posts-871482d8ea8d
https://ai-alignment.com/against-mimicry-6002a472fc42
https://ai-alignment.com/advisor-games-b33382fef68c
https://ai-alignment.com/learning-representations-c330b7d12c76
https://ai-alignment.com/reinforcement-learning-and-linguistic-convention-1f75f7f4f158
https://ai-alignment.com/two-guarantees-c4c03a6b434f
https://ai-alignment.com/synthesizing-training-data-f92a637dc1b4
https://ai-alignment.com/how-common-is-imitation-3bd2d477c384
https://ai-alignment.com/apprenticeship-learning-and-mimicry-b59055722604
https://ai-alignment.com/approval-directed-algorithm-learning-bf1f8fad42cd
https://ai-alignment.com/reward-engineering-f8b5de40d075
https://ai-alignment.com/towards-formalizing-universality-409ab893a456
https://ai-alignment.com/supervised-learning-and-ai-control-154450c5c4bc
https://ai-alignment.com/not-just-learning-e3bfb5a1f96e
https://ai-alignment.com/efficient-feedback-a347748b1557
https://ai-alignment.com/mimicry-maximization-and-meeting-halfway-c149dd23fc17
https://ai-alignment.com/red-teams-b5b6de33dc76
https://ai-alignment.com/model-free-decisions-6e6609f5d99e
https://ai-alignment.com/security-and-ai-control-675ace05ce31
https://ai-alignment.com/imitation-and-justification-e0a363c2088a
https://ai-alignment.com/the-state-of-the-steering-problem-9d4a9e662db5
https://ai-alignment.com/learn-policies-or-goals-348add76b8eb