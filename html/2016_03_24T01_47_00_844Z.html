<!DOCTYPE html><html xmlns:cc="http://creativecommons.org/ns#"><head prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# medium-com: http://ogp.me/ns/fb/medium-com#"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=contain"><title>Efficient and safely scalable ‚Äì AI Alignment</title><link rel="canonical" href="https://ai-alignment.com/efficient-and-safely-scalable-8218fa8a871f"><meta name="title" content="Efficient and safely scalable ‚Äì AI Alignment"><meta name="referrer" content="always"><meta name="description" content="Precisely defining the goal of AI control research seems quite difficult. This post gives preliminary definitions of safe scalability and efficiency for AI control protocols, taking a step towards‚Ä¶"><meta name="theme-color" content="#000000"><meta property="og:title" content="Efficient and safely scalable ‚Äì AI Alignment"><meta property="twitter:title" content="Efficient and safely scalable"><meta property="og:url" content="https://ai-alignment.com/efficient-and-safely-scalable-8218fa8a871f"><meta property="fb:app_id" content="542599432471018"><meta property="og:description" content="A precise but overambitious goal for AI control research."><meta name="twitter:description" content="A precise but overambitious goal for AI control research."><link rel="author" href="https://ai-alignment.com/@paulfchristiano"><meta name="author" content="Paul Christiano"><meta property="og:type" content="article"><meta name="twitter:card" content="summary"><meta property="article:publisher" content="https://www.facebook.com/medium"><meta property="article:author" content="1167284919"><meta name="robots" content="index, follow"><meta property="article:published_time" content="2016-03-24T01:47:00.844Z"><meta name="twitter:site" content="@Medium"><meta property="og:site_name" content="AI Alignment"><meta name="twitter:label1" value="Reading time"><meta name="twitter:data1" value="15 min read"><meta name="twitter:app:name:iphone" content="Medium"><meta name="twitter:app:id:iphone" content="828256236"><meta name="twitter:app:url:iphone" content="medium://p/8218fa8a871f"><meta property="al:ios:app_name" content="Medium"><meta property="al:ios:app_store_id" content="828256236"><meta property="al:android:package" content="com.medium.reader"><meta property="al:android:app_name" content="Medium"><meta property="al:ios:url" content="medium://p/8218fa8a871f"><meta property="al:android:url" content="medium://p/8218fa8a871f"><meta property="al:web:url" content="https://ai-alignment.com/efficient-and-safely-scalable-8218fa8a871f"><link rel="search" type="application/opensearchdescription+xml" title="Medium" href="/osd.xml"><link rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/8218fa8a871f"><script async="" src="https://cdn.branch.io/branch-latest.min.js"></script><script type="application/ld+json">{"@context":"http://schema.org","@type":"NewsArticle","image":{"@type":"ImageObject","width":545,"height":106,"url":"https://cdn-images-1.medium.com/max/545/1*OMF3fSqH8t4xBJ9-6oZDZw.png"},"url":"https://ai-alignment.com/efficient-and-safely-scalable-8218fa8a871f","dateCreated":"2016-03-24T01:47:00.844Z","datePublished":"2016-03-24T01:47:00.844Z","dateModified":"2018-03-14T23:29:35.653Z","headline":"Efficient and safely scalable","name":"Efficient and safely scalable","articleId":"8218fa8a871f","thumbnailUrl":"https://cdn-images-1.medium.com/max/545/1*OMF3fSqH8t4xBJ9-6oZDZw.png","keywords":["Publication:ai-control","LockedPostSource:0","Elevated:false","LayerCake:0"],"author":{"@type":"Person","name":"Paul Christiano","url":"https://ai-alignment.com/@paulfchristiano"},"creator":["Paul Christiano"],"publisher":{"@type":"Organization","name":"AI Alignment","url":"https://ai-alignment.com","logo":{"@type":"ImageObject","width":308,"height":60,"url":"https://cdn-images-1.medium.com/max/308/1*OMF3fSqH8t4xBJ9-6oZDZw.png"}},"mainEntityOfPage":"https://ai-alignment.com/efficient-and-safely-scalable-8218fa8a871f"}</script><meta name="parsely-link" content="https://ai-alignment.com/efficient-and-safely-scalable-8218fa8a871f"><link rel="stylesheet" href="https://cdn-static-1.medium.com/_/fp/css/main-branding-base.sMRbh_65n82B91860QdvTg.css"><script>!function(n,e){var t,o,i,c=[],f={passive:!0,capture:!0},r=new Date,a="pointerup",u="pointercancel";function p(n,c){t||(t=c,o=n,i=new Date,w(e),s())}function s(){o>=0&&o<i-r&&(c.forEach(function(n){n(o,t)}),c=[])}function l(t){if(t.cancelable){var o=(t.timeStamp>1e12?new Date:performance.now())-t.timeStamp;"pointerdown"==t.type?function(t,o){function i(){p(t,o),r()}function c(){r()}function r(){e(a,i,f),e(u,c,f)}n(a,i,f),n(u,c,f)}(o,t):p(o,t)}}function w(n){["click","mousedown","keydown","touchstart","pointerdown"].forEach(function(e){n(e,l,f)})}w(n),self.perfMetrics=self.perfMetrics||{},self.perfMetrics.onFirstInputDelay=function(n){c.push(n),s()}}(addEventListener,removeEventListener);</script><script>if (window.top !== window.self) window.top.location = window.self.location.href;var OB_startTime = new Date().getTime(); var OB_loadErrors = []; function _onerror(e) { OB_loadErrors.push(e) }; if (document.addEventListener) document.addEventListener("error", _onerror, true); else if (document.attachEvent) document.attachEvent("onerror", _onerror); function _asyncScript(u) {var d = document, f = d.getElementsByTagName("script")[0], s = d.createElement("script"); s.type = "text/javascript"; s.async = true; s.src = u; f.parentNode.insertBefore(s, f);}function _asyncStyles(u) {var d = document, f = d.getElementsByTagName("script")[0], s = d.createElement("link"); s.rel = "stylesheet"; s.href = u; f.parentNode.insertBefore(s, f); return s}(new Image()).src = "/_/stat?event=pixel.load&origin=" + encodeURIComponent(location.origin);</script><script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date; ga("create", "UA-24232453-2", "auto", {"allowLinker": true, "legacyCookieDomain": window.location.hostname}); ga("send", "pageview");</script><script async="" src="https://www.google-analytics.com/analytics.js"></script><script>(function () {var height = window.innerHeight || document.documentElement.clientHeight || document.body.clientHeight; var width = window.innerWidth || document.documentElement.clientWidth || document.body.clientWidth; document.write("<style>section.section-image--fullBleed.is-backgrounded {padding-top: " + Math.round(1.1 * height) + "px;}section.section-image--fullScreen.is-backgrounded, section.section-image--coverFade.is-backgrounded {min-height: " + height + "px; padding-top: " + Math.round(0.5 * height) + "px;}.u-height100vh {height: " + height + "px !important;}.u-height110vh {height: " + Math.round(1.1 * height) + "px !important;}.u-minHeight100vh {min-height: " + height + "px !important;}.u-maxHeight100vh {max-height: " + height + "px !important;}section.section-image--coverFade {height: " + height + "px;}.section-aspectRatioViewportPlaceholder, .section-aspectRatioViewportCropPlaceholder {max-height: " + height + "px;}.section-aspectRatioViewportBottomSpacer, .section-aspectRatioViewportBottomPlaceholder {max-height: " + Math.round(0.5 * height) + "px;}.zoomable:before {top: " + (-1 * height) + "px; left: " + (-1 * width) + "px; padding: " + height + "px " + width + "px;}</style>");})()</script><style>section.section-image--fullBleed.is-backgrounded {padding-top: 660px;}section.section-image--fullScreen.is-backgrounded, section.section-image--coverFade.is-backgrounded {min-height: 600px; padding-top: 300px;}.u-height100vh {height: 600px !important;}.u-height110vh {height: 660px !important;}.u-minHeight100vh {min-height: 600px !important;}.u-maxHeight100vh {max-height: 600px !important;}section.section-image--coverFade {height: 600px;}.section-aspectRatioViewportPlaceholder, .section-aspectRatioViewportCropPlaceholder {max-height: 600px;}.section-aspectRatioViewportBottomSpacer, .section-aspectRatioViewportBottomPlaceholder {max-height: 300px;}.zoomable:before {top: -600px; left: -800px; padding: 600px 800px;}</style><!--[if lt IE 9]><script charset="UTF-8" src="https://cdn-static-1.medium.com/_/fp/js/shiv.RI2ePTZ5gFmMgLzG5bEVAA.js"></script><![endif]--><link rel="icon" href="https://cdn-images-1.medium.com/fit/c/128/128/1*cciPf4CUXd_Zyux0Jg0yBQ.png" class="js-favicon"><link rel="apple-touch-icon" sizes="152x152" href="https://cdn-images-1.medium.com/fit/c/152/152/1*N56Qc5-aHTcfGff0scntKQ.png"><link rel="apple-touch-icon" sizes="120x120" href="https://cdn-images-1.medium.com/fit/c/120/120/1*N56Qc5-aHTcfGff0scntKQ.png"><link rel="apple-touch-icon" sizes="76x76" href="https://cdn-images-1.medium.com/fit/c/76/76/1*N56Qc5-aHTcfGff0scntKQ.png"><link rel="apple-touch-icon" sizes="60x60" href="https://cdn-images-1.medium.com/fit/c/60/60/1*N56Qc5-aHTcfGff0scntKQ.png"><link rel="mask-icon" href="https://cdn-static-1.medium.com/_/fp/icons/monogram-mask.KPLCSFEZviQN0jQ7veN2RQ.svg" color="#171717"><meta property="og:image" content=""><style type="text/css">.metabar,.u-fixed,footer { display: none}</style></head><body itemscope="" class="postShowScreen browser-chrome os-mac v-glyph v-glyph--m2 is-js is-resizing" data-action-scope="_actionscope_0"><script>document.body.className = document.body.className.replace(/(^|\s)is-noJs(\s|$)/, "$1is-js$2")</script><div class="site-main surface-container" id="container"><div class="butterBar butterBar--error" data-action-scope="_actionscope_1"></div><div class="surface" id="_obv.shell._surface_1557467314286" style="display: block; visibility: visible;"><div class="screenContent surface-content is-supplementalPostContentLoaded" data-used="true" data-action-scope="_actionscope_2"><canvas class="canvas-renderer" width="800" height="600"></canvas><div class="container u-maxWidth740 u-xs-margin0 notesPositionContainer js-notesPositionContainer"><div class="notesMarkers" data-action-scope="_actionscope_4"></div></div><div class="metabar u-clearfix u-boxShadow4px12pxBlackLightest u-fixed u-backgroundTransparentWhiteDarkest u-xs-sizeFullViewportWidth js-metabar"><div class="branch-journeys-top"></div><div class="js-metabarMiddle metabar-inner u-marginAuto u-maxWidth1032 u-flexCenter u-justifyContentSpaceBetween u-height65 u-xs-height56 u-paddingHorizontal20"><div class="metabar-block u-flex1 u-flexCenter"><div class="u-xs-hide js-metabarLogoLeft"><a href="https://medium.com/" data-log-event="home" class="siteNav-logo u-fillTransparentBlackDarker u-flex0 u-flexCenter u-paddingTop0"><span class="svgIcon svgIcon--logoMonogram svgIcon--45px is-flushLeft u-flex0 u-flexCenter u-paddingTop0"><svg class="svgIcon-use" width="45" height="45"><path d="M5 40V5h35v35H5zm8.56-12.627c0 .555-.027.687-.318 1.03l-2.457 2.985v.396h6.974v-.396l-2.456-2.985c-.291-.343-.344-.502-.344-1.03V18.42l6.127 13.364h.714l5.256-13.364v10.644c0 .29 0 .342-.185.528l-1.848 1.796v.396h9.19v-.396l-1.822-1.796c-.184-.186-.21-.238-.21-.528V15.937c0-.291.026-.344.21-.528l1.823-1.797v-.396h-6.471l-4.622 11.542-5.203-11.542h-6.79v.396l2.14 2.64c.239.292.291.37.291.768v10.353z"></path></svg></span><span class="u-textScreenReader">Homepage</span></a></div><div class="u-xs-show js-metabarLogoLeft"><a href="https://medium.com/" data-log-event="home" class="siteNav-logo u-fillTransparentBlackDarker u-flex0 u-flexCenter u-paddingTop0"><span class="svgIcon svgIcon--logoMonogram svgIcon--45px is-flushLeft u-flex0 u-flexCenter u-paddingTop0"><svg class="svgIcon-use" width="45" height="45"><path d="M5 40V5h35v35H5zm8.56-12.627c0 .555-.027.687-.318 1.03l-2.457 2.985v.396h6.974v-.396l-2.456-2.985c-.291-.343-.344-.502-.344-1.03V18.42l6.127 13.364h.714l5.256-13.364v10.644c0 .29 0 .342-.185.528l-1.848 1.796v.396h9.19v-.396l-1.822-1.796c-.184-.186-.21-.238-.21-.528V15.937c0-.291.026-.344.21-.528l1.823-1.797v-.396h-6.471l-4.622 11.542-5.203-11.542h-6.79v.396l2.14 2.64c.239.292.291.37.291.768v10.353z"></path></svg></span><span class="u-textScreenReader">Homepage</span></a></div><div class="u-flexCenter u-height65 u-xs-height56"><span class="u-inlineBlock u-height28 u-xs-height24 u-verticalAlignTop u-marginRight20 u-marginLeft15 u-borderRightLighter"></span></div><div class="u-flexCenter u-height65 u-xs-height56 u-marginRight18"><div class="u-xs-show"><a class="link u-baseColor--link avatar avatar--roundedRectangle" href="https://ai-alignment.com?source=avatar-lo_JuU2p2EvGepj-624d886c4aa4" title="Go to AI Alignment" aria-label="Go to AI Alignment" data-action-source="avatar-lo_JuU2p2EvGepj-624d886c4aa4" data-collection-slug="ai-control"><img src="https://cdn-images-1.medium.com/fit/c/32/32/1*N56Qc5-aHTcfGff0scntKQ.png" class="avatar-image avatar-image--icon" alt="AI Alignment"></a></div><div class="u-xs-hide"><a href="https://ai-alignment.com?source=logo-lo_JuU2p2EvGepj---624d886c4aa4" class="u-flexCenter js-collectionLogoOrName"><span class="u-noWrapWithEllipsis u-maxWidth1032 u-uiTextBold u-fontSize26 u-textColorDarker">AI Alignment</span></a></div></div></div><div class="metabar-block u-flex0 u-flexCenter"><div class="u-flexCenter u-height65 u-xs-height56"><div class="buttonSet buttonSet--wide u-lineHeightInherit"><a class="button button--primary button--chromeless u-accentColor--buttonNormal is-inSiteNavBar u-xs-hide js-signInButton" href="https://medium.com/m/signin?redirect=https%3A%2F%2Fai-alignment.com%2Fefficient-and-safely-scalable-8218fa8a871f&amp;source=--------------------------nav_reg&amp;operation=login" data-action="sign-in-prompt" data-redirect="https://ai-alignment.com/efficient-and-safely-scalable-8218fa8a871f" data-action-source="--------------------------nav_reg">Sign in</a><a class="button button--primary button--withChrome u-accentColor--buttonNormal is-inSiteNavBar js-signUpButton" href="https://medium.com/m/signin?redirect=https%3A%2F%2Fai-alignment.com%2Fefficient-and-safely-scalable-8218fa8a871f&amp;source=--------------------------nav_reg&amp;operation=register" data-action="sign-up-prompt" data-redirect="https://ai-alignment.com/efficient-and-safely-scalable-8218fa8a871f" data-action-source="--------------------------nav_reg">Get started</a></div></div></div></div></div><div class="metabar metabar--spacer js-metabarSpacer u-height65 u-xs-height56"></div><main role="main"><article class=" u-minHeight100vhOffset65 u-overflowHidden postArticle postArticle--full is-withAccentColors u-marginBottom40" lang="en"><div class="postArticle-content js-postField js-notesSource js-trackPostScrolls" data-post-id="8218fa8a871f" data-source="post_page" data-collection-id="624d886c4aa4" data-tracking-context="postPage" data-scroll="native"><section name="c867" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h1 name="531d" id="531d" class="graf graf--h3 graf--leading graf--title">Efficient and safely&nbsp;scalable</h1><div class="uiScale uiScale-ui--regular uiScale-caption--regular u-flexCenter u-marginVertical24 u-fontSize15 js-postMetaLockup"><div class="u-flex0"><a class="link u-baseColor--link avatar" href="https://ai-alignment.com/@paulfchristiano?source=post_header_lockup" data-action="show-user-card" data-action-source="post_header_lockup" data-action-value="57f1a655a613" data-action-type="hover" data-user-id="57f1a655a613" data-collection-slug="ai-control" dir="auto"><img src="https://cdn-images-1.medium.com/fit/c/50/50/1*BNjZCuQuRfIgcXCBMipuBw.jpeg" class="avatar-image u-size50x50" alt="Go to the profile of Paul Christiano"></a></div><div class="u-flex1 u-paddingLeft15 u-overflowHidden"><div class="u-paddingBottom3"><a class="ds-link ds-link--styleSubtle ui-captionStrong u-inlineBlock link link--darken link--darker" href="https://ai-alignment.com/@paulfchristiano" data-action="show-user-card" data-action-value="57f1a655a613" data-action-type="hover" data-user-id="57f1a655a613" data-collection-slug="ai-control" dir="auto">Paul Christiano</a><span class="followState js-followState" data-user-id="57f1a655a613"><button class="button button--smallest u-noUserSelect button--withChrome u-baseColor--buttonNormal button--withHover button--unblock js-unblockButton u-marginLeft10 u-xs-hide" data-action="sign-up-prompt" data-sign-in-action="toggle-block-user" data-requires-token="true" data-redirect="https://ai-alignment.com/efficient-and-safely-scalable-8218fa8a871f" data-action-source="post_header_lockup"><span class="button-label  button-defaultState">Blocked</span><span class="button-label button-hoverState">Unblock</span></button><button class="button button--primary button--smallest button--dark u-noUserSelect button--withChrome u-accentColor--buttonDark button--follow js-followButton u-marginLeft10 u-xs-hide" data-action="sign-up-prompt" data-sign-in-action="toggle-subscribe-user" data-requires-token="true" data-redirect="https://medium.com/_/subscribe/user/57f1a655a613" data-action-source="post_header_lockup-57f1a655a613-------------------------follow_byline"><span class="button-label  button-defaultState js-buttonLabel">Follow</span><span class="button-label button-activeState">Following</span></button></span></div><div class="ui-caption u-noWrapWithEllipsis js-testPostMetaInlineSupplemental"><time datetime="2016-03-24T01:47:00.844Z">Mar 23, 2016</time><span class="middotDivider u-fontSize12"></span><span class="readingTime" title="15 min read"></span></div></div></div><p name="30e4" id="30e4" class="graf graf--p graf-after--h3">Precisely defining the goal of AI control research seems quite difficult. This post gives preliminary definitions of <strong class="markup--strong markup--p-strong">safe scalability</strong> and <strong class="markup--strong markup--p-strong">efficiency</strong> for AI control protocols, taking a step towards formalization. Roughly, these properties say that ‚Äúusing better machine learning primitives results in better systems‚Äù and ‚Äúthe control scheme does not impose significant overhead.‚Äù</p><p name="b32d" id="b32d" class="graf graf--p graf-after--p">I think these properties are probably sufficient conditions for success, but they are also probably too ambitious to be realistic goals. I discuss a few possible ways to weaken these definitions.</p><p name="12bf" id="12bf" class="graf graf--p graf-after--p">Both scalability and efficiency are defined with respect to a preference order ‚âª·¥∞ which tells us when one algorithm is ‚Äúbetter‚Äù another on some distribution D, according to the user‚Äôs preferences. I won‚Äôt offer any precise definition of ‚âª·¥∞, but I‚Äôll discuss a few informal candidates.</p><h4 name="2794" id="2794" class="graf graf--h4 graf-after--p">Motivation</h4><p name="caf0" id="caf0" class="graf graf--p graf-after--h4">I‚Äôm interested in defining alignment formally for at least three reasons:</p><ul class="postList"><li name="89ca" id="89ca" class="graf graf--li graf-after--p">Having a precise goal makes it easier to do good and well-targeted research. The AI control problem would feel much easier to me (both to work on and to talk to others about) if there were a precise, satisfactory, and achievable goal.</li><li name="0b19" id="0b19" class="graf graf--li graf-after--li">A precise definition of alignment might be helpful when analyzing AI control schemes. For example, <a href="https://medium.com/ai-control/alba-an-explicit-proposal-for-aligned-ai-17a55f60bbcf" data-href="https://medium.com/ai-control/alba-an-explicit-proposal-for-aligned-ai-17a55f60bbcf" class="markup--anchor markup--li-anchor" target="_blank">the analysis of ALBA</a> calls for maintaining alignment as an inductive invariant as the agent becomes more powerful. Right now, there is little hope of making that argument formal.</li><li name="91e1" id="91e1" class="graf graf--li graf-after--li">Trying to formalize alignment may shed light on what the key difficulties are, what assumptions are likely to be necessary, and so on. Trying to pin down slippery concepts is often a good idea&nbsp;.</li></ul><h3 name="14b9" id="14b9" class="graf graf--h3 graf-after--li">Definitions</h3><h4 name="fca7" id="fca7" class="graf graf--h4 graf-after--h3">What is a control protocol?</h4><p name="291d" id="291d" class="graf graf--p graf-after--h4">Our AI control protocols will use machine learning primitives as building blocks, and construct a (hopefully aligned) AI out of them.</p><p name="3894" id="3894" class="graf graf--p graf-after--p">To instantiate a control protocol A ü…™…¢…¥, we provide some set of learning primitives that are required by the protocol. A ü…™…¢…¥ then instantiates any number of copies of each of those primitives. A ü…™…¢…¥ may choose what inputs to provide to those instances, and may use their outputs however it likes. A ü…™…¢…¥ may also interact with the user arbitrarily.</p><p name="8c2d" id="8c2d" class="graf graf--p graf-after--p">For simplicity, throughout the post we will assume that A ü…™…¢…¥ is built from an RL algorithm, and write A ü…™…¢…¥(A·¥ø·¥∏) for the algorithm obtained by using A·¥ø·¥∏. Note that A ü…™…¢…¥ can instantiate any number of distinct instances of A·¥ø·¥∏, can provide each of them distinct rewards, and so on.</p><p name="61d5" id="61d5" class="graf graf--p graf-after--p">All of our definitions can be easily extended to any set of machine learning primitives, as long as we can define what it means for one implementation of a primitive to ‚Äúoutperform‚Äù another on a given distribution. I think that the definitions are most interesting when we can efficiently test whether one implementation outperforms another, and amongst such primitives RL is essentially universal (since we can use the test itself as a reward function).</p><h4 name="4318" id="4318" class="graf graf--h4 graf-after--p">Betterness</h4><p name="a066" id="a066" class="graf graf--p graf-after--h4">What does it mean for one algorithm to be better than another?</p><p name="20f0" id="20f0" class="graf graf--p graf-after--p">We won‚Äôt answer that question. Instead, we take as given a family of preorders ‚â∫·¥∞ indexed by distributions D. These orders define when one program ‚Äúoutperforms‚Äù another on the distribution D, according to the user‚Äôs preferences.</p><p name="297f" id="297f" class="graf graf--p graf-after--p">Intuitively, we can imagine some (unobserved) utility function U characterizing the user‚Äôs preferences. U takes as input an (<em class="markup--em markup--p-em">x</em>, <em class="markup--em markup--p-em">y</em>) pair, and outputs a real number reflecting how good it is, according to the user‚Äôs preferences, for a program to output <em class="markup--em markup--p-em">y</em> given input <em class="markup--em markup--p-em">x</em>.</p><p name="8f6d" id="8f6d" class="graf graf--p graf-after--p">Then we could define:</p><ul class="postList"><li name="ae34" id="ae34" class="graf graf--li graf-after--p">A ‚âº·¥∞ B ‚ü∫ ùîº[U(<em class="markup--em markup--li-em">x, </em>A(<em class="markup--em markup--li-em">x</em>))] ‚â§ ùîº[U(<em class="markup--em markup--li-em">x</em>,<em class="markup--em markup--li-em"> </em>B(<em class="markup--em markup--li-em">x</em>))],</li></ul><p name="bb87" id="bb87" class="graf graf--p graf-after--li">where the expectations are taken over <em class="markup--em markup--p-em">x</em> drawn from D. We could also strengthen the condition by allowing A to score nearly as well on average over many episodes, or by requiring B to do at least as well as A for every utility function in some big set ùí∞. These changes make ‚â∫·¥∞ a preorder rather than a total order.</p><p name="c27a" id="c27a" class="graf graf--p graf-after--p">We‚Äôll give a range of more plausible definitions in the final section, but this is a good concrete example to have in mind.</p><h4 name="5254" id="5254" class="graf graf--h4 graf-after--p">Safely scalable and efficient</h4><p name="9d36" id="9d36" class="graf graf--p graf-after--h4">Intuitively, a control scheme is <em class="markup--em markup--p-em">safely scalable </em>if using better RL algorithms never results in worse performance. A control scheme is <em class="markup--em markup--p-em">efficient</em> if it can realize any level of performance with low overhead.</p><ul class="postList"><li name="d3f2" id="d3f2" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Safely scalable (with respect to </strong>‚âª·¥∞). Given any A·¥ø·¥∏, B·¥ø·¥∏, and the ability to sample from some distribution D with A ü…™…¢…¥(A·¥ø·¥∏) ‚âª·¥∞ A ü…™…¢…¥(B·¥ø·¥∏), we can sample from a distribution D·¥ø·¥∏ over RL episodes on which A·¥ø·¥∏ outperforms B·¥ø·¥∏.</li><li name="dc13" id="dc13" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Efficient (with respect to </strong>‚âª·¥∞). Given any B, we can implement an RL agent B·¥ø·¥∏ such that, for every distribution D from which we can sample, A ü…™…¢…¥(B·¥ø·¥∏) ‚™∞·¥∞ B.</li></ul><p name="1877" id="1877" class="graf graf--p graf-after--li">Efficiency is quantified by how much more time A ü…™…¢…¥(B·¥ø·¥∏) takes than B itself, and how often it queries the user. I‚Äôll say that a scheme is ‚Äú<strong class="markup--strong markup--p-strong">asymptotically efficient</strong>‚Äù if the difference in running times, and the number of queries to the user, is sublinear in the number of episodes T.</p><p name="3796" id="3796" class="graf graf--p graf-after--p">In order to be achievable this definition probably needs to be weakened. I think the most plausible way to weaken it is to make additional assumptions about the agent B in <strong class="markup--strong markup--p-strong">efficiency</strong>. For example, we could focus our attention on a particular approach to building AI systems, and assume that B is the kind of agent that might be produced by that approach. Particularly interesting are structural assumptions about how B itself is built out of the same building blocks that are available to A ü…™…¢…¥.</p><h4 name="770f" id="770f" class="graf graf--h4 graf-after--p">Hard to&nbsp;beat</h4><p name="2539" id="2539" class="graf graf--p graf-after--h4">Together efficiency and safe scalability imply a third property:</p><ul class="postList"><li name="1037" id="1037" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Hard to beat</strong>. Given any RL agent A·¥ø·¥∏, any agent B, and the ability to sample from a distribution D with B ‚âª·¥∞ A ü…™…¢…¥(A·¥ø·¥∏), we can implement an agent B·¥ø·¥∏ and sample from a distribution D·¥ø·¥∏ over RL episodes on which B·¥ø·¥∏ outperforms A·¥ø·¥∏.</li></ul><p name="085f" id="085f" class="graf graf--p graf-after--li">If an algorithm is ‚Äúhard to beat,‚Äù then the only way to make it better (according to ‚âª·¥∞) is to improve the underlying RL algorithms. In some sense this is the strongest form of optimality that we can realistically hope for, since improving our RL algorithms will allow us to build ‚Äúbetter‚Äù AI systems for any reasonable notion of ‚Äúbetter.‚Äù</p><p name="a29e" id="a29e" class="graf graf--p graf-after--p">To see that (efficient + scalable ‚Üí hard to beat), apply efficiency to find an agent A ü…™…¢…¥(B·¥ø·¥∏) ‚™∞·¥∞ B, use transitivity to infer that A ü…™…¢…¥(B·¥ø·¥∏) ‚âª·¥∞ A ü…™…¢…¥(A·¥ø·¥∏), and then to use safe scalability to sample from a distribution where B·¥ø·¥∏ outperforms A·¥ø·¥∏.</p><p name="7248" id="7248" class="graf graf--p graf-after--p">Being hard to beat is slightly weaker than being efficient + scalable while being almost as comforting. So it might also be useful as an easier goal.</p><h4 name="b895" id="b895" class="graf graf--h4 graf-after--p">Restrictions on the building&nbsp;blocks</h4><p name="fa54" id="fa54" class="graf graf--p graf-after--h4">Rather than working with a generic RL algorithm, we might want to work with an RL algorithm that satisfies some additional property. For example, A ü…™…¢…¥(A·¥ø·¥∏) might only be safely scalable if A·¥ø·¥∏ is able to make good enough predictions about humans, or if A·¥ø·¥∏ is ‚Äútransparent‚Äù in an appropriate sense.</p><p name="4687" id="4687" class="graf graf--p graf-after--p">These restrictions can be incorporated into the definition of safe scalability and efficiency‚Ää‚Äî‚Ääin safe scalability, we can strengthen the hypothesis by assuming that the learning algorithms satisfy the restrictions, and in efficiency we can strengthen the conclusion by assuming that the learning algorithms satisfy the restrictions.</p><p name="e051" id="e051" class="graf graf--p graf-after--p">To make the task easiest, we could strengthen the hypothesis of safe scalability <em class="markup--em markup--p-em">without</em> strengthening the conclusion of efficiency. For example, if we want to work with ‚Äútransparent‚Äù RL algorithms, we will probably not be able to strengthen the conclusion of efficiency‚Ää‚Äî‚Ääwe won‚Äôt be able to turn a black-box algorithm B into a transparent RL algorithm B·¥ø·¥∏. So we could instead aim for a scheme that is safely scalable when applied with transparent RL algorithms, and that is efficient when we are allowed to use arbitrary RL algorithms. The resulting control scheme would only be practically efficient to the extent that there are transparent nearly-state-of-the-art RL algorithms.</p><p name="b02c" id="b02c" class="graf graf--p graf-after--p">For now I am interested in schemes that work under <em class="markup--em markup--p-em">any</em> remotely plausible assumptions:</p><ul class="postList"><li name="500c" id="500c" class="graf graf--li graf-after--p">Even a conditional result would be a big advance beyond our current understanding.</li><li name="6125" id="6125" class="graf graf--li graf-after--li">Conditional results could clarify our understanding of when AI control will and won‚Äôt succeed.</li><li name="2c45" id="2c45" class="graf graf--li graf-after--li">Conditional results present natural targets for differential AI progress. For example, if we could formulate a transparency condition that was sufficient for building safe+efficient AI, this could help clarify the goals of research on transparency.</li></ul><h4 name="889b" id="889b" class="graf graf--h4 graf-after--li">Related building&nbsp;blocks</h4><p name="3471" id="3471" class="graf graf--p graf-after--h4">We might also work with a number of different building blocks, and require them to have some relationship to each other. For example, we might want to use both a classifier and an RL agent, and assume that the classifier is in some sense more powerful than the RL agent (though it‚Äôs <a href="https://medium.com/ai-control/the-informed-oversight-problem-1b51b4f66b35#.dl1zzh3jm" data-href="https://medium.com/ai-control/the-informed-oversight-problem-1b51b4f66b35#.dl1zzh3jm" class="markup--anchor markup--p-anchor" target="_blank">not yet clear to me what assumption of this form would actually be useful</a>). Or we might work with a sequence of RL agents, and <a href="https://medium.com/ai-control/alba-an-explicit-proposal-for-aligned-ai-17a55f60bbcf" data-href="https://medium.com/ai-control/alba-an-explicit-proposal-for-aligned-ai-17a55f60bbcf" class="markup--anchor markup--p-anchor" target="_blank">assume that each is only slightly more powerful than the last</a>.</p><h3 name="60f1" id="60f1" class="graf graf--h3 graf-after--p">Non-solutions</h3><h4 name="570a" id="570a" class="graf graf--h4 graf-after--h3">Plain RL (+counterfactual oversight)</h4><p name="1f5e" id="1f5e" class="graf graf--p graf-after--h4">The simplest behavior for A ü…™…¢…¥ is to simply consult the underlying RL agent directly, and then to define a reward that induces aligned behavior.</p><p name="7d30" id="7d30" class="graf graf--p graf-after--p">Perhaps the simplest reward function is a human‚Äôs evaluation: a human watches the agent and presses the reward button when the agent behaves well.</p><p name="f7c6" id="f7c6" class="graf graf--p graf-after--p">If the human has to monitor the agent during every episode, then this constitutes a huge efficiency hit and so our algorithm won‚Äôt be reasonably efficient.</p><p name="655e" id="655e" class="graf graf--p graf-after--p">More realistically, we could train our agent on a small subset of the data (for which the human does have to monitor the agent and press the reward button) and then use the learned policy to act even when there is no human monitor. If necessary, we could train online as in <a href="https://medium.com/ai-control/counterfactual-human-in-the-loop-a7822e36f399" data-href="https://medium.com/ai-control/counterfactual-human-in-the-loop-a7822e36f399" class="markup--anchor markup--p-anchor" target="_blank">counterfactual oversight</a>.</p><p name="e293" id="e293" class="graf graf--p graf-after--p">This approach is asymptotically efficient (as long as the size of the training set is sublinear in the total number of episodes, as would be typical).</p><p name="7494" id="7494" class="graf graf--p graf-after--p">However, this scheme is <strong class="markup--strong markup--p-strong">not</strong> safely scalable for a reasonable order ‚âª·¥∞.</p><p name="da66" id="da66" class="graf graf--p graf-after--p">The problem is that the user‚Äôs judgments are not exactly aligned with the user‚Äôs preferences. For any given input <em class="markup--em markup--p-em">x</em>, there are some outputs <em class="markup--em markup--p-em">y</em> for which the user assigns <em class="markup--em markup--p-em">y</em> an ‚Äúerroneously‚Äù high expected value, whether due to error, to bias, or simply to not having enough time to understand the consequences of a proposed action.</p><p name="cfe4" id="cfe4" class="graf graf--p graf-after--p">So let A·¥ø·¥∏ be an RL agent which outputs actions which the user mistakenly rates highly, and let B·¥ø·¥∏ be an RL agent which outputs actions that are better than A·¥ø·¥∏‚Äôs outputs but which are rated lower by the user. As long as the user‚Äôs judgments don‚Äôt perfectly preserve the ordering of outcomes, then we can construct such a pair. Then we can have A ü…™…¢…¥(A·¥ø·¥∏) ‚âª·¥∞ A ü…™…¢…¥(B·¥ø·¥∏) for most distributions D, while B·¥ø·¥∏ outperforms A·¥ø·¥∏ on <em class="markup--em markup--p-em">every</em> distribution D·¥ø·¥∏</p><h4 name="8379" id="8379" class="graf graf--h4 graf-after--p">Plain imitation learning (+counterfactual oversight)</h4><p name="eebc" id="eebc" class="graf graf--p graf-after--h4">Given observations of a human expert, we can give A·¥ø·¥∏ the problem ‚Äúpredict what output the human expert will produce on input <em class="markup--em markup--p-em">x</em>.‚Äù</p><p name="645e" id="645e" class="graf graf--p graf-after--p">After A·¥ø·¥∏ produces a prediction, with small probability we ask the human to actually produce an output <em class="markup--em markup--p-em">y</em>, and then we provide A·¥ø·¥∏ a payoff depending on the quality of its prediction. (There are a number of possible ways to score A·¥ø·¥∏, most involving two separate learners. For example, we could use a generative adversarial model, with a second instance of A·¥ø·¥∏ trying to distinguish the predicted output from the real human output. Or we could score A·¥ø·¥∏ based on a variational lower bound on the log probability it assigned to the particular prediction made by the user.)</p><p name="cdc5" id="cdc5" class="graf graf--p graf-after--p">This kind of imitation learning is not safely scalable: an agent which chooses superhuman actions will become strictly worse if we make them a perfect human-predictor, yet their performance in the RL game will improve.</p><p name="0d86" id="0d86" class="graf graf--p graf-after--p">(Intuitively, imitation <em class="markup--em markup--p-em">is</em> safely scalable but <em class="markup--em markup--p-em">is not </em>efficient‚Ää‚Äî‚Ääthis example highlights a way in which our definitions fail to map well to the intuitive definitions of these concepts.)</p><h4 name="7557" id="7557" class="graf graf--h4 graf-after--p">ALBA</h4><p name="3dbf" id="3dbf" class="graf graf--p graf-after--h4">The <a href="https://medium.com/ai-control/alba-an-explicit-proposal-for-aligned-ai-17a55f60bbcf" data-href="https://medium.com/ai-control/alba-an-explicit-proposal-for-aligned-ai-17a55f60bbcf" class="markup--anchor markup--p-anchor" target="_blank">current version of ALBA</a> is not safely scalable + efficient, even under the generous assumptions made in the post. The key problem is its reliance on a sequence of throttled RL subagents.</p><p name="8b3d" id="8b3d" class="graf graf--p graf-after--p">The missing ingredients, roughly speaking, are the following:</p><ul class="postList"><li name="5d17" id="5d17" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Speedup</strong>. Given black-box access to the agent B, we can produce a <em class="markup--em markup--li-em">strictly less capable</em> agent B‚Ä≤ such that Bootstrap(B‚Ä≤) ‚™∞·¥∞ B.</li><li name="3f28" id="3f28" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Informed oversight</strong>. <a href="https://medium.com/ai-control/the-informed-oversight-problem-1b51b4f66b35" data-href="https://medium.com/ai-control/the-informed-oversight-problem-1b51b4f66b35" class="markup--anchor markup--li-anchor" target="_blank">See here</a>.</li></ul><p name="8445" id="8445" class="graf graf--p graf-after--li">Speedup is impossible without some additional assumptions on B, and informed oversight probably also requires some additional assumptions (in order to make transparency possible). It‚Äôs not clear what kind of assumptions on B might be sufficient to carry out the analysis, and overall it looks like a daunting project.</p><h3 name="2641" id="2641" class="graf graf--h3 graf-after--p">Limitations</h3><h4 name="3ecb" id="3ecb" class="graf graf--h4 graf-after--h3">Too strong</h4><p name="5bc3" id="5bc3" class="graf graf--p graf-after--h4">I think the biggest problem with this definition is that it is too strong.</p><p name="a248" id="a248" class="graf graf--p graf-after--p">It‚Äôs not so strong as to be <em class="markup--em markup--p-em">obviously</em> impossible. But it looks <em class="markup--em markup--p-em">almost </em>obviously impossible. The discussions of RL and ALBA illustrate why the definition is so strong:</p><ul class="postList"><li name="69cf" id="69cf" class="graf graf--li graf-after--p">In order to turn a black box agent B into an agent B·¥ø·¥∏ with A ü…™…¢…¥(B·¥ø·¥∏) ‚™∞·¥∞ B, we are essentially forced to take B·¥ø·¥∏ = B (since we can‚Äôt produce other derivative agents using black-box access to B).</li><li name="0da5" id="0da5" class="graf graf--li graf-after--li">Then A ü…™…¢…¥ is essentially forced to be a training scheme for RL agents.</li><li name="b356" id="b356" class="graf graf--li graf-after--li">So in order to be safely scalable, A ü…™…¢…¥ needs to evaluate of the quality of the agent‚Äôs decisions ‚Äúwell enough‚Äù that optimizing its evaluations optimizes ‚âª·¥∞.</li><li name="4d4a" id="4d4a" class="graf graf--li graf-after--li">Moreover, A ü…™…¢…¥ can‚Äôt really use the RL agent‚Äôs help to make those decisions‚Ää‚Äî‚Ääif A ü…™…¢…¥ is merely a training procedure, the RL agent need not output anything except on the support of D, and so we can‚Äôt get any useful work out of the agent. Thus A ü…™…¢…¥ is using the same evaluations for every agent.</li><li name="3329" id="3329" class="graf graf--li graf-after--li">If A ü…™…¢…¥ evaluates the agent‚Äôs behavior ‚Äúwell enough‚Äù for an arbitrary agent, then A ü…™…¢…¥ must be evaluating the agent‚Äôs behavior perfectly.</li><li name="afbe" id="afbe" class="graf graf--li graf-after--li">It seems infeasible to produce such a perfect evaluations for any interesting ‚âª·¥∞.</li></ul><p name="c4cb" id="c4cb" class="graf graf--p graf-after--li">How might we weaken the definition?</p><ul class="postList"><li name="cf97" id="cf97" class="graf graf--li graf-after--p">Place some restriction on the set of agents B that we consider in <strong class="markup--strong markup--li-strong">efficiency</strong>. For example, we may restrict attention to the kinds of agents that could be produced by some particular AI research project in AI. I think that this is by far the most promising approach.</li><li name="49cb" id="49cb" class="graf graf--li graf-after--li">As discussed in the section <strong class="markup--strong markup--li-strong">Restrictions on building blocks</strong>, we could only require safe scalability for a certain class of RL agents, thus moving some of the work to ensuring that state-of-the-art RL agents have the required properties.</li><li name="e3c1" id="e3c1" class="graf graf--li graf-after--li">We could use relations ‚âª·¥∞ that evaluate agents holistically in terms of a <em class="markup--em markup--li-em">description</em> of the distribution D (see below). For example, we might say that ‚ÄúA ‚âª·¥∞ B if the human believes that A would outperform B on the distribution D.‚Äù I don‚Äôt really see a way to make this work, but it might be worth thinking about.</li><li name="2af0" id="2af0" class="graf graf--li graf-after--li">We could settle for an agent which is hard to beat instead of both efficient and safely scalable. I don‚Äôt think this really addresses the difficulty described above, but it does give us a tiny bit more traction.</li><li name="5702" id="5702" class="graf graf--li graf-after--li">We could swap the quantifier order, giving us access to B and D when trying to construct an agent B·¥ø·¥∏ with A ü…™…¢…¥(B·¥ø·¥∏) ‚™∞·¥∞ B. I don‚Äôt think this will help.</li></ul><p name="c65a" id="c65a" class="graf graf--p graf-after--li">I expect there are many other ways to weaken the definition, and of course we could pursue some combination of the above.</p><h4 name="5ef5" id="5ef5" class="graf graf--h4 graf-after--p">Improving RL algorithms is quite&nbsp;broad</h4><p name="00c5" id="00c5" class="graf graf--p graf-after--h4">Even if A ü…™…¢…¥ is efficient and safely scalable, A ü…™…¢…¥(A·¥ø·¥∏) isn‚Äôt necessarily <em class="markup--em markup--p-em">good</em> even according to ‚âª·¥∞. In order to make A ü…™…¢…¥(A·¥ø·¥∏) actually be good, we may need to improve A·¥ø·¥∏. In some sense this is obvious and inevitable‚Ää‚Äî‚Ääit‚Äôs like saying that even if we solve the control problem, AI progress will still make our AI systems work better.</p><p name="6e07" id="6e07" class="graf graf--p graf-after--p">But in particular, the alignment of A ü…™…¢…¥(A·¥ø·¥∏) may depend on how A·¥ø·¥∏ performs on some very unnatural distribution over RL problems (e.g. on how well A·¥ø·¥∏ is able to predict the results of human deliberation about moral questions).</p><p name="f21b" id="f21b" class="graf graf--p graf-after--p">Given how strong safe scalability and efficiency are, I don‚Äôt think this is a problem for this particular definition. That is, any such ‚Äúunnatural‚Äù distribution over RL problems would be necessary to achieving good behavior, even for very weak agents:</p><ul class="postList"><li name="a0c4" id="a0c4" class="graf graf--li graf-after--p">Given any aligned agent B we can apply efficiency to obtain an RL agent B·¥ø·¥∏.</li><li name="5f54" id="5f54" class="graf graf--li graf-after--li">If B·¥ø·¥∏ always does well on these unnatural instances, then they were in some strong sense <em class="markup--em markup--li-em">necessary</em> in order to get good behavior. But note that B might be quite weak, so these ‚Äúunnatural‚Äù instances were necessary even to getting good behavior out of weak AI systems.</li><li name="69f4" id="69f4" class="graf graf--li graf-after--li">If B·¥ø·¥∏ does poorly on these unnatural instances, then we can consider a very powerful agent A·¥ø·¥∏ that does equally poorly.</li><li name="22b4" id="22b4" class="graf graf--li graf-after--li">By safe scalability, A ü…™…¢…¥(A·¥ø·¥∏) remains at-least-as-good-as-B for that RL agent A·¥ø·¥∏.</li></ul><p name="0697" id="0697" class="graf graf--p graf-after--li">This argument would still go through if we restricted B to the kinds of AI‚Äôs that we might actually produce. (The conclusion would be that the unnatural RL instances are in fact necessary, <em class="markup--em markup--p-em">for the kinds of AI that we might actually build</em>, which is just as good.)</p><p name="2a5b" id="2a5b" class="graf graf--p graf-after--p">If we weakened the definition enough we might encounter a more troubling version of this unnatural-RL-instances problem, but even then I think that reducing the alignment problem to a concrete RL problem would probably represent significant progress in and of itself. So overall I‚Äôm not concerned about this potential bug.</p><h4 name="23f4" id="23f4" class="graf graf--h4 graf-after--p">Missing definition of&nbsp;‚âª·¥∞</h4><p name="9f3d" id="9f3d" class="graf graf--p graf-after--h4">We don‚Äôt provide any definition of ‚âª·¥∞; that definition needs to be quite subtle and is doing a lot of the work of formalizing our goals. See the discussion in the next section.</p><h3 name="c8ed" id="c8ed" class="graf graf--h3 graf-after--p">Defining ‚âª·¥∞</h3><h4 name="df5a" id="df5a" class="graf graf--h4 graf-after--h3">Human judgment</h4><p name="e9c4" id="e9c4" class="graf graf--p graf-after--h4">For sufficiently subhuman agents we could define:</p><ul class="postList"><li name="be0f" id="be0f" class="graf graf--li graf-after--p">Draw a random <em class="markup--em markup--li-em">x</em> from D, compute A(<em class="markup--em markup--li-em">x</em>) and B(<em class="markup--em markup--li-em">x</em>), and give them both to a human judge (along with the input x) to decide which is better. A ‚âª·¥∞ B if the human prefers A(<em class="markup--em markup--li-em">x</em>) with probability at least 2/3.</li></ul><p name="8b92" id="8b92" class="graf graf--p graf-after--li">For this definition of ‚â∫, the RL agent described above is in fact efficient and safely scalable.</p><p name="f2e9" id="f2e9" class="graf graf--p graf-after--p">But being safely scalable in this sense doesn‚Äôt seem very useful, since the human‚Äôs judgment about ‚Äúwhich action is good‚Äù need not be correct, and the human would substantially prefer an agent that chooses actions which are <em class="markup--em markup--p-em">actually</em> good.</p><h4 name="f3c7" id="f3c7" class="graf graf--h4 graf-after--p">Human judgment on reflection</h4><p name="cdc7" id="cdc7" class="graf graf--p graf-after--h4">We could try to fix this definition with an alternative informal definition:</p><ul class="postList"><li name="5dac" id="5dac" class="graf graf--li graf-after--p">Draw a random <em class="markup--em markup--li-em">x</em> from D, compute A(<em class="markup--em markup--li-em">x</em>) and B(<em class="markup--em markup--li-em">x</em>). Give a human judge <a href="https://ordinaryideas.wordpress.com/2012/04/21/indirect-normativity-write-up/" data-href="https://ordinaryideas.wordpress.com/2012/04/21/indirect-normativity-write-up/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">an extremely long time to reflect, and access to extremely powerful tools</a>. A ‚âª·¥∞ B if, upon extensive reflection, the human prefers A(<em class="markup--em markup--li-em">x</em>) with probability at least 2/3.</li></ul><p name="6ddd" id="6ddd" class="graf graf--p graf-after--li">This definition leads to a very strong notion of safe scalability. Unfortunately that strong notion is <em class="markup--em markup--p-em">too</em> strong, and it is clearly intractable to build a hard-to-beat agent in this sense.</p><p name="4794" id="4794" class="graf graf--p graf-after--p">For example, consider some hard question that bears on what strategies will have good long-term effects. This question is beyond our abilities currently, but we will be able to answer it with sufficient reflection. If B guesses the correct answer to that question and A does not, then A ‚â∫·¥∞ B, where D is the a point distribution concentrated on a decision where that question matters. If B guesses the wrong answer, then B ‚â∫·¥∞ A. But by efficiency + safe scalability, we can essentially produce a pair of agents A·¥ø·¥∏ and B·¥ø·¥∏ and sample from a distribution D·¥ø·¥∏ such that A ‚â∫·¥∞ B iff B·¥ø·¥∏ outperforms A·¥ø·¥∏ on D ·¥ø·¥∏. But then we can test which of A and B is correct about the hard question, contradicting its supposed hardness.</p><h4 name="96d8" id="96d8" class="graf graf--h4 graf-after--p">Holistic judgment</h4><p name="1854" id="1854" class="graf graf--p graf-after--h4">A very different approach would be to directly elicit the human‚Äôs judgment about the relative merits of A and B. That is:</p><ul class="postList"><li name="e159" id="e159" class="graf graf--li graf-after--p">Give a human judge a description of A and B, and the sampling procedure for D, and ask them which they expect to perform better. A ‚âª·¥∞ B if the human thinks that A would make significantly better decisions than B, on inputs sampled from D.</li></ul><p name="48e2" id="48e2" class="graf graf--p graf-after--li">In some sense this definition gets very directly at what we care about. Suppose that some alternative AI control research program produced B, and that we would be happier using B than A. Then we are precisely satisfying this definition of A ‚â∫·¥∞ B.</p><p name="e008" id="e008" class="graf graf--p graf-after--p">An obvious problem with this approach is that determining which of A and B is better may itself be a very hard problem‚Ää‚Äî‚Ääindeed, it‚Äôs easy to believe that it includes all of the difficulty of the alignment problem.</p><p name="628c" id="628c" class="graf graf--p graf-after--p">The definition of efficiency<strong class="markup--strong markup--p-strong"> </strong>still has teeth if we restrict our attention to algorithms B that ‚Äúexplain themselves,‚Äù e.g. that are accompanied with significant documentation and explanation. The description of the agent B could embody the entire output of the alternative research program that produced it.</p><p name="edbf" id="edbf" class="graf graf--p graf-after--p">So this definition of betterness is adequate if we think that there are efficient and good decision-making protocols which are <em class="markup--em markup--p-em">demonstrably</em> good to existing humans. This definition is very unsatisfying if we think that evaluating a possible proposal, even given the best available arguments, is the core difficulty of AI control. This might be either because those arguments are necessarily extremely complex, or because there will be many bad proposals that are also supported by extremely convincing-looking arguments.</p><h4 name="08c8" id="08c8" class="graf graf--h4 graf-after--p">What we really&nbsp;want</h4><p name="5df8" id="5df8" class="graf graf--p graf-after--h4">Intuitively, I would like a definition along the lines of:</p><ul class="postList"><li name="0415" id="0415" class="graf graf--li graf-after--p">Draw a random <em class="markup--em markup--li-em">x</em> from D, compute A(<em class="markup--em markup--li-em">x</em>) and B(<em class="markup--em markup--li-em">x</em>). Give a human judge the same information, abilities, and insights, that A and B used to compute these quantities. A ‚âª·¥∞ B if the human prefers A(<em class="markup--em markup--li-em">x</em>) with probability at least 2/3.</li></ul><p name="aebe" id="aebe" class="graf graf--p graf-after--li">This definition smuggles all of the complexity into imagining that the human has the same ‚Äúinformation, abilities, and insights‚Äù as the AI they are evaluating. I don‚Äôt have any candidate formalization of this idea, nor am I especially optimistic about being able to formalize it.</p><p name="4b26" id="4b26" class="graf graf--p graf-after--p">I do feel like I can reason about this definition intuitively and that it roughly captures my intuitive desiderata. This makes me more optimistic that there is <em class="markup--em markup--p-em">some</em> satisfactory definition of ‚âª.</p><p name="5d9a" id="5d9a" class="graf graf--p graf-after--p">Note that this definition is closely related to the goal in <a href="https://medium.com/ai-control/the-informed-oversight-problem-1b51b4f66b35" data-href="https://medium.com/ai-control/the-informed-oversight-problem-1b51b4f66b35" class="markup--anchor markup--p-anchor" target="_blank">the informed oversight problem</a>, which is roughly to ensure that the overseer ‚Äúknows everything the AI knows.‚Äù In the informed oversight problem we are willing to assume that the overseer is significantly more powerful than the system they are overseeing. That may well be a necessary assumption to actually ensure that the overseer ‚Äúknows everything the AI knows,‚Äù but it probably isn‚Äôt needed to define what it would mean for the overseer to ‚Äúknow everything the AI knows.‚Äù</p><h3 name="daa8" id="daa8" class="graf graf--h3 graf-after--p">Conclusion</h3><p name="075d" id="075d" class="graf graf--p graf-after--h3">We can try to define the goals of AI control by thinking about how AI systems relate to the underlying machine learning primitives. Such a framework wouldn‚Äôt cover all possible approaches to AI control, but where applicable it could be a great way to organize research and a useful analysis tool.</p><p name="e937" id="e937" class="graf graf--p graf-after--p graf--trailing">This post gave a step in that direction, but did not yet succeed. I would love to see other attempts, and I think there is a good chance that it will be possible to find a satisfying problem statement for AI control.</p></div></div></section></div><footer class="u-paddingTop10"><div class="container u-maxWidth740"><div class="row"><div class="col u-size12of12"></div></div><div class="row"><div class="col u-size12of12 js-postTags"><div class="u-paddingBottom10"><ul class="tags tags--postTags tags--borderless"></ul></div></div></div><div class="postActions js-postActionsFooter "><div class="u-flexCenter"><div class="u-flex1"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="8218fa8a871f" data-is-icon-29px="true" data-is-circle="true" data-has-recommend-list="true" data-source="post_actions_footer-----8218fa8a871f---------------------clap_footer" data-clap-string-singular="clap" data-clap-string-plural="claps"><div class="u-relative u-foreground"><button class="button button--large button--circle button--withChrome u-baseColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--darker clapButton--largePill u-relative u-foreground u-xs-paddingLeft13 u-width60 u-height60 u-accentColor--textNormal u-accentColor--buttonNormal clap-onboardingcollection" data-action="sign-up-prompt" data-sign-in-action="multivote" data-requires-token="true" data-redirect="https://medium.com/_/vote/p/8218fa8a871f" data-action-source="post_actions_footer-----8218fa8a871f---------------------clap_footer" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--33px u-relative u-topNegative2 u-xs-top0"><svg class="svgIcon-use" width="33" height="33"><path d="M28.86 17.342l-3.64-6.402c-.292-.433-.712-.729-1.163-.8a1.124 1.124 0 0 0-.889.213c-.63.488-.742 1.181-.33 2.061l1.222 2.587 1.4 2.46c2.234 4.085 1.511 8.007-2.145 11.663-.26.26-.526.49-.797.707 1.42-.084 2.881-.683 4.292-2.094 3.822-3.823 3.565-7.876 2.05-10.395zm-6.252 11.075c3.352-3.35 3.998-6.775 1.978-10.469l-3.378-5.945c-.292-.432-.712-.728-1.163-.8a1.122 1.122 0 0 0-.89.213c-.63.49-.742 1.182-.33 2.061l1.72 3.638a.502.502 0 0 1-.806.568l-8.91-8.91a1.335 1.335 0 0 0-1.887 1.886l5.292 5.292a.5.5 0 0 1-.707.707l-5.292-5.292-1.492-1.492c-.503-.503-1.382-.505-1.887 0a1.337 1.337 0 0 0 0 1.886l1.493 1.492 5.292 5.292a.499.499 0 0 1-.353.854.5.5 0 0 1-.354-.147L5.642 13.96a1.338 1.338 0 0 0-1.887 0 1.338 1.338 0 0 0 0 1.887l2.23 2.228 3.322 3.324a.499.499 0 0 1-.353.853.502.502 0 0 1-.354-.146l-3.323-3.324a1.333 1.333 0 0 0-1.886 0 1.325 1.325 0 0 0-.39.943c0 .356.138.691.39.943l6.396 6.397c3.528 3.53 8.86 5.313 12.821 1.353zM12.73 9.26l5.68 5.68-.49-1.037c-.518-1.107-.426-2.13.224-2.89l-3.303-3.304a1.337 1.337 0 0 0-1.886 0 1.326 1.326 0 0 0-.39.944c0 .217.067.42.165.607zm14.787 19.184c-1.599 1.6-3.417 2.392-5.353 2.392-.349 0-.7-.03-1.058-.082a7.922 7.922 0 0 1-3.667.887c-3.049 0-6.115-1.626-8.359-3.87l-6.396-6.397A2.315 2.315 0 0 1 2 19.724a2.327 2.327 0 0 1 1.923-2.296l-.875-.875a2.339 2.339 0 0 1 0-3.3 2.33 2.33 0 0 1 1.24-.647l-.139-.139c-.91-.91-.91-2.39 0-3.3.884-.884 2.421-.882 3.301 0l.138.14a2.335 2.335 0 0 1 3.948-1.24l.093.092c.091-.423.291-.828.62-1.157a2.336 2.336 0 0 1 3.3 0l3.384 3.386a2.167 2.167 0 0 1 1.271-.173c.534.086 1.03.354 1.441.765.11-.549.415-1.034.911-1.418a2.12 2.12 0 0 1 1.661-.41c.727.117 1.385.565 1.853 1.262l3.652 6.423c1.704 2.832 2.025 7.377-2.205 11.607zM13.217.484l-1.917.882 2.37 2.837-.454-3.719zm8.487.877l-1.928-.86-.44 3.697 2.368-2.837zM16.5 3.293L15.478-.005h2.044L16.5 3.293z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--33px u-relative u-topNegative2 u-xs-top0"><svg class="svgIcon-use" width="33" height="33"><g fill-rule="evenodd"><path d="M29.58 17.1l-3.854-6.78c-.365-.543-.876-.899-1.431-.989a1.491 1.491 0 0 0-1.16.281c-.42.327-.65.736-.7 1.207v.001l3.623 6.367c2.46 4.498 1.67 8.802-2.333 12.807-.265.265-.536.505-.81.728 1.973-.222 3.474-1.286 4.45-2.263 4.166-4.165 3.875-8.6 2.215-11.36zm-4.831.82l-3.581-6.3c-.296-.439-.725-.742-1.183-.815a1.105 1.105 0 0 0-.89.213c-.647.502-.755 1.188-.33 2.098l1.825 3.858a.601.601 0 0 1-.197.747.596.596 0 0 1-.77-.067L10.178 8.21c-.508-.506-1.393-.506-1.901 0a1.335 1.335 0 0 0-.393.95c0 .36.139.698.393.95v.001l5.61 5.61a.599.599 0 1 1-.848.847l-5.606-5.606c-.001 0-.002 0-.003-.002L5.848 9.375a1.349 1.349 0 0 0-1.902 0 1.348 1.348 0 0 0 0 1.901l1.582 1.582 5.61 5.61a.6.6 0 0 1-.848.848l-5.61-5.61c-.51-.508-1.393-.508-1.9 0a1.332 1.332 0 0 0-.394.95c0 .36.139.697.393.952l2.363 2.362c.002.001.002.002.002.003l3.52 3.52a.6.6 0 0 1-.848.847l-3.522-3.523h-.001a1.336 1.336 0 0 0-.95-.393 1.345 1.345 0 0 0-.949 2.295l6.779 6.78c3.715 3.713 9.327 5.598 13.49 1.434 3.527-3.528 4.21-7.13 2.086-11.015zM11.817 7.727c.06-.328.213-.64.466-.893.64-.64 1.755-.64 2.396 0l3.232 3.232c-.82.783-1.09 1.833-.764 2.992l-5.33-5.33z"></path><path d="M13.285.48l-1.916.881 2.37 2.837z"></path><path d="M21.719 1.361L19.79.501l-.44 3.697z"></path><path d="M16.502 3.298L15.481 0h2.043z"></path></g></svg></span></span></button><div class="clapUndo u-width60 u-round u-height32 u-absolute u-borderBox u-paddingRight5 u-transition--transform200Springu-backgroundGrayLighter js-clapUndo" style="top: 14px; padding: 2px;"><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon u-floatRight" data-action="multivote-undo" data-action-value="8218fa8a871f"><span class="svgIcon svgIcon--removeThin svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M20.13 8.11l-5.61 5.61-5.609-5.61-.801.801 5.61 5.61-5.61 5.61.801.8 5.61-5.609 5.61 5.61.8-.801-5.609-5.61 5.61-5.61" fill-rule="evenodd"></path></svg></span></button></div></div><span class="u-relative u-background js-actionMultirecommendCount u-marginLeft16"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-textColorDarker" data-action="show-recommends" data-action-value="8218fa8a871f">4 claps</button><span class="u-xs-hide"></span></span></div></div><div class="buttonSet u-flex0"><a class="button button--dark button--chromeless u-baseColor--buttonDark button--withIcon button--withSvgIcon button--dark button--chromeless u-xs-hide u-marginRight12" href="https://medium.com/p/8218fa8a871f/share/twitter" title="Share on Twitter" aria-label="Share on Twitter" target="_blank" data-action-source="post_actions_footer"><span class="button-defaultState"><span class="svgIcon svgIcon--twitterFilled svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M22.053 7.54a4.474 4.474 0 0 0-3.31-1.455 4.526 4.526 0 0 0-4.526 4.524c0 .35.04.7.082 1.05a12.9 12.9 0 0 1-9.3-4.77c-.39.69-.61 1.46-.65 2.26.03 1.6.83 2.99 2.02 3.79-.72-.02-1.41-.22-2.02-.57-.01.02-.01.04 0 .08-.01 2.17 1.55 4 3.63 4.44-.39.08-.79.13-1.21.16-.28-.03-.57-.05-.81-.08.54 1.77 2.21 3.08 4.2 3.15a9.564 9.564 0 0 1-5.66 1.94c-.34-.03-.7-.06-1.05-.08 2 1.27 4.38 2.02 6.94 2.02 8.31 0 12.86-6.9 12.84-12.85.02-.24.01-.43 0-.65.89-.62 1.65-1.42 2.26-2.34-.82.38-1.69.62-2.59.72a4.37 4.37 0 0 0 1.94-2.51c-.84.53-1.81.9-2.83 1.13z"></path></svg></span></span></a><a class="button button--dark button--chromeless u-baseColor--buttonDark button--withIcon button--withSvgIcon button--dark button--chromeless u-xs-hide u-marginRight12" href="https://medium.com/p/8218fa8a871f/share/facebook" title="Share on Facebook" aria-label="Share on Facebook" target="_blank" data-action-source="post_actions_footer"><span class="button-defaultState"><span class="svgIcon svgIcon--facebookSquare svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M23.209 5H5.792A.792.792 0 0 0 5 5.791V23.21c0 .437.354.791.792.791h9.303v-7.125H12.72v-2.968h2.375v-2.375c0-2.455 1.553-3.662 3.741-3.662 1.049 0 1.95.078 2.213.112v2.565h-1.517c-1.192 0-1.469.567-1.469 1.397v1.963h2.969l-.594 2.968h-2.375L18.11 24h5.099a.791.791 0 0 0 .791-.791V5.79a.791.791 0 0 0-.791-.79"></path></svg></span></span></a><button class="button button--large button--dark button--chromeless u-baseColor--buttonDark button--withIcon button--withSvgIcon u-xs-show u-marginRight10" title="Share this story on Twitter or Facebook" aria-label="Share this story on Twitter or Facebook" data-action="show-share-popover" data-action-source="post_actions_footer"><span class="svgIcon svgIcon--share svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M20.385 8H19a.5.5 0 1 0 .011 1h1.39c.43 0 .84.168 1.14.473.31.305.48.71.48 1.142v10.77c0 .43-.17.837-.47 1.142-.3.305-.71.473-1.14.473H8.62c-.43 0-.84-.168-1.144-.473a1.603 1.603 0 0 1-.473-1.142v-10.77c0-.43.17-.837.48-1.142A1.599 1.599 0 0 1 8.62 9H10a.502.502 0 0 0 0-1H8.615c-.67 0-1.338.255-1.85.766-.51.51-.765 1.18-.765 1.85v10.77c0 .668.255 1.337.766 1.848.51.51 1.18.766 1.85.766h11.77c.668 0 1.337-.255 1.848-.766.51-.51.766-1.18.766-1.85v-10.77c0-.668-.255-1.337-.766-1.848A2.61 2.61 0 0 0 20.384 8zm-8.67-2.508L14 3.207v8.362c0 .27.224.5.5.5s.5-.23.5-.5V3.2l2.285 2.285a.49.49 0 0 0 .704-.001.511.511 0 0 0 0-.708l-3.14-3.14a.504.504 0 0 0-.71 0L11 4.776a.501.501 0 0 0 .71.706" fill-rule="evenodd"></path></svg></span></button><button class="button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon" data-action="scroll-to-responses" data-action-source="post_actions_footer"><span class="svgIcon svgIcon--response svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M21.27 20.058c1.89-1.826 2.754-4.17 2.754-6.674C24.024 8.21 19.67 4 14.1 4 8.53 4 4 8.21 4 13.384c0 5.175 4.53 9.385 10.1 9.385 1.007 0 2-.14 2.95-.41.285.25.592.49.918.7 1.306.87 2.716 1.31 4.19 1.31.276-.01.494-.14.6-.36a.625.625 0 0 0-.052-.65c-.61-.84-1.042-1.71-1.282-2.58a5.417 5.417 0 0 1-.154-.75zm-3.85 1.324l-.083-.28-.388.12a9.72 9.72 0 0 1-2.85.424c-4.96 0-8.99-3.706-8.99-8.262 0-4.556 4.03-8.263 8.99-8.263 4.95 0 8.77 3.71 8.77 8.27 0 2.25-.75 4.35-2.5 5.92l-.24.21v.32c0 .07 0 .19.02.37.03.29.1.6.19.92.19.7.49 1.4.89 2.08-.93-.14-1.83-.49-2.67-1.06-.34-.22-.88-.48-1.16-.74z"></path></svg></span></button><button class="button button--large button--dark button--chromeless is-touchIconFadeInPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="sign-up-prompt" data-sign-in-action="add-to-bookmarks" data-requires-token="true" data-redirect="https://medium.com/_/bookmark/p/8218fa8a871f" data-action-source="post_actions_footer"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--29px u-marginRight4"><svg class="svgIcon-use" width="29" height="29"><path d="M19.385 4h-9.77A2.623 2.623 0 0 0 7 6.615V23.01a1.022 1.022 0 0 0 1.595.847l5.905-4.004 5.905 4.004A1.022 1.022 0 0 0 22 23.011V6.62A2.625 2.625 0 0 0 19.385 4zM21 23l-5.91-3.955-.148-.107a.751.751 0 0 0-.884 0l-.147.107L8 23V6.615C8 5.725 8.725 5 9.615 5h9.77C20.275 5 21 5.725 21 6.615V23z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--29px u-marginRight4"><svg class="svgIcon-use" width="29" height="29"><path d="M19.385 4h-9.77A2.623 2.623 0 0 0 7 6.615V23.01a1.022 1.022 0 0 0 1.595.847l5.905-4.004 5.905 4.004A1.022 1.022 0 0 0 22 23.011V6.62A2.625 2.625 0 0 0 19.385 4z" fill-rule="evenodd"></path></svg></span></span></button><button class="button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon js-moreActionsButton" title="More actions" aria-label="More actions" data-action="more-actions"><span class="svgIcon svgIcon--more svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="-480.5 272.5 21 21"><path d="M-463 284.6c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5zm-7-.9c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5zm-7-.9c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5z"></path></svg></span></button></div></div></div></div><div class="u-maxWidth740 u-paddingTop20 u-marginTop20 u-borderTopLightest container u-paddingBottom20 u-xs-paddingBottom10 js-postAttributionFooterContainer"><div class="row js-postFooterInfo"><div class="col u-size6of12 u-xs-size12of12"><li class="uiScale uiScale-ui--small uiScale-caption--regular u-block u-paddingBottom18 js-cardUser"><div class="u-marginLeft20 u-floatRight"><span class="followState js-followState" data-user-id="57f1a655a613"><button class="button button--small u-noUserSelect button--withChrome u-baseColor--buttonNormal button--withHover button--unblock js-unblockButton" data-action="sign-up-prompt" data-sign-in-action="toggle-block-user" data-requires-token="true" data-redirect="https://ai-alignment.com/efficient-and-safely-scalable-8218fa8a871f" data-action-source="footer_card"><span class="button-label  button-defaultState">Blocked</span><span class="button-label button-hoverState">Unblock</span></button><button class="button button--primary button--small u-noUserSelect button--withChrome u-accentColor--buttonNormal button--follow js-followButton" data-action="sign-up-prompt" data-sign-in-action="toggle-subscribe-user" data-requires-token="true" data-redirect="https://medium.com/_/subscribe/user/57f1a655a613" data-action-source="footer_card-57f1a655a613-------------------------follow_footer"><span class="button-label  button-defaultState js-buttonLabel">Follow</span><span class="button-label button-activeState">Following</span></button></span></div><div class="u-tableCell"><a class="link u-baseColor--link avatar" href="https://ai-alignment.com/@paulfchristiano?source=footer_card" title="Go to the profile of Paul Christiano" aria-label="Go to the profile of Paul Christiano" data-action-source="footer_card" data-user-id="57f1a655a613" data-collection-slug="ai-control" dir="auto"><img src="https://cdn-images-1.medium.com/fit/c/60/60/1*BNjZCuQuRfIgcXCBMipuBw.jpeg" class="avatar-image avatar-image--small" alt="Go to the profile of Paul Christiano"></a></div><div class="u-tableCell u-verticalAlignMiddle u-breakWord u-paddingLeft15"><h3 class="ui-h3 u-fontSize18 u-lineHeightTighter u-marginBottom4"><a class="link link--primary u-accentColor--hoverTextNormal" href="https://ai-alignment.com/@paulfchristiano" property="cc:attributionName" title="Go to the profile of Paul Christiano" aria-label="Go to the profile of Paul Christiano" rel="author cc:attributionUrl" data-user-id="57f1a655a613" data-collection-slug="ai-control" dir="auto">Paul Christiano</a></h3><p class="ui-body u-fontSize14 u-lineHeightBaseSans u-textColorDark u-marginBottom4">OpenAI</p></div></li></div><div class="col u-size6of12 u-xs-size12of12 u-xs-marginTop30"><li class="uiScale uiScale-ui--small uiScale-caption--regular u-block u-paddingBottom18 js-cardCollection"><div class="u-marginLeft20 u-floatRight"><button class="button button--primary button--small u-noUserSelect button--withChrome u-accentColor--buttonNormal js-relationshipButton" data-action="sign-up-prompt" data-sign-in-action="toggle-follow-collection" data-requires-token="true" data-redirect="https://medium.com/_/subscribe/collection/ai-control" data-action-source="footer_card----624d886c4aa4----------------------follow_footer" data-collection-id="624d886c4aa4"><span class="button-label  js-buttonLabel">Follow</span></button></div><div class="u-tableCell "><a class="link u-baseColor--link avatar avatar--roundedRectangle" href="https://ai-alignment.com?source=footer_card" title="Go to AI Alignment" aria-label="Go to AI Alignment" data-action-source="footer_card" data-collection-slug="ai-control"><img src="https://cdn-images-1.medium.com/fit/c/60/60/1*N56Qc5-aHTcfGff0scntKQ.png" class="avatar-image u-size60x60" alt="AI Alignment"></a></div><div class="u-tableCell u-verticalAlignMiddle u-breakWord u-paddingLeft15"><h3 class="ui-h3 u-fontSize18 u-lineHeightTighter u-marginBottom4"><a class="link link--primary u-accentColor--hoverTextNormal" href="https://ai-alignment.com?source=footer_card" rel="collection" data-action-source="footer_card" data-collection-slug="ai-control">AI Alignment</a></h3><p class="ui-body u-fontSize14 u-lineHeightBaseSans u-textColorDark u-marginBottom4">Aligning AI systems with human interests.</p><div class="buttonSet"></div></div></li></div></div></div><div class="js-postFooterPlacements" data-post-id="8218fa8a871f" data-collection-id="624d886c4aa4" data-scroll="native"><div class="streamItem streamItem--placementCardGrid js-streamItem"><div class="u-clearfix u-backgroundGrayLightest"><div class="row u-marginAuto u-maxWidth1032 u-paddingTop30 u-paddingBottom40"><div class="col u-padding8 u-xs-size12of12 u-size4of12"><div class="uiScale uiScale-ui--small uiScale-caption--regular u-height280 u-width100pct u-backgroundWhite u-borderCardBorder u-boxShadow u-borderBox u-borderRadius4 js-trackPostPresentation" data-post-id="c0bee00365bd" data-source="placement_card_footer_grid---------0-41" data-tracking-context="placement"><div class="u-padding15 u-borderBox u-flexColumn u-sizeFull"><a class="link link--noUnderline u-baseColor--link u-flex1 u-flexColumn" href="https://ai-alignment.com/universality-and-consequentialism-within-hch-c0bee00365bd?source=placement_card_footer_grid---------0-41" data-action-source="placement_card_footer_grid---------0-41"><div class="uiScale uiScale-ui--regular uiScale-caption--small u-textColorNormal u-marginBottom7">More from AI Alignment</div><div class="ui-h3 ui-clamp2 u-textColorDarkest u-contentSansBold u-fontSize24 u-maxHeight2LineHeightTighter u-lineClamp2 u-textOverflowEllipsis u-letterSpacingTight u-paddingBottom2">Universality and consequentialism within HCH</div><div class="ui-body ui-clamp2 u-lineClamp2 u-textOverflowEllipsis u-maxHeight2LineHeightTighter">One exotic reason HCH can fail to be universal is the emergence of malicious patterns of behavior; universality may help address this risk.</div></a><div class="u-paddingBottom10 u-flex0 u-flexCenter"><div class="u-flex1 u-minWidth0 u-marginRight10"><div class="u-flexCenter"><div class="postMetaInline-avatar u-flex0"><a class="link u-baseColor--link avatar" href="https://ai-alignment.com/@paulfchristiano" data-action="show-user-card" data-action-value="57f1a655a613" data-action-type="hover" data-user-id="57f1a655a613" data-collection-slug="ai-control" dir="auto"><img src="https://cdn-images-1.medium.com/fit/c/36/36/1*BNjZCuQuRfIgcXCBMipuBw.jpeg" class="avatar-image u-size36x36 u-xs-size32x32" alt="Go to the profile of Paul Christiano"></a></div><div class="postMetaInline postMetaInline-authorLockup ui-captionStrong u-flex1 u-noWrapWithEllipsis"><a class="ds-link ds-link--styleSubtle link link--darken link--darker" href="https://ai-alignment.com/@paulfchristiano?source=placement_card_footer_grid---------0-41" data-action="show-user-card" data-action-source="placement_card_footer_grid---------0-41" data-action-value="57f1a655a613" data-action-type="hover" data-user-id="57f1a655a613" data-collection-slug="ai-control" dir="auto">Paul Christiano</a><div class="ui-caption u-fontSize12 u-baseColor--textNormal u-textColorNormal js-postMetaInlineSupplemental"><a class="link link--darken" href="https://ai-alignment.com/universality-and-consequentialism-within-hch-c0bee00365bd?source=placement_card_footer_grid---------0-41" data-action="open-post" data-action-value="https://ai-alignment.com/universality-and-consequentialism-within-hch-c0bee00365bd?source=placement_card_footer_grid---------0-41" data-action-source="preview-listing"><time datetime="2019-01-10T03:50:05.776Z">Jan 9</time></a><span class="middotDivider u-fontSize12"></span><span class="readingTime" title="9 min read"></span></div></div></div></div><div class="u-flex0 u-flexCenter"><div class="buttonSet"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="c0bee00365bd" data-is-label-padded="true" data-source="placement_card_footer_grid-----c0bee00365bd----0-41----------------clap_preview"><div class="u-relative u-foreground"><button class="button button--primary button--chromeless u-accentColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--darker" data-action="sign-up-prompt" data-sign-in-action="multivote" data-requires-token="true" data-redirect="https://medium.com/_/vote/p/c0bee00365bd" data-action-source="placement_card_footer_grid-----c0bee00365bd----0-41----------------clap_preview" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M11.739 0l.761 2.966L13.261 0z"></path><path d="M14.815 3.776l1.84-2.551-1.43-.471z"></path><path d="M8.378 1.224l1.84 2.551L9.81.753z"></path><path d="M20.382 21.622c-1.04 1.04-2.115 1.507-3.166 1.608.168-.14.332-.29.492-.45 2.885-2.886 3.456-5.982 1.69-9.211l-1.101-1.937-.955-2.02c-.315-.676-.235-1.185.245-1.556a.836.836 0 0 1 .66-.16c.342.056.66.28.879.605l2.856 5.023c1.179 1.962 1.379 5.119-1.6 8.098m-13.29-.528l-5.02-5.02a1 1 0 0 1 .707-1.701c.255 0 .512.098.707.292l2.607 2.607a.442.442 0 0 0 .624-.624L4.11 14.04l-1.75-1.75a.998.998 0 1 1 1.41-1.413l4.154 4.156a.44.44 0 0 0 .624 0 .44.44 0 0 0 0-.624l-4.152-4.153-1.172-1.171a.998.998 0 0 1 0-1.41 1.018 1.018 0 0 1 1.41 0l1.172 1.17 4.153 4.152a.437.437 0 0 0 .624 0 .442.442 0 0 0 0-.624L6.43 8.222a.988.988 0 0 1-.291-.705.99.99 0 0 1 .29-.706 1 1 0 0 1 1.412 0l6.992 6.993a.443.443 0 0 0 .71-.501l-1.35-2.856c-.315-.676-.235-1.185.246-1.557a.85.85 0 0 1 .66-.16c.342.056.659.28.879.606L18.628 14c1.573 2.876 1.067 5.545-1.544 8.156-1.396 1.397-3.144 1.966-5.063 1.652-1.713-.286-3.463-1.248-4.928-2.714zM10.99 5.976l2.562 2.562c-.497.607-.563 1.414-.155 2.284l.265.562-4.257-4.257a.98.98 0 0 1-.117-.445c0-.267.104-.517.292-.706a1.023 1.023 0 0 1 1.41 0zm8.887 2.06c-.375-.557-.902-.916-1.486-1.011a1.738 1.738 0 0 0-1.342.332c-.376.29-.61.656-.712 1.065a2.1 2.1 0 0 0-1.095-.562 1.776 1.776 0 0 0-.992.128l-2.636-2.636a1.883 1.883 0 0 0-2.658 0 1.862 1.862 0 0 0-.478.847 1.886 1.886 0 0 0-2.671-.012 1.867 1.867 0 0 0-.503.909c-.754-.754-1.992-.754-2.703-.044a1.881 1.881 0 0 0 0 2.658c-.288.12-.605.288-.864.547a1.884 1.884 0 0 0 0 2.659l.624.622a1.879 1.879 0 0 0-.91 3.16l5.019 5.02c1.595 1.594 3.515 2.645 5.408 2.959a7.16 7.16 0 0 0 1.173.098c1.026 0 1.997-.24 2.892-.7.279.04.555.065.828.065 1.53 0 2.969-.628 4.236-1.894 3.338-3.338 3.083-6.928 1.738-9.166l-2.868-5.043z"></path></g></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M11.738 0l.762 2.966L13.262 0z"></path><path d="M16.634 1.224l-1.432-.47-.408 3.022z"></path><path d="M9.79.754l-1.431.47 1.84 2.552z"></path><path d="M22.472 13.307l-3.023-5.32c-.287-.426-.689-.705-1.123-.776a1.16 1.16 0 0 0-.911.221c-.297.231-.474.515-.535.84.017.022.036.04.053.063l2.843 5.001c1.95 3.564 1.328 6.973-1.843 10.144a8.46 8.46 0 0 1-.549.501c1.205-.156 2.328-.737 3.351-1.76 3.268-3.268 3.041-6.749 1.737-8.914"></path><path d="M12.58 9.887c-.156-.83.096-1.569.692-2.142L10.78 5.252c-.5-.504-1.378-.504-1.879 0-.178.18-.273.4-.329.63l4.008 4.005z"></path><path d="M15.812 9.04c-.218-.323-.539-.55-.88-.606a.814.814 0 0 0-.644.153c-.176.137-.713.553-.24 1.566l1.43 3.025a.539.539 0 1 1-.868.612L7.2 6.378a.986.986 0 1 0-1.395 1.395l4.401 4.403a.538.538 0 1 1-.762.762L5.046 8.54 3.802 7.295a.99.99 0 0 0-1.396 0 .981.981 0 0 0 0 1.394L3.647 9.93l4.402 4.403a.537.537 0 0 1 0 .761.535.535 0 0 1-.762 0L2.89 10.696a.992.992 0 0 0-1.399-.003.983.983 0 0 0 0 1.395l1.855 1.854 2.763 2.765a.538.538 0 0 1-.76.761l-2.765-2.764a.982.982 0 0 0-1.395 0 .989.989 0 0 0 0 1.395l5.32 5.32c3.371 3.372 6.64 4.977 10.49 1.126C19.74 19.8 20.271 17 18.62 13.982L15.812 9.04z"></path></g></svg></span></span></button></div><span class="u-relative u-background js-actionMultirecommendCount u-marginLeft5"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-disablePointerEvents u-marginLeft4" data-action="show-recommends" data-action-value="c0bee00365bd">18</button></span></div></div><div class="u-height20 u-borderRightLighter u-inlineBlock u-relative u-marginRight10 u-marginLeft12"></div><div class="buttonSet"><button class="button button--chromeless is-touchIconFadeInPulse u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="sign-up-prompt" data-sign-in-action="add-to-bookmarks" data-requires-token="true" data-redirect="https://medium.com/_/bookmark/p/c0bee00365bd" data-action-source="placement_card_footer_grid-----c0bee00365bd----0-41----------------bookmark_preview"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126a.508.508 0 0 0 .708-.03.5.5 0 0 0 .118-.285H19V6zm-6.838 9.97L7 19.636V6c0-.55.45-1 1-1h9c.55 0 1 .45 1 1v13.637l-5.162-3.668a.49.49 0 0 0-.676 0z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126c.205.183.52.17.708-.03a.5.5 0 0 0 .118-.285H19V6z"></path></svg></span></span></button></div></div></div></div></div></div><div class="col u-padding8 u-xs-size12of12 u-size4of12"><div class="uiScale uiScale-ui--small uiScale-caption--regular u-height280 u-width100pct u-backgroundWhite u-borderCardBorder u-boxShadow u-borderBox u-borderRadius4 js-trackPostPresentation" data-post-id="b6ffa82198ee" data-source="placement_card_footer_grid---------1-14" data-tracking-context="placement"><a class="link link--noUnderline u-baseColor--link" href="https://medium.com/forwardtick/how-google-collapsed-b6ffa82198ee?source=placement_card_footer_grid---------1-14" data-action-source="placement_card_footer_grid---------1-14"><div class="u-backgroundCover u-backgroundColorGrayLight u-height100 u-width100pct u-borderBottomLight u-borderRadiusTop4" style="background-image: url(&quot;https://cdn-images-1.medium.com/fit/c/400/120/1*BGD9g1PoepfxaPn1Uxyzfg.jpeg&quot;); background-position: 50% 50% !important;"></div></a><div class="u-padding15 u-borderBox u-flexColumn u-height180"><a class="link link--noUnderline u-baseColor--link u-flex1" href="https://medium.com/forwardtick/how-google-collapsed-b6ffa82198ee?source=placement_card_footer_grid---------1-14" data-action-source="placement_card_footer_grid---------1-14"><div class="uiScale uiScale-ui--regular uiScale-caption--small u-textColorNormal u-marginBottom7"><div class="u-floatRight u-textColorNormal"><span class="svgIcon svgIcon--star svgIcon--15px"><svg class="svgIcon-use" width="15" height="15"><path d="M7.438 2.324c.034-.099.09-.099.123 0l1.2 3.53a.29.29 0 0 0 .26.19h3.884c.11 0 .127.049.038.111L9.8 8.327a.271.271 0 0 0-.099.291l1.2 3.53c.034.1-.011.131-.098.069l-3.142-2.18a.303.303 0 0 0-.32 0l-3.145 2.182c-.087.06-.132.03-.099-.068l1.2-3.53a.271.271 0 0 0-.098-.292L2.056 6.146c-.087-.06-.071-.112.038-.112h3.884a.29.29 0 0 0 .26-.19l1.2-3.52z"></path></svg></span></div><div class="u-noWrapWithEllipsis u-marginRight40">Top on Medium</div></div><div class="ui-h3 ui-clamp2 u-textColorDarkest u-contentSansBold u-fontSize24 u-maxHeight2LineHeightTighter u-lineClamp2 u-textOverflowEllipsis u-letterSpacingTight u-paddingBottom2">This Is How Google Will Collapse</div></a><div class="u-paddingBottom10 u-flex0 u-flexCenter"><div class="u-flex1 u-minWidth0 u-marginRight10"><div class="u-flexCenter"><div class="postMetaInline-avatar u-flex0"><a class="link u-baseColor--link avatar" href="https://medium.com/@dacoja" data-action="show-user-card" data-action-value="6502e16a569a" data-action-type="hover" data-user-id="6502e16a569a" dir="auto"><div class="u-relative u-inlineBlock u-flex0"><img src="https://cdn-images-1.medium.com/fit/c/36/36/1*XDy5OzyjY4cHWYxsFcJX_Q.png" class="avatar-image u-size36x36 u-xs-size32x32" alt="Go to the profile of Daniel Colin James"><div class="avatar-halo u-absolute u-textColorGreenNormal svgIcon" style="width: calc(100% + 10px); height: calc(100% + 10px); top:-5px; left:-5px"><svg viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M3.44615311,11.6601601 C6.57294867,5.47967718 12.9131553,1.5 19.9642857,1.5 C27.0154162,1.5 33.3556228,5.47967718 36.4824183,11.6601601 L37.3747245,11.2087295 C34.0793076,4.69494641 27.3961457,0.5 19.9642857,0.5 C12.5324257,0.5 5.84926381,4.69494641 2.55384689,11.2087295 L3.44615311,11.6601601 Z"></path><path d="M36.4824183,28.2564276 C33.3556228,34.4369105 27.0154162,38.4165876 19.9642857,38.4165876 C12.9131553,38.4165876 6.57294867,34.4369105 3.44615311,28.2564276 L2.55384689,28.7078582 C5.84926381,35.2216412 12.5324257,39.4165876 19.9642857,39.4165876 C27.3961457,39.4165876 34.0793076,35.2216412 37.3747245,28.7078582 L36.4824183,28.2564276 Z"></path></svg></div></div></a></div><div class="postMetaInline postMetaInline-authorLockup ui-captionStrong u-flex1 u-noWrapWithEllipsis"><a class="ds-link ds-link--styleSubtle link link--darken link--darker" href="https://medium.com/@dacoja?source=placement_card_footer_grid---------1-14" data-action="show-user-card" data-action-source="placement_card_footer_grid---------1-14" data-action-value="6502e16a569a" data-action-type="hover" data-user-id="6502e16a569a" dir="auto">Daniel Colin James</a><div class="ui-caption u-fontSize12 u-baseColor--textNormal u-textColorNormal js-postMetaInlineSupplemental"><a class="link link--darken" href="https://medium.com/forwardtick/how-google-collapsed-b6ffa82198ee?source=placement_card_footer_grid---------1-14" data-action="open-post" data-action-value="https://medium.com/forwardtick/how-google-collapsed-b6ffa82198ee?source=placement_card_footer_grid---------1-14" data-action-source="preview-listing"><time datetime="2017-04-24T19:14:43.112Z">Apr 24, 2017</time></a><span class="middotDivider u-fontSize12"></span><span class="readingTime" title="9 min read"></span><span class="u-paddingLeft4"><span class="svgIcon svgIcon--star svgIcon--15px"><svg class="svgIcon-use" width="15" height="15"><path d="M7.438 2.324c.034-.099.09-.099.123 0l1.2 3.53a.29.29 0 0 0 .26.19h3.884c.11 0 .127.049.038.111L9.8 8.327a.271.271 0 0 0-.099.291l1.2 3.53c.034.1-.011.131-.098.069l-3.142-2.18a.303.303 0 0 0-.32 0l-3.145 2.182c-.087.06-.132.03-.099-.068l1.2-3.53a.271.271 0 0 0-.098-.292L2.056 6.146c-.087-.06-.071-.112.038-.112h3.884a.29.29 0 0 0 .26-.19l1.2-3.52z"></path></svg></span></span></div></div></div></div><div class="u-flex0 u-flexCenter"><div class="buttonSet"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="b6ffa82198ee" data-is-label-padded="true" data-source="placement_card_footer_grid-----b6ffa82198ee----1-14----------------clap_preview"><div class="u-relative u-foreground"><button class="button button--primary button--chromeless u-accentColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--darker" data-action="sign-up-prompt" data-sign-in-action="multivote" data-requires-token="true" data-redirect="https://medium.com/_/vote/p/b6ffa82198ee" data-action-source="placement_card_footer_grid-----b6ffa82198ee----1-14----------------clap_preview" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M11.739 0l.761 2.966L13.261 0z"></path><path d="M14.815 3.776l1.84-2.551-1.43-.471z"></path><path d="M8.378 1.224l1.84 2.551L9.81.753z"></path><path d="M20.382 21.622c-1.04 1.04-2.115 1.507-3.166 1.608.168-.14.332-.29.492-.45 2.885-2.886 3.456-5.982 1.69-9.211l-1.101-1.937-.955-2.02c-.315-.676-.235-1.185.245-1.556a.836.836 0 0 1 .66-.16c.342.056.66.28.879.605l2.856 5.023c1.179 1.962 1.379 5.119-1.6 8.098m-13.29-.528l-5.02-5.02a1 1 0 0 1 .707-1.701c.255 0 .512.098.707.292l2.607 2.607a.442.442 0 0 0 .624-.624L4.11 14.04l-1.75-1.75a.998.998 0 1 1 1.41-1.413l4.154 4.156a.44.44 0 0 0 .624 0 .44.44 0 0 0 0-.624l-4.152-4.153-1.172-1.171a.998.998 0 0 1 0-1.41 1.018 1.018 0 0 1 1.41 0l1.172 1.17 4.153 4.152a.437.437 0 0 0 .624 0 .442.442 0 0 0 0-.624L6.43 8.222a.988.988 0 0 1-.291-.705.99.99 0 0 1 .29-.706 1 1 0 0 1 1.412 0l6.992 6.993a.443.443 0 0 0 .71-.501l-1.35-2.856c-.315-.676-.235-1.185.246-1.557a.85.85 0 0 1 .66-.16c.342.056.659.28.879.606L18.628 14c1.573 2.876 1.067 5.545-1.544 8.156-1.396 1.397-3.144 1.966-5.063 1.652-1.713-.286-3.463-1.248-4.928-2.714zM10.99 5.976l2.562 2.562c-.497.607-.563 1.414-.155 2.284l.265.562-4.257-4.257a.98.98 0 0 1-.117-.445c0-.267.104-.517.292-.706a1.023 1.023 0 0 1 1.41 0zm8.887 2.06c-.375-.557-.902-.916-1.486-1.011a1.738 1.738 0 0 0-1.342.332c-.376.29-.61.656-.712 1.065a2.1 2.1 0 0 0-1.095-.562 1.776 1.776 0 0 0-.992.128l-2.636-2.636a1.883 1.883 0 0 0-2.658 0 1.862 1.862 0 0 0-.478.847 1.886 1.886 0 0 0-2.671-.012 1.867 1.867 0 0 0-.503.909c-.754-.754-1.992-.754-2.703-.044a1.881 1.881 0 0 0 0 2.658c-.288.12-.605.288-.864.547a1.884 1.884 0 0 0 0 2.659l.624.622a1.879 1.879 0 0 0-.91 3.16l5.019 5.02c1.595 1.594 3.515 2.645 5.408 2.959a7.16 7.16 0 0 0 1.173.098c1.026 0 1.997-.24 2.892-.7.279.04.555.065.828.065 1.53 0 2.969-.628 4.236-1.894 3.338-3.338 3.083-6.928 1.738-9.166l-2.868-5.043z"></path></g></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M11.738 0l.762 2.966L13.262 0z"></path><path d="M16.634 1.224l-1.432-.47-.408 3.022z"></path><path d="M9.79.754l-1.431.47 1.84 2.552z"></path><path d="M22.472 13.307l-3.023-5.32c-.287-.426-.689-.705-1.123-.776a1.16 1.16 0 0 0-.911.221c-.297.231-.474.515-.535.84.017.022.036.04.053.063l2.843 5.001c1.95 3.564 1.328 6.973-1.843 10.144a8.46 8.46 0 0 1-.549.501c1.205-.156 2.328-.737 3.351-1.76 3.268-3.268 3.041-6.749 1.737-8.914"></path><path d="M12.58 9.887c-.156-.83.096-1.569.692-2.142L10.78 5.252c-.5-.504-1.378-.504-1.879 0-.178.18-.273.4-.329.63l4.008 4.005z"></path><path d="M15.812 9.04c-.218-.323-.539-.55-.88-.606a.814.814 0 0 0-.644.153c-.176.137-.713.553-.24 1.566l1.43 3.025a.539.539 0 1 1-.868.612L7.2 6.378a.986.986 0 1 0-1.395 1.395l4.401 4.403a.538.538 0 1 1-.762.762L5.046 8.54 3.802 7.295a.99.99 0 0 0-1.396 0 .981.981 0 0 0 0 1.394L3.647 9.93l4.402 4.403a.537.537 0 0 1 0 .761.535.535 0 0 1-.762 0L2.89 10.696a.992.992 0 0 0-1.399-.003.983.983 0 0 0 0 1.395l1.855 1.854 2.763 2.765a.538.538 0 0 1-.76.761l-2.765-2.764a.982.982 0 0 0-1.395 0 .989.989 0 0 0 0 1.395l5.32 5.32c3.371 3.372 6.64 4.977 10.49 1.126C19.74 19.8 20.271 17 18.62 13.982L15.812 9.04z"></path></g></svg></span></span></button></div><span class="u-relative u-background js-actionMultirecommendCount u-marginLeft5"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-disablePointerEvents u-marginLeft4" data-action="show-recommends" data-action-value="b6ffa82198ee">86K</button></span></div></div><div class="u-height20 u-borderRightLighter u-inlineBlock u-relative u-marginRight10 u-marginLeft12"></div><div class="buttonSet"><button class="button button--chromeless is-touchIconFadeInPulse u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="sign-up-prompt" data-sign-in-action="add-to-bookmarks" data-requires-token="true" data-redirect="https://medium.com/_/bookmark/p/b6ffa82198ee" data-action-source="placement_card_footer_grid-----b6ffa82198ee----1-14----------------bookmark_preview"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126a.508.508 0 0 0 .708-.03.5.5 0 0 0 .118-.285H19V6zm-6.838 9.97L7 19.636V6c0-.55.45-1 1-1h9c.55 0 1 .45 1 1v13.637l-5.162-3.668a.49.49 0 0 0-.676 0z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126c.205.183.52.17.708-.03a.5.5 0 0 0 .118-.285H19V6z"></path></svg></span></span></button></div></div></div></div></div></div><div class="col u-padding8 u-xs-size12of12 u-size4of12"><div class="uiScale uiScale-ui--small uiScale-caption--regular u-height280 u-width100pct u-backgroundWhite u-borderCardBorder u-boxShadow u-borderBox u-borderRadius4 js-trackPostPresentation" data-post-id="e4510b6d7975" data-source="placement_card_footer_grid---------2-14" data-tracking-context="placement"><a class="link link--noUnderline u-baseColor--link" href="https://onezero.medium.com/whats-on-your-home-screen-erica-joy-baker-e4510b6d7975?source=placement_card_footer_grid---------2-14" data-action-source="placement_card_footer_grid---------2-14"><div class="u-backgroundCover u-backgroundColorGrayLight u-height100 u-width100pct u-borderBottomLight u-borderRadiusTop4" style="background-image: url(&quot;https://cdn-images-1.medium.com/focal/400/120/52/36/1*202HQdP0MHQMLL17O1ryXw.png&quot;); background-position: 52% 36% !important;"></div></a><div class="u-padding15 u-borderBox u-flexColumn u-height180"><a class="link link--noUnderline u-baseColor--link u-flex1" href="https://onezero.medium.com/whats-on-your-home-screen-erica-joy-baker-e4510b6d7975?source=placement_card_footer_grid---------2-14" data-action-source="placement_card_footer_grid---------2-14"><div class="uiScale uiScale-ui--regular uiScale-caption--small u-textColorNormal u-marginBottom7"><div class="u-floatRight u-textColorNormal"><span class="svgIcon svgIcon--star svgIcon--15px"><svg class="svgIcon-use" width="15" height="15"><path d="M7.438 2.324c.034-.099.09-.099.123 0l1.2 3.53a.29.29 0 0 0 .26.19h3.884c.11 0 .127.049.038.111L9.8 8.327a.271.271 0 0 0-.099.291l1.2 3.53c.034.1-.011.131-.098.069l-3.142-2.18a.303.303 0 0 0-.32 0l-3.145 2.182c-.087.06-.132.03-.099-.068l1.2-3.53a.271.271 0 0 0-.098-.292L2.056 6.146c-.087-.06-.071-.112.038-.112h3.884a.29.29 0 0 0 .26-.19l1.2-3.52z"></path></svg></span></div><div class="u-noWrapWithEllipsis u-marginRight40">Top on Medium</div></div><div class="ui-h3 ui-clamp2 u-textColorDarkest u-contentSansBold u-fontSize24 u-maxHeight2LineHeightTighter u-lineClamp2 u-textOverflowEllipsis u-letterSpacingTight u-paddingBottom2">What‚Äôs on Your Home Screen, Erica Joy Baker?</div></a><div class="u-paddingBottom10 u-flex0 u-flexCenter"><div class="u-flex1 u-minWidth0 u-marginRight10"><div class="u-flexCenter"><div class="postMetaInline-avatar u-flex0"><a class="link u-baseColor--link avatar" href="https://onezero.medium.com/@dlberes" data-action="show-user-card" data-action-value="1ccc714607f0" data-action-type="hover" data-user-id="1ccc714607f0" data-collection-slug="one-zero" dir="auto"><div class="u-relative u-inlineBlock u-flex0"><img src="https://cdn-images-1.medium.com/fit/c/36/36/1*lLRGoD_Y3uJ78dOHSHrhMg.jpeg" class="avatar-image u-size36x36 u-xs-size32x32" alt="Go to the profile of Damon Beres"><div class="avatar-halo u-absolute u-textColorGreenNormal svgIcon" style="width: calc(100% + 10px); height: calc(100% + 10px); top:-5px; left:-5px"><svg viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M3.44615311,11.6601601 C6.57294867,5.47967718 12.9131553,1.5 19.9642857,1.5 C27.0154162,1.5 33.3556228,5.47967718 36.4824183,11.6601601 L37.3747245,11.2087295 C34.0793076,4.69494641 27.3961457,0.5 19.9642857,0.5 C12.5324257,0.5 5.84926381,4.69494641 2.55384689,11.2087295 L3.44615311,11.6601601 Z"></path><path d="M36.4824183,28.2564276 C33.3556228,34.4369105 27.0154162,38.4165876 19.9642857,38.4165876 C12.9131553,38.4165876 6.57294867,34.4369105 3.44615311,28.2564276 L2.55384689,28.7078582 C5.84926381,35.2216412 12.5324257,39.4165876 19.9642857,39.4165876 C27.3961457,39.4165876 34.0793076,35.2216412 37.3747245,28.7078582 L36.4824183,28.2564276 Z"></path></svg></div></div></a></div><div class="postMetaInline postMetaInline-authorLockup ui-captionStrong u-flex1 u-noWrapWithEllipsis"><a class="ds-link ds-link--styleSubtle link link--darken link--darker" href="https://onezero.medium.com/@dlberes?source=placement_card_footer_grid---------2-14" data-action="show-user-card" data-action-source="placement_card_footer_grid---------2-14" data-action-value="1ccc714607f0" data-action-type="hover" data-user-id="1ccc714607f0" data-collection-slug="one-zero" dir="auto">Damon Beres</a><div class="ui-caption u-fontSize12 u-baseColor--textNormal u-textColorNormal js-postMetaInlineSupplemental"><a class="link link--darken" href="https://onezero.medium.com/whats-on-your-home-screen-erica-joy-baker-e4510b6d7975?source=placement_card_footer_grid---------2-14" data-action="open-post" data-action-value="https://onezero.medium.com/whats-on-your-home-screen-erica-joy-baker-e4510b6d7975?source=placement_card_footer_grid---------2-14" data-action-source="preview-listing"><time datetime="2019-03-15T15:26:28.206Z">Mar 15</time></a><span class="middotDivider u-fontSize12"></span><span class="readingTime" title="7 min read"></span><span class="u-paddingLeft4"><span class="svgIcon svgIcon--star svgIcon--15px"><svg class="svgIcon-use" width="15" height="15"><path d="M7.438 2.324c.034-.099.09-.099.123 0l1.2 3.53a.29.29 0 0 0 .26.19h3.884c.11 0 .127.049.038.111L9.8 8.327a.271.271 0 0 0-.099.291l1.2 3.53c.034.1-.011.131-.098.069l-3.142-2.18a.303.303 0 0 0-.32 0l-3.145 2.182c-.087.06-.132.03-.099-.068l1.2-3.53a.271.271 0 0 0-.098-.292L2.056 6.146c-.087-.06-.071-.112.038-.112h3.884a.29.29 0 0 0 .26-.19l1.2-3.52z"></path></svg></span></span></div></div></div></div><div class="u-flex0 u-flexCenter"><div class="buttonSet"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="e4510b6d7975" data-is-label-padded="true" data-source="placement_card_footer_grid-----e4510b6d7975----2-14----------------clap_preview"><div class="u-relative u-foreground"><button class="button button--primary button--chromeless u-accentColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--darker" data-action="sign-up-prompt" data-sign-in-action="multivote" data-requires-token="true" data-redirect="https://medium.com/_/vote/p/e4510b6d7975" data-action-source="placement_card_footer_grid-----e4510b6d7975----2-14----------------clap_preview" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M11.739 0l.761 2.966L13.261 0z"></path><path d="M14.815 3.776l1.84-2.551-1.43-.471z"></path><path d="M8.378 1.224l1.84 2.551L9.81.753z"></path><path d="M20.382 21.622c-1.04 1.04-2.115 1.507-3.166 1.608.168-.14.332-.29.492-.45 2.885-2.886 3.456-5.982 1.69-9.211l-1.101-1.937-.955-2.02c-.315-.676-.235-1.185.245-1.556a.836.836 0 0 1 .66-.16c.342.056.66.28.879.605l2.856 5.023c1.179 1.962 1.379 5.119-1.6 8.098m-13.29-.528l-5.02-5.02a1 1 0 0 1 .707-1.701c.255 0 .512.098.707.292l2.607 2.607a.442.442 0 0 0 .624-.624L4.11 14.04l-1.75-1.75a.998.998 0 1 1 1.41-1.413l4.154 4.156a.44.44 0 0 0 .624 0 .44.44 0 0 0 0-.624l-4.152-4.153-1.172-1.171a.998.998 0 0 1 0-1.41 1.018 1.018 0 0 1 1.41 0l1.172 1.17 4.153 4.152a.437.437 0 0 0 .624 0 .442.442 0 0 0 0-.624L6.43 8.222a.988.988 0 0 1-.291-.705.99.99 0 0 1 .29-.706 1 1 0 0 1 1.412 0l6.992 6.993a.443.443 0 0 0 .71-.501l-1.35-2.856c-.315-.676-.235-1.185.246-1.557a.85.85 0 0 1 .66-.16c.342.056.659.28.879.606L18.628 14c1.573 2.876 1.067 5.545-1.544 8.156-1.396 1.397-3.144 1.966-5.063 1.652-1.713-.286-3.463-1.248-4.928-2.714zM10.99 5.976l2.562 2.562c-.497.607-.563 1.414-.155 2.284l.265.562-4.257-4.257a.98.98 0 0 1-.117-.445c0-.267.104-.517.292-.706a1.023 1.023 0 0 1 1.41 0zm8.887 2.06c-.375-.557-.902-.916-1.486-1.011a1.738 1.738 0 0 0-1.342.332c-.376.29-.61.656-.712 1.065a2.1 2.1 0 0 0-1.095-.562 1.776 1.776 0 0 0-.992.128l-2.636-2.636a1.883 1.883 0 0 0-2.658 0 1.862 1.862 0 0 0-.478.847 1.886 1.886 0 0 0-2.671-.012 1.867 1.867 0 0 0-.503.909c-.754-.754-1.992-.754-2.703-.044a1.881 1.881 0 0 0 0 2.658c-.288.12-.605.288-.864.547a1.884 1.884 0 0 0 0 2.659l.624.622a1.879 1.879 0 0 0-.91 3.16l5.019 5.02c1.595 1.594 3.515 2.645 5.408 2.959a7.16 7.16 0 0 0 1.173.098c1.026 0 1.997-.24 2.892-.7.279.04.555.065.828.065 1.53 0 2.969-.628 4.236-1.894 3.338-3.338 3.083-6.928 1.738-9.166l-2.868-5.043z"></path></g></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M11.738 0l.762 2.966L13.262 0z"></path><path d="M16.634 1.224l-1.432-.47-.408 3.022z"></path><path d="M9.79.754l-1.431.47 1.84 2.552z"></path><path d="M22.472 13.307l-3.023-5.32c-.287-.426-.689-.705-1.123-.776a1.16 1.16 0 0 0-.911.221c-.297.231-.474.515-.535.84.017.022.036.04.053.063l2.843 5.001c1.95 3.564 1.328 6.973-1.843 10.144a8.46 8.46 0 0 1-.549.501c1.205-.156 2.328-.737 3.351-1.76 3.268-3.268 3.041-6.749 1.737-8.914"></path><path d="M12.58 9.887c-.156-.83.096-1.569.692-2.142L10.78 5.252c-.5-.504-1.378-.504-1.879 0-.178.18-.273.4-.329.63l4.008 4.005z"></path><path d="M15.812 9.04c-.218-.323-.539-.55-.88-.606a.814.814 0 0 0-.644.153c-.176.137-.713.553-.24 1.566l1.43 3.025a.539.539 0 1 1-.868.612L7.2 6.378a.986.986 0 1 0-1.395 1.395l4.401 4.403a.538.538 0 1 1-.762.762L5.046 8.54 3.802 7.295a.99.99 0 0 0-1.396 0 .981.981 0 0 0 0 1.394L3.647 9.93l4.402 4.403a.537.537 0 0 1 0 .761.535.535 0 0 1-.762 0L2.89 10.696a.992.992 0 0 0-1.399-.003.983.983 0 0 0 0 1.395l1.855 1.854 2.763 2.765a.538.538 0 0 1-.76.761l-2.765-2.764a.982.982 0 0 0-1.395 0 .989.989 0 0 0 0 1.395l5.32 5.32c3.371 3.372 6.64 4.977 10.49 1.126C19.74 19.8 20.271 17 18.62 13.982L15.812 9.04z"></path></g></svg></span></span></button></div><span class="u-relative u-background js-actionMultirecommendCount u-marginLeft5"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-disablePointerEvents u-marginLeft4" data-action="show-recommends" data-action-value="e4510b6d7975">809</button></span></div></div><div class="u-height20 u-borderRightLighter u-inlineBlock u-relative u-marginRight10 u-marginLeft12"></div><div class="buttonSet"><button class="button button--chromeless is-touchIconFadeInPulse u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="sign-up-prompt" data-sign-in-action="add-to-bookmarks" data-requires-token="true" data-redirect="https://medium.com/_/bookmark/p/e4510b6d7975" data-action-source="placement_card_footer_grid-----e4510b6d7975----2-14----------------bookmark_preview"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126a.508.508 0 0 0 .708-.03.5.5 0 0 0 .118-.285H19V6zm-6.838 9.97L7 19.636V6c0-.55.45-1 1-1h9c.55 0 1 .45 1 1v13.637l-5.162-3.668a.49.49 0 0 0-.676 0z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126c.205.183.52.17.708-.03a.5.5 0 0 0 .118-.285H19V6z"></path></svg></span></span></button></div></div></div></div></div></div></div></div></div></div><div class="u-padding0 u-clearfix u-backgroundGrayLightest u-print-hide supplementalPostContent js-responsesWrapper" data-action-scope="_actionscope_5"><div class="container u-maxWidth740"><div class="responsesStreamWrapper u-maxWidth640 u-hide js-responsesStreamWrapper"><div class="container responsesStream-title u-paddingTop15"><div class="row"><header class="heading"><div class="u-clearfix"><div class="heading-content u-floatLeft"><span class="heading-title heading-title--semibold">Responses</span></div></div></header></div></div><div class="responsesStream js-responsesStream"></div><div class="container u-hide js-showOtherResponses"><div class="row"><button class="button button--primary button--withChrome u-accentColor--buttonNormal responsesStream-showOtherResponses cardChromeless u-width100pct u-marginVertical20 u-heightAuto" data-action="show-other-responses">Show all responses</button></div></div><div class="responsesStream js-responsesStreamOther"></div></div></div></div><div class="supplementalPostContent js-heroPromo"></div></footer></article></main><aside class="u-marginAuto u-maxWidth1032 js-postLeftSidebar"><div class="u-foreground u-top0 u-transition--fadeOut300 u-fixed u-sm-hide js-postShareWidget" data-scroll="fixed" style="transform: translateY(150px);"><div class="u-breakWord u-md-hide u-width131"><div class="u-width131 collection-title u-fontWeightBold u-fontSize18 u-lineHeightTight"><a href="https://ai-alignment.com?source=logo-lo_JuU2p2EvGepj">AI Alignment</a></div><div class="u-width131 u-multiline-clamp u-textColorNormal u-fontSize14 u-lineHeightTight u-paddingTop3">Aligning AI systems with human interests.</div><div class="u-paddingTop15 u-paddingBottom30 u-borderBottomLight u-marginBottom30"><button class="button button--primary button--small u-noUserSelect button--withChrome u-accentColor--buttonNormal js-relationshipButton" data-action="sign-up-prompt" data-sign-in-action="toggle-follow-collection" data-requires-token="true" data-redirect="https://medium.com/_/subscribe/collection/ai-control" data-action-source="post_sidebar----624d886c4aa4----------------------post_sidebar" data-collection-id="624d886c4aa4"><span class="button-label  js-buttonLabel">Follow</span></button></div></div><ul><li class="u-marginVertical10"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="8218fa8a871f" data-is-icon-29px="true" data-has-recommend-list="true" data-source="post_share_widget-----8218fa8a871f---------------------clap_sidebar"><div class="u-relative u-foreground"><button class="button button--primary button--large button--chromeless u-accentColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--darker" data-action="sign-up-prompt" data-sign-in-action="multivote" data-requires-token="true" data-redirect="https://medium.com/_/vote/p/8218fa8a871f" data-action-source="post_share_widget-----8218fa8a871f---------------------clap_sidebar" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><g fill-rule="evenodd"><path d="M13.739 1l.761 2.966L15.261 1z"></path><path d="M16.815 4.776l1.84-2.551-1.43-.471z"></path><path d="M10.378 2.224l1.84 2.551-.408-3.022z"></path><path d="M22.382 22.622c-1.04 1.04-2.115 1.507-3.166 1.608.168-.14.332-.29.492-.45 2.885-2.886 3.456-5.982 1.69-9.211l-1.101-1.937-.955-2.02c-.315-.676-.235-1.185.245-1.556a.836.836 0 0 1 .66-.16c.342.056.66.28.879.605l2.856 5.023c1.179 1.962 1.379 5.119-1.6 8.098m-13.29-.528l-5.02-5.02a1 1 0 0 1 .707-1.701c.255 0 .512.098.707.292l2.607 2.607a.442.442 0 0 0 .624-.624L6.11 15.04l-1.75-1.75a.998.998 0 1 1 1.41-1.413l4.154 4.156a.44.44 0 0 0 .624 0 .44.44 0 0 0 0-.624l-4.152-4.153-1.172-1.171a.998.998 0 0 1 0-1.41 1.018 1.018 0 0 1 1.41 0l1.172 1.17 4.153 4.152a.437.437 0 0 0 .624 0 .442.442 0 0 0 0-.624L8.43 9.222a.988.988 0 0 1-.291-.705.99.99 0 0 1 .29-.706 1 1 0 0 1 1.412 0l6.992 6.993a.443.443 0 0 0 .71-.501l-1.35-2.856c-.315-.676-.235-1.185.246-1.557a.85.85 0 0 1 .66-.16c.342.056.659.28.879.606L20.628 15c1.573 2.876 1.067 5.545-1.544 8.156-1.396 1.397-3.144 1.966-5.063 1.652-1.713-.286-3.463-1.248-4.928-2.714zM12.99 6.976l2.562 2.562c-.497.607-.563 1.414-.155 2.284l.265.562-4.257-4.257a.98.98 0 0 1-.117-.445c0-.267.104-.517.292-.706a1.023 1.023 0 0 1 1.41 0zm8.887 2.06c-.375-.557-.902-.916-1.486-1.011a1.738 1.738 0 0 0-1.342.332c-.376.29-.61.656-.712 1.065a2.1 2.1 0 0 0-1.095-.562 1.776 1.776 0 0 0-.992.128l-2.636-2.636a1.883 1.883 0 0 0-2.658 0 1.862 1.862 0 0 0-.478.847 1.886 1.886 0 0 0-2.671-.012 1.867 1.867 0 0 0-.503.909c-.754-.754-1.992-.754-2.703-.044a1.881 1.881 0 0 0 0 2.658c-.288.12-.605.288-.864.547a1.884 1.884 0 0 0 0 2.659l.624.622a1.879 1.879 0 0 0-.91 3.16l5.019 5.02c1.595 1.594 3.515 2.645 5.408 2.959a7.16 7.16 0 0 0 1.173.098c1.026 0 1.997-.24 2.892-.7.279.04.555.065.828.065 1.53 0 2.969-.628 4.236-1.894 3.338-3.338 3.083-6.928 1.738-9.166l-2.868-5.043z"></path></g></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><g fill-rule="evenodd"><path d="M13.738 1l.762 2.966L15.262 1z"></path><path d="M18.634 2.224l-1.432-.47-.408 3.022z"></path><path d="M11.79 1.754l-1.431.47 1.84 2.552z"></path><path d="M24.472 14.307l-3.023-5.32c-.287-.426-.689-.705-1.123-.776a1.16 1.16 0 0 0-.911.221c-.297.231-.474.515-.535.84.017.022.036.04.053.063l2.843 5.001c1.95 3.564 1.328 6.973-1.843 10.144a8.46 8.46 0 0 1-.549.501c1.205-.156 2.328-.737 3.351-1.76 3.268-3.268 3.041-6.749 1.737-8.914"></path><path d="M14.58 10.887c-.156-.83.096-1.569.692-2.142L12.78 6.252c-.5-.504-1.378-.504-1.879 0-.178.18-.273.4-.329.63l4.008 4.005z"></path><path d="M17.812 10.04c-.218-.323-.539-.55-.88-.606a.814.814 0 0 0-.644.153c-.176.137-.713.553-.24 1.566l1.43 3.025a.539.539 0 1 1-.868.612L9.2 7.378a.986.986 0 1 0-1.395 1.395l4.401 4.403a.538.538 0 1 1-.762.762L7.046 9.54 5.802 8.295a.99.99 0 0 0-1.396 0 .981.981 0 0 0 0 1.394l1.241 1.241 4.402 4.403a.537.537 0 0 1 0 .761.535.535 0 0 1-.762 0L4.89 11.696a.992.992 0 0 0-1.399-.003.983.983 0 0 0 0 1.395l1.855 1.854 2.763 2.765a.538.538 0 0 1-.76.761l-2.765-2.764a.982.982 0 0 0-1.395 0 .989.989 0 0 0 0 1.395l5.32 5.32c3.371 3.372 6.64 4.977 10.49 1.126C21.74 20.8 22.271 18 20.62 14.982l-2.809-4.942z"></path></g></svg></span></span></button></div><span class="u-relative u-background js-actionMultirecommendCount u-marginLeft5"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton" data-action="show-recommends" data-action-value="8218fa8a871f">4</button></span></div></li><li class="u-marginVertical10 u-marginLeft3"><button class="button button--large button--dark button--chromeless is-touchIconFadeInPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="sign-up-prompt" data-sign-in-action="add-to-bookmarks" data-requires-token="true" data-redirect="https://medium.com/_/bookmark/p/8218fa8a871f" data-action-source="post_share_widget-----8218fa8a871f---------------------bookmark_sidebar"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M19.385 4h-9.77A2.623 2.623 0 0 0 7 6.615V23.01a1.022 1.022 0 0 0 1.595.847l5.905-4.004 5.905 4.004A1.022 1.022 0 0 0 22 23.011V6.62A2.625 2.625 0 0 0 19.385 4zM21 23l-5.91-3.955-.148-.107a.751.751 0 0 0-.884 0l-.147.107L8 23V6.615C8 5.725 8.725 5 9.615 5h9.77C20.275 5 21 5.725 21 6.615V23z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M19.385 4h-9.77A2.623 2.623 0 0 0 7 6.615V23.01a1.022 1.022 0 0 0 1.595.847l5.905-4.004 5.905 4.004A1.022 1.022 0 0 0 22 23.011V6.62A2.625 2.625 0 0 0 19.385 4z" fill-rule="evenodd"></path></svg></span></span></button></li><li class="u-marginVertical10 u-marginLeft3"><a class="button button--dark button--chromeless u-baseColor--buttonDark button--withIcon button--withSvgIcon button--dark button--chromeless" href="https://medium.com/p/8218fa8a871f/share/twitter" title="Share on Twitter" aria-label="Share on Twitter" target="_blank" data-action-source="post_share_widget"><span class="button-defaultState"><span class="svgIcon svgIcon--twitterFilled svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M22.053 7.54a4.474 4.474 0 0 0-3.31-1.455 4.526 4.526 0 0 0-4.526 4.524c0 .35.04.7.082 1.05a12.9 12.9 0 0 1-9.3-4.77c-.39.69-.61 1.46-.65 2.26.03 1.6.83 2.99 2.02 3.79-.72-.02-1.41-.22-2.02-.57-.01.02-.01.04 0 .08-.01 2.17 1.55 4 3.63 4.44-.39.08-.79.13-1.21.16-.28-.03-.57-.05-.81-.08.54 1.77 2.21 3.08 4.2 3.15a9.564 9.564 0 0 1-5.66 1.94c-.34-.03-.7-.06-1.05-.08 2 1.27 4.38 2.02 6.94 2.02 8.31 0 12.86-6.9 12.84-12.85.02-.24.01-.43 0-.65.89-.62 1.65-1.42 2.26-2.34-.82.38-1.69.62-2.59.72a4.37 4.37 0 0 0 1.94-2.51c-.84.53-1.81.9-2.83 1.13z"></path></svg></span></span></a></li><li class="u-marginVertical10 u-marginLeft3"><a class="button button--dark button--chromeless u-baseColor--buttonDark button--withIcon button--withSvgIcon button--dark button--chromeless" href="https://medium.com/p/8218fa8a871f/share/facebook" title="Share on Facebook" aria-label="Share on Facebook" target="_blank" data-action-source="post_share_widget"><span class="button-defaultState"><span class="svgIcon svgIcon--facebookSquare svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M23.209 5H5.792A.792.792 0 0 0 5 5.791V23.21c0 .437.354.791.792.791h9.303v-7.125H12.72v-2.968h2.375v-2.375c0-2.455 1.553-3.662 3.741-3.662 1.049 0 1.95.078 2.213.112v2.565h-1.517c-1.192 0-1.469.567-1.469 1.397v1.963h2.969l-.594 2.968h-2.375L18.11 24h5.099a.791.791 0 0 0 .791-.791V5.79a.791.791 0 0 0-.791-.79"></path></svg></span></span></a></li></ul></div></aside><div class="u-fixed u-bottom0 u-width100pct u-backgroundWhite u-boxShadowTop u-borderBox u-paddingTop10 u-paddingBottom10 u-zIndexMetabar u-xs-hide js-stickyFooter"><div class="u-maxWidth700 u-marginAuto u-flexCenter"><div class="u-fontSize16 u-flex1 u-flexCenter"><div class="u-flex0 u-inlineBlock u-paddingRight20"><a class="link u-baseColor--link avatar avatar--roundedRectangle" href="https://ai-alignment.com" title="Go to AI Alignment" aria-label="Go to AI Alignment" data-collection-slug="ai-control"><img src="https://cdn-images-1.medium.com/fit/c/40/40/1*N56Qc5-aHTcfGff0scntKQ.png" class="avatar-image avatar-image--smaller" alt="AI Alignment"></a></div><div class="u-flex1 u-inlineBlock">Never miss a story from<strong> AI Alignment</strong>, when you sign up for Medium. <a class="link u-baseColor--link link--accent u-accentColor--textNormal u-accentColor--textDarken" href="https://medium.com/@Medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg" data-action-source="sticky_footer">Learn more</a></div></div><div class="u-marginLeft50"><button class="button button--primary button--dark is-active u-noUserSelect button--withChrome u-accentColor--buttonDark u-uiTextSemibold u-textUppercase u-fontSize12 button--followCollection js-followCollectionButton" data-action="sign-up-prompt" data-sign-in-action="toggle-subscribe-collection" data-requires-token="true" data-redirect="https://medium.com/_/subscribe/collection/ai-control" data-action-source="sticky_footer----624d886c4aa4----------------------follow_metabar"><span class="button-label  button-defaultState js-buttonLabel">Get updates</span><span class="button-label button-activeState">Get updates</span></button></div></div></div><style class="js-collectionStyle">
.u-accentColor--borderLight {border-color: #02B875 !important;}
.u-accentColor--borderNormal {border-color: #02B875 !important;}
.u-accentColor--borderDark {border-color: #1C9963 !important;}
.u-accentColor--iconLight .svgIcon,.u-accentColor--iconLight.svgIcon {fill: #02B875 !important;}
.u-accentColor--iconNormal .svgIcon,.u-accentColor--iconNormal.svgIcon {fill: #02B875 !important;}
.u-accentColor--iconDark .svgIcon,.u-accentColor--iconDark.svgIcon {fill: #1C9963 !important;}
.u-accentColor--textNormal {color: #1C9963 !important;}
.u-accentColor--hoverTextNormal:hover {color: #1C9963 !important;}
.u-accentColor--textNormal.u-accentColor--textDarken:hover {color: #1C9963 !important;}
.u-accentColor--textDark {color: #1C9963 !important;}
.u-accentColor--backgroundLight {background-color: #02B875 !important;}
.u-accentColor--backgroundNormal {background-color: #02B875 !important;}
.u-accentColor--backgroundDark {background-color: #1C9963 !important;}
.u-accentColor--buttonDark {border-color: #1C9963 !important; color: #1C9963 !important;}
.u-accentColor--buttonDark:hover {border-color: #1C9963 !important;}
.u-accentColor--buttonDark .icon:before,.u-accentColor--buttonDark .svgIcon{color: #1C9963 !important; fill: #1C9963 !important;}
.u-accentColor--buttonNormal:not(.clapButton--largePill) {border-color: #02B875 !important; color: #1C9963 !important;}
.u-accentColor--buttonNormal:hover {border-color: #1C9963 !important;}
.u-accentColor--buttonNormal .icon:before,.u-accentColor--buttonNormal .svgIcon{color: #02B875 !important; fill: #02B875 !important;}
.u-accentColor--buttonNormal.button--filled .icon:before,.u-accentColor--buttonNormal.button--filled .svgIcon{color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-accentColor--buttonDark.button--filled,.u-accentColor--buttonDark.button--withChrome.is-active,.u-accentColor--fillWhenActive.is-active {background-color: #1C9963 !important; border-color: #1C9963 !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-accentColor--buttonNormal.button--filled:not(.clapButton--largePill),.u-accentColor--buttonNormal.button--withChrome.is-active:not(.clapButton--largePill) {background-color: #02B875 !important; border-color: #02B875 !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.postArticle.is-withAccentColors .markup--user,.postArticle.is-withAccentColors .markup--query {color: #1C9963 !important;}
.u-accentColor--highlightFaint {background-color: rgba(233, 253, 240, 1) !important;}
.u-accentColor--highlightStrong.is-active .svgIcon {fill: rgba(125, 255, 179, 1) !important;}
.postArticle.is-withAccentColors .markup--quote.is-other {background-color: rgba(233, 253, 240, 1) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--quote.is-other {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(233, 253, 240, 1), rgba(233, 253, 240, 1));}
.postArticle.is-withAccentColors .markup--quote.is-me {background-color: rgba(173, 255, 207, 1) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--quote.is-me {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(173, 255, 207, 1), rgba(173, 255, 207, 1));}
.postArticle.is-withAccentColors .markup--quote.is-targeted {background-color: rgba(125, 255, 179, 1) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--quote.is-targeted {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(125, 255, 179, 1), rgba(125, 255, 179, 1));}
.postArticle.is-withAccentColors .markup--quote.is-selected {background-color: rgba(125, 255, 179, 1) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--quote.is-selected {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(125, 255, 179, 1), rgba(125, 255, 179, 1));}
.postArticle.is-withAccentColors .markup--highlight {background-color: rgba(125, 255, 179, 1) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--highlight {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(125, 255, 179, 1), rgba(125, 255, 179, 1));}.u-baseColor--iconNormal.avatar-halo {fill: rgba(0, 0, 0, 0.4980392156862745) !important;}</style><style class="js-collectionStyleConstant">.u-imageBgColor {background-color: rgba(0, 0, 0, 0.24705882352941178);}
.u-imageSpectrum .u-baseColor--borderLight {border-color: rgba(255, 255, 255, 0.6980392156862745) !important;}
.u-imageSpectrum .u-baseColor--borderNormal {border-color: rgba(255, 255, 255, 0.8980392156862745) !important;}
.u-imageSpectrum .u-baseColor--borderDark {border-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--iconLight .svgIcon,.u-imageSpectrum .u-baseColor--iconLight.svgIcon {fill: rgba(255, 255, 255, 0.8) !important;}
.u-imageSpectrum .u-baseColor--iconNormal .svgIcon,.u-imageSpectrum .u-baseColor--iconNormal.svgIcon {fill: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--iconDark .svgIcon,.u-imageSpectrum .u-baseColor--iconDark.svgIcon {fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--textNormal {color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--textNormal.u-baseColor--textDarken:hover {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--textDark {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--textDarker {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--backgroundLight {background-color: rgba(255, 255, 255, 0.8980392156862745) !important;}
.u-imageSpectrum .u-baseColor--backgroundNormal {background-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--backgroundDark {background-color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--buttonLight {border-color: rgba(255, 255, 255, 0.6980392156862745) !important; color: rgba(255, 255, 255, 0.8) !important;}
.u-imageSpectrum .u-baseColor--buttonLight:hover {border-color: rgba(255, 255, 255, 0.6980392156862745) !important;}
.u-imageSpectrum .u-baseColor--buttonLight .icon:before,.u-imageSpectrum .u-baseColor--buttonLight .svgIcon {color: rgba(255, 255, 255, 0.8) !important; fill: rgba(255, 255, 255, 0.8) !important;}
.u-imageSpectrum .u-baseColor--buttonDark {border-color: rgba(255, 255, 255, 0.9490196078431372) !important; color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--buttonDark:hover {border-color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--buttonDark .icon:before,.u-imageSpectrum .u-baseColor--buttonDark .svgIcon {color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--buttonNormal {border-color: rgba(255, 255, 255, 0.8980392156862745) !important; color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--buttonNormal:hover {border-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--buttonNormal .icon:before,.u-imageSpectrum .u-baseColor--buttonNormal .svgIcon {color: rgba(255, 255, 255, 0.9490196078431372) !important; fill: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--buttonDark.button--filled,.u-imageSpectrum .u-baseColor--buttonDark.button--withChrome.is-active {background-color: rgba(255, 255, 255, 1) !important; border-color: rgba(255, 255, 255, 1) !important; color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}
.u-imageSpectrum .u-baseColor--buttonNormal.button--filled,.u-imageSpectrum .u-baseColor--buttonNormal.button--withChrome.is-active {background-color: rgba(255, 255, 255, 0.9490196078431372) !important; border-color: rgba(255, 255, 255, 0.9490196078431372) !important; color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}
.u-imageSpectrum .u-baseColor--link {color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--link.link--darkenOnHover:hover {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--link.link--darken:hover,.u-imageSpectrum .u-baseColor--link.link--darken:focus,.u-imageSpectrum .u-baseColor--link.link--darken:active {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--link.link--dark {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--link.link--dark.link--darken:hover,.u-imageSpectrum .u-baseColor--link.link--dark.link--darken:focus,.u-imageSpectrum .u-baseColor--link.link--dark.link--darken:active {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--link.link--darker {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--placeholderNormal ::-webkit-input-placeholder {color: rgba(255, 255, 255, 0.8);}
.u-imageSpectrum .u-baseColor--placeholderNormal ::-moz-placeholder {color: rgba(255, 255, 255, 0.8);}
.u-imageSpectrum .u-baseColor--placeholderNormal :-ms-input-placeholder {color: rgba(255, 255, 255, 0.8);}
.u-imageSpectrum .svgIcon--logoWordmark {stroke: none !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .svgIcon--logoMonogram {stroke: none !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum  .ui-h1,.u-imageSpectrum  .ui-h2,.u-imageSpectrum  .ui-h3,.u-imageSpectrum  .ui-h4,.u-imageSpectrum  .ui-brand1,.u-imageSpectrum  .ui-brand2,.u-imageSpectrum  .ui-captionStrong {color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum  .ui-body,.u-imageSpectrum  .ui-caps {color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum  .ui-summary,.u-imageSpectrum  .ui-caption {color: rgba(255, 255, 255, 0.8) !important; fill: rgba(255, 255, 255, 0.8) !important;}
.u-imageSpectrum .u-accentColor--borderLight {border-color: rgba(255, 255, 255, 0.6980392156862745) !important;}
.u-imageSpectrum .u-accentColor--borderNormal {border-color: rgba(255, 255, 255, 0.8980392156862745) !important;}
.u-imageSpectrum .u-accentColor--borderDark {border-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--iconLight .svgIcon,.u-imageSpectrum .u-accentColor--iconLight.svgIcon {fill: rgba(255, 255, 255, 0.8) !important;}
.u-imageSpectrum .u-accentColor--iconNormal .svgIcon,.u-imageSpectrum .u-accentColor--iconNormal.svgIcon {fill: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--iconDark .svgIcon,.u-imageSpectrum .u-accentColor--iconDark.svgIcon {fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--textNormal {color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--hoverTextNormal:hover {color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--textNormal.u-accentColor--textDarken:hover {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--textDark {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--backgroundLight {background-color: rgba(255, 255, 255, 0.8980392156862745) !important;}
.u-imageSpectrum .u-accentColor--backgroundNormal {background-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--backgroundDark {background-color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--buttonDark {border-color: rgba(255, 255, 255, 0.9490196078431372) !important; color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--buttonDark:hover {border-color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--buttonDark .icon:before,.u-imageSpectrum .u-accentColor--buttonDark .svgIcon{color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--buttonNormal:not(.clapButton--largePill) {border-color: rgba(255, 255, 255, 0.8980392156862745) !important; color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--buttonNormal:hover {border-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--buttonNormal .icon:before,.u-imageSpectrum .u-accentColor--buttonNormal .svgIcon{color: rgba(255, 255, 255, 0.9490196078431372) !important; fill: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--buttonNormal.button--filled .icon:before,.u-imageSpectrum .u-accentColor--buttonNormal.button--filled .svgIcon{color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}
.u-imageSpectrum .u-accentColor--buttonDark.button--filled,.u-imageSpectrum .u-accentColor--buttonDark.button--withChrome.is-active,.u-imageSpectrum .u-accentColor--fillWhenActive.is-active {background-color: rgba(255, 255, 255, 1) !important; border-color: rgba(255, 255, 255, 1) !important; color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}
.u-imageSpectrum .u-accentColor--buttonNormal.button--filled:not(.clapButton--largePill),.u-imageSpectrum .u-accentColor--buttonNormal.button--withChrome.is-active:not(.clapButton--largePill) {background-color: rgba(255, 255, 255, 0.9490196078431372) !important; border-color: rgba(255, 255, 255, 0.9490196078431372) !important; color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}
.u-imageSpectrum .postArticle.is-withAccentColors .markup--user,.u-imageSpectrum .postArticle.is-withAccentColors .markup--query {color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--highlightFaint {background-color: rgba(255, 255, 255, 0.2) !important;}
.u-imageSpectrum .u-accentColor--highlightStrong.is-active .svgIcon {fill: rgba(255, 255, 255, 0.6) !important;}
.postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-other {background-color: rgba(255, 255, 255, 0.2) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-other {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.2), rgba(255, 255, 255, 0.2));}
.postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-me {background-color: rgba(255, 255, 255, 0.4) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-me {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.4), rgba(255, 255, 255, 0.4));}
.postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-targeted {background-color: rgba(255, 255, 255, 0.6) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-targeted {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.6), rgba(255, 255, 255, 0.6));}
.postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-selected {background-color: rgba(255, 255, 255, 0.6) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-selected {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.6), rgba(255, 255, 255, 0.6));}
.postArticle.is-withAccentColors .u-imageSpectrum .markup--highlight {background-color: rgba(255, 255, 255, 0.6) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--highlight {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.6), rgba(255, 255, 255, 0.6));}.u-resetSpectrum .u-tintBgColor {background-color: rgba(255, 255, 255, 1) !important;}.u-resetSpectrum .u-tintBgColor .u-fadeLeft:before {background-image: linear-gradient(to right, rgba(255, 255, 255, 1) 0%, rgba(255, 255, 255, 0) 100%) !important;}.u-resetSpectrum .u-tintBgColor .u-fadeRight:after {background-image: linear-gradient(to right, rgba(255, 255, 255, 0) 0%, rgba(255, 255, 255, 1) 100%) !important;}
.u-resetSpectrum .u-baseColor--borderLight {border-color: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--borderNormal {border-color: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--borderDark {border-color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--iconLight .svgIcon,.u-resetSpectrum .u-baseColor--iconLight.svgIcon {fill: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--iconNormal .svgIcon,.u-resetSpectrum .u-baseColor--iconNormal.svgIcon {fill: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--iconDark .svgIcon,.u-resetSpectrum .u-baseColor--iconDark.svgIcon {fill: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--textNormal {color: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--textNormal.u-baseColor--textDarken:hover {color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--textDark {color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--textDarker {color: rgba(0, 0, 0, 0.8) !important;}
.u-resetSpectrum .u-baseColor--backgroundLight {background-color: rgba(0, 0, 0, 0.09803921568627451) !important;}
.u-resetSpectrum .u-baseColor--backgroundNormal {background-color: rgba(0, 0, 0, 0.2) !important;}
.u-resetSpectrum .u-baseColor--backgroundDark {background-color: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonLight {border-color: rgba(0, 0, 0, 0.2980392156862745) !important; color: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonLight:hover {border-color: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonLight .icon:before,.u-resetSpectrum .u-baseColor--buttonLight .svgIcon {color: rgba(0, 0, 0, 0.2980392156862745) !important; fill: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonDark {border-color: rgba(0, 0, 0, 0.6) !important; color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--buttonDark:hover {border-color: rgba(0, 0, 0, 0.8) !important;}
.u-resetSpectrum .u-baseColor--buttonDark .icon:before,.u-resetSpectrum .u-baseColor--buttonDark .svgIcon {color: rgba(0, 0, 0, 0.6) !important; fill: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--buttonNormal {border-color: rgba(0, 0, 0, 0.4980392156862745) !important; color: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonNormal:hover {border-color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--buttonNormal .icon:before,.u-resetSpectrum .u-baseColor--buttonNormal .svgIcon {color: rgba(0, 0, 0, 0.4980392156862745) !important; fill: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonDark.button--filled,.u-resetSpectrum .u-baseColor--buttonDark.button--withChrome.is-active {background-color: rgba(0, 0, 0, 0.2980392156862745) !important; border-color: rgba(0, 0, 0, 0.2980392156862745) !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-resetSpectrum .u-baseColor--buttonNormal.button--filled,.u-resetSpectrum .u-baseColor--buttonNormal.button--withChrome.is-active {background-color: rgba(0, 0, 0, 0.2) !important; border-color: rgba(0, 0, 0, 0.2) !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-resetSpectrum .u-baseColor--link {color: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--link.link--darkenOnHover:hover {color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--link.link--darken:hover,.u-resetSpectrum .u-baseColor--link.link--darken:focus,.u-resetSpectrum .u-baseColor--link.link--darken:active {color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--link.link--dark {color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--link.link--dark.link--darken:hover,.u-resetSpectrum .u-baseColor--link.link--dark.link--darken:focus,.u-resetSpectrum .u-baseColor--link.link--dark.link--darken:active {color: rgba(0, 0, 0, 0.8) !important;}
.u-resetSpectrum .u-baseColor--link.link--darker {color: rgba(0, 0, 0, 0.8) !important;}
.u-resetSpectrum .u-baseColor--placeholderNormal ::-webkit-input-placeholder {color: rgba(0, 0, 0, 0.2980392156862745);}
.u-resetSpectrum .u-baseColor--placeholderNormal ::-moz-placeholder {color: rgba(0, 0, 0, 0.2980392156862745);}
.u-resetSpectrum .u-baseColor--placeholderNormal :-ms-input-placeholder {color: rgba(0, 0, 0, 0.2980392156862745);}
.u-resetSpectrum .svgIcon--logoWordmark {stroke: none !important; fill: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .svgIcon--logoMonogram {stroke: none !important; fill: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum  .ui-h1,.u-resetSpectrum  .ui-h2,.u-resetSpectrum  .ui-h3,.u-resetSpectrum  .ui-h4,.u-resetSpectrum  .ui-brand1,.u-resetSpectrum  .ui-brand2,.u-resetSpectrum  .ui-captionStrong {color: rgba(0, 0, 0, 0.8) !important; fill: rgba(0, 0, 0, 0.8) !important;}
.u-resetSpectrum  .ui-body,.u-resetSpectrum  .ui-caps {color: rgba(0, 0, 0, 0.6) !important; fill: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum  .ui-summary,.u-resetSpectrum  .ui-caption {color: rgba(0, 0, 0, 0.2980392156862745) !important; fill: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-accentColor--borderLight {border-color: rgba(2, 184, 117, 1) !important;}
.u-resetSpectrum .u-accentColor--borderNormal {border-color: rgba(2, 184, 117, 1) !important;}
.u-resetSpectrum .u-accentColor--borderDark {border-color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--iconLight .svgIcon,.u-resetSpectrum .u-accentColor--iconLight.svgIcon {fill: rgba(2, 184, 117, 1) !important;}
.u-resetSpectrum .u-accentColor--iconNormal .svgIcon,.u-resetSpectrum .u-accentColor--iconNormal.svgIcon {fill: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--iconDark .svgIcon,.u-resetSpectrum .u-accentColor--iconDark.svgIcon {fill: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--textNormal {color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--hoverTextNormal:hover {color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--textNormal.u-accentColor--textDarken:hover {color: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--textDark {color: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--backgroundLight {background-color: rgba(2, 184, 117, 1) !important;}
.u-resetSpectrum .u-accentColor--backgroundNormal {background-color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--backgroundDark {background-color: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonDark {border-color: rgba(0, 171, 107, 1) !important; color: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonDark:hover {border-color: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonDark .icon:before,.u-resetSpectrum .u-accentColor--buttonDark .svgIcon{color: rgba(28, 153, 99, 1) !important; fill: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonNormal:not(.clapButton--largePill) {border-color: rgba(2, 184, 117, 1) !important; color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonNormal:hover {border-color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonNormal .icon:before,.u-resetSpectrum .u-accentColor--buttonNormal .svgIcon{color: rgba(0, 171, 107, 1) !important; fill: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonNormal.button--filled .icon:before,.u-resetSpectrum .u-accentColor--buttonNormal.button--filled .svgIcon{color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonDark.button--filled,.u-resetSpectrum .u-accentColor--buttonDark.button--withChrome.is-active,.u-resetSpectrum .u-accentColor--fillWhenActive.is-active {background-color: rgba(28, 153, 99, 1) !important; border-color: rgba(28, 153, 99, 1) !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonNormal.button--filled:not(.clapButton--largePill),.u-resetSpectrum .u-accentColor--buttonNormal.button--withChrome.is-active:not(.clapButton--largePill) {background-color: rgba(0, 171, 107, 1) !important; border-color: rgba(0, 171, 107, 1) !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-resetSpectrum .postArticle.is-withAccentColors .markup--user,.u-resetSpectrum .postArticle.is-withAccentColors .markup--query {color: rgba(0, 171, 107, 1) !important;}</style><div class="highlightMenu" data-action-scope="_actionscope_3"><div class="highlightMenu-inner"><div class="buttonSet"><a class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--chromeless button--highlightMenu js-highlightMenuTwitterShare" href="https://medium.com/p/8218fa8a871f/share/twitter" title="Share on Twitter" aria-label="Share on Twitter" target="_blank" data-action="twitter"><span class="button-defaultState"><span class="svgIcon svgIcon--twitterFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M21.725 5.338c-.744.47-1.605.804-2.513 1.006a3.978 3.978 0 0 0-2.942-1.293c-2.22 0-4.02 1.81-4.02 4.02 0 .32.034.63.07.94-3.31-.18-6.27-1.78-8.255-4.23a4.544 4.544 0 0 0-.574 2.01c.04 1.43.74 2.66 1.8 3.38-.63-.01-1.25-.19-1.79-.5v.08c0 1.93 1.38 3.56 3.23 3.95-.34.07-.7.12-1.07.14-.25-.02-.5-.04-.72-.07.49 1.58 1.97 2.74 3.74 2.8a8.49 8.49 0 0 1-5.02 1.72c-.3-.03-.62-.04-.93-.07A11.447 11.447 0 0 0 8.88 21c7.386 0 11.43-6.13 11.414-11.414.015-.21.01-.38 0-.578a7.604 7.604 0 0 0 2.01-2.08 7.27 7.27 0 0 1-2.297.645 3.856 3.856 0 0 0 1.72-2.23"></path></svg></span></span></a><div class="buttonSet-separator"></div><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--highlightMenu" data-action="sign-up-prompt" data-sign-in-action="highlight" data-redirect="https://ai-alignment.com/efficient-and-safely-scalable-8218fa8a871f" data-skip-onboarding="true" data-action-source="quote_menu--------------------------privatenote_text"><span class="svgIcon svgIcon--privatenoteFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M17.662 4.552H7.346A4.36 4.36 0 0 0 3 8.898v5.685c0 2.168 1.614 3.962 3.697 4.28v2.77c0 .303.35.476.59.29l3.904-2.994h6.48c2.39 0 4.35-1.96 4.35-4.35V8.9c0-2.39-1.95-4.346-4.34-4.346zM16 14.31a.99.99 0 0 1-1.003.99h-4.994C9.45 15.3 9 14.85 9 14.31v-3.02a.99.99 0 0 1 1-.99v-.782a2.5 2.5 0 0 1 2.5-2.51c1.38 0 2.5 1.13 2.5 2.51v.782c.552.002 1 .452 1 .99v3.02z"></path><path d="M14 9.81c0-.832-.674-1.68-1.5-1.68-.833 0-1.5.84-1.5 1.68v.49h3v-.49z"></path></g></svg></span></button></div></div><div class="highlightMenu-arrowClip"><span class="highlightMenu-arrow"></span></div></div></div></div></div><div class="loadingBar"></div><script>// <![CDATA[
window["obvInit"] = function (opt_embedded) {window["obvInit"]["embedded"] = opt_embedded; window["obvInit"]["ready"] = true;}
// ]]></script><script>// <![CDATA[
var GLOBALS = {"audioUrl":"https://d1fcbxp97j4nb2.cloudfront.net","baseUrl":"https://ai-alignment.com","buildLabel":"37496-7f20643","currentUser":{"userId":"lo_JuU2p2EvGepj","isVerified":false,"subscriberEmail":"","hasPastMemberships":false,"isEnrolledInHightower":false,"isEligibleForHightower":false,"hightowerLastLockedAt":0,"isWriterProgramEnrolled":true,"isWriterProgramInvited":false,"isWriterProgramOptedOut":false,"writerProgramVersion":0,"writerProgramEnrolledAt":0,"friendLinkOnboarding":0,"hasAdditionalUnlocks":false,"hasApiAccess":false,"isQuarantined":false,"writerProgramDistributionSettingOptedIn":false},"currentUserHasUnverifiedEmail":false,"isAuthenticated":false,"isCurrentUserVerified":false,"miroUrl":"https://cdn-images-1.medium.com","moduleUrls":{"base":"https://cdn-static-1.medium.com/_/fp/gen-js/main-base.bundle.h-S66qYGELCwGMjo-I5sGg.js","common-async":"https://cdn-static-1.medium.com/_/fp/gen-js/main-common-async.bundle.qFZkgzLZ5TYXIerh_w9awQ.js","hightower":"https://cdn-static-1.medium.com/_/fp/gen-js/main-hightower.bundle.YYDLiHqz4VuEAfIKbpgHlA.js","home-screens":"https://cdn-static-1.medium.com/_/fp/gen-js/main-home-screens.bundle.KOsn4BMHvTHwO7kChpWnwQ.js","misc-screens":"https://cdn-static-1.medium.com/_/fp/gen-js/main-misc-screens.bundle.9HQt5flvjhqNbC82Kz7w3A.js","notes":"https://cdn-static-1.medium.com/_/fp/gen-js/main-notes.bundle.V05mXLtyLz2Mj5DzEML26A.js","payments":"https://cdn-static-1.medium.com/_/fp/gen-js/main-payments.bundle.4s7BX_pcnrqTR9pXdg44lw.js","posters":"https://cdn-static-1.medium.com/_/fp/gen-js/main-posters.bundle.oAF5QtbeXBsEy2D-ZeKzOA.js","power-readers":"https://cdn-static-1.medium.com/_/fp/gen-js/main-power-readers.bundle.242jbfrxhns9kmBC8hYbGA.js","pubs":"https://cdn-static-1.medium.com/_/fp/gen-js/main-pubs.bundle.OVIBk1ifJgWYBiuHy2mNlA.js","stats":"https://cdn-static-1.medium.com/_/fp/gen-js/main-stats.bundle.FRAzB3YCXktr7d19iN9skg.js"},"previewConfig":{"weightThreshold":1,"weightImageParagraph":0.51,"weightIframeParagraph":0.8,"weightTextParagraph":0.08,"weightEmptyParagraph":0,"weightP":0.003,"weightH":0.005,"weightBq":0.003,"minPTextLength":60,"truncateBoundaryChars":20,"detectTitle":true,"detectTitleLevThreshold":0.15},"productName":"Medium","supportsEdit":false,"termsUrl":"//medium.com/policy/9db0094a1e0f","textshotHost":"textshot.medium.com","transactionId":"1557467313753:bf6a757159e7","useragent":{"browser":"headlesschrome","family":"chrome","os":"mac","version":0,"supportsDesktopEdit":false,"supportsInteract":false,"supportsView":true,"isMobile":false,"isTablet":false,"isNative":false,"supportsFileAPI":false,"isTier1":false,"clientVersion":"","unknownParagraphsBad":false,"clientChannel":"","supportsRealScrollEvents":false,"supportsVhUnits":false,"ruinsViewportSections":false,"supportsHtml5Video":false,"supportsMagicUnderlines":false,"isWebView":false,"isFacebookWebView":false,"supportsProgressiveMedia":false,"supportsPromotedPosts":true,"isBot":false,"isNativeIphone":false,"supportsCssVariables":false,"supportsVideoSections":true,"emojiSupportLevel":5,"isSearchBot":false,"isSyndicationBot":false,"isNativeAndroid":false,"isNativeIos":false,"supportsScrollableMetabar":false},"variants":{"allow_access":true,"allow_signup":true,"allow_test_auth":"disallow","signin_services":"twitter,facebook,google,email,google-fastidv,google-one-tap","signup_services":"twitter,facebook,google,email,google-fastidv,google-one-tap","google_sign_in_android":true,"reengagement_notification_duration":3,"browsable_stream_config_bucket":"curated-topics","enable_dedicated_series_tab_api_ios":true,"enable_post_import":true,"available_monthly_plan":"60e220181034","available_annual_plan":"2c754bcc2995","disable_ios_resume_reading_toast":true,"is_not_medium_subscriber":true,"glyph_font_set":"m2","enable_branding":true,"enable_branding_fonts":true,"max_premium_content_per_user_under_metering":3,"enable_automated_mission_control_triggers":true,"enable_lite_profile":true,"enable_marketing_emails":true,"enable_topic_lifecycle_email":true,"enable_parsely":true,"enable_branch_io":true,"enable_ios_post_stats":true,"enable_lite_topics":true,"enable_lite_stories":true,"redis_read_write_splitting":true,"enable_tipalti_onboarding":true,"enable_annual_renewal_reminder_email":true,"enable_janky_spam_rules":"users,posts","enable_new_collaborative_filtering_data":true,"android_rating_prompt_stories_read_threshold":2,"stripe_v3":true,"enable_google_one_tap":true,"enable_email_sign_in_captcha":true,"enable_rito_with_viewer_query":true,"enable_rito_with_flag_query":true,"enable_rito_post_handler":true,"enable_rito_sequence_post_recirc_query":true,"enable_rito_post_recirc_query":true,"enable_rito_topic_handler":true,"enable_rito_stats_post_handler":true,"enable_rito_stats_post_chart":true,"enable_rito_lifetime_earnings_tooltip":true,"enable_rito_stats_post_referrers_container":true,"enable_rito_post_feature_mutation":true,"enable_rito_post_unfeature_mutation":true,"enable_rito_quote_delete_mutation":true,"enable_rito_user_block_mutation":true,"enable_rito_user_unblock_mutation":true,"enable_rito_report_user_link":true,"enable_rito_bookmark_post_default":true,"enable_rito_unbookmark_post_default":true,"enable_rito_archive_post_default":true,"enable_rito_unarchive_post_default":true,"enable_rito_clap":true,"enable_rito_subscribe_series":true,"enable_rito_unsubscribe_series":true,"enable_rito_follow_topic":true,"enable_rito_unfollow_topic":true,"enable_rito_follow_user":true,"enable_rito_unfollow_user":true,"enable_rito_your_story_delete_mutation":true,"enable_rito_update_last_read_section":true,"editorial_push_notifications":true,"enable_primary_topic_for_mobile":true,"enable_rito_sequence_post_handler":true,"enable_todays_highlights_ios":true,"enable_logged_out_homepage_signup":true,"use_new_admin_topic_backend":true,"enable_quarantine_rules":true,"enable_lite_privacy_banner":true,"enable_patronus_on_kubernetes":true,"pub_sidebar":true,"disable_mobile_featured_chunk":true,"enable_rito_user_profile_overview_handler":true,"enable_rito_user_stream_overview":true,"enable_rito_user_profile_latest_handler":true,"enable_rito_user_stream_latest":true,"enable_rito_user_profile_actions":true,"enable_rito_post_actions":true,"enable_rito_user_profile_highlights_handler":true,"enable_rito_user_stream_highlights":true,"enable_rito_user_profile_series_handler":true,"enable_rito_user_stream_series":true,"enable_rito_user_profile_claps_handler":true,"enable_rito_user_stream_claps":true,"enable_rito_user_profile_responses_handler":true,"enable_rito_user_stream_responses":true,"enable_rito_billing_history_handler":true,"enable_rito_your_stories_handler":true,"enable_rito_sequence_library_handler":true,"enable_rito_series_handler":true,"enable_rito_amppost_handler":true,"enable_rito_follow_collection_mutation":true,"enable_rito_unfollow_collection_mutation":true,"enable_pub_newsletters":true,"enable_may_meter_email_test":true,"enable_rex_app_highlights":true,"enable_new_user_avatar_dropdown_menu":true,"enable_mobile_pubcrawl_home_feed":true,"enable_draft_in_post_cotent":true},"xsrfToken":"","iosAppId":"828256236","supportEmail":"yourfriends@medium.com","fp":{"/icons/monogram-mask.svg":"https://cdn-static-1.medium.com/_/fp/icons/monogram-mask.KPLCSFEZviQN0jQ7veN2RQ.svg","/icons/favicon-dev-editor.ico":"https://cdn-static-1.medium.com/_/fp/icons/favicon-dev-editor.YKKRxBO8EMvIqhyCwIiJeQ.ico","/icons/favicon-hatch-editor.ico":"https://cdn-static-1.medium.com/_/fp/icons/favicon-hatch-editor.BuEyHIqlyh2s_XEk4Rl32Q.ico","/icons/favicon-medium-editor.ico":"https://cdn-static-1.medium.com/_/fp/icons/favicon-medium-editor.PiakrZWB7Yb80quUVQWM6g.ico"},"authBaseUrl":"https://medium.com","imageUploadSizeMb":25,"isAuthDomainRequest":false,"domainCollectionSlug":"ai-control","algoliaApiEndpoint":"https://MQ57UUUQZ2-dsn.algolia.net","algoliaAppId":"MQ57UUUQZ2","algoliaSearchOnlyApiKey":"394474ced050e3911ae2249ecc774921","iosAppStoreUrl":"https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8","iosAppLinkBaseUrl":"medium:","algoliaIndexPrefix":"medium_","androidPlayStoreUrl":"https://play.google.com/store/apps/details?id=com.medium.reader","googleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","androidPackage":"com.medium.reader","androidPlayStoreMarketScheme":"market://details?id=com.medium.reader","googleAuthUri":"https://accounts.google.com/o/oauth2/auth","androidScheme":"medium","layoutData":{"useDynamicScripts":false,"googleAnalyticsTrackingCode":"UA-24232453-2","jsShivUrl":"https://cdn-static-1.medium.com/_/fp/js/shiv.RI2ePTZ5gFmMgLzG5bEVAA.js","useDynamicCss":false,"faviconUrl":"https://cdn-static-1.medium.com/_/fp/icons/favicon-rebrand-medium.3Y6xpZ-0FSdWDnPM3hSBIA.ico","faviconImageId":"1*8I-HPL0bfoIzGied-dzOvA.png","fontSets":[{"id":8,"url":"https://glyph.medium.com/css/e/sr/latin/e/ssr/latin/e/ssb/latin/m2.css"},{"id":11,"url":"https://glyph.medium.com/css/m2.css"},{"id":9,"url":"https://glyph.medium.com/css/mkt.css"}],"editorFaviconUrl":"https://cdn-static-1.medium.com/_/fp/icons/favicon-rebrand-medium-editor.3Y6xpZ-0FSdWDnPM3hSBIA.ico","glyphUrl":"https://glyph.medium.com"},"authBaseUrlRev":"moc.muidem//:sptth","isDnt":false,"stripePublishableKey":"pk_live_7FReX44VnNIInZwrIIx6ghjl","archiveUploadSizeMb":100,"paymentData":{"currencies":{"1":{"label":"US Dollar","external":"usd"}},"countries":{"1":{"label":"United States of America","external":"US"}},"accountTypes":{"1":{"label":"Individual","external":"individual"},"2":{"label":"Company","external":"company"}}},"previewConfig2":{"weightThreshold":1,"weightImageParagraph":0.05,"raiseImage":true,"enforceHeaderHierarchy":true,"isImageInsetRight":true},"isAmp":false,"iosScheme":"medium","isSwBoot":false,"lightstep":{"accessToken":"ce5be895bef60919541332990ac9fef2","carrier":"{\"ot-tracer-spanid\":\"60500aaf5f5feb52\",\"ot-tracer-traceid\":\"160f6b435c6b1158\",\"ot-tracer-sampled\":\"true\"}","host":"collector-medium.lightstep.com"},"facebook":{"key":"542599432471018","namespace":"medium-com","scope":{"default":["public_profile","email"],"connect":["public_profile","email"],"login":["public_profile","email"],"share":["public_profile","email"]}},"editorsPicksTopicId":"3985d2a191c5","popularOnMediumTopicId":"9d34e48ecf94","memberContentTopicId":"13d7efd82fb2","audioContentTopicId":"3792abbd134","brandedSequenceId":"7d337ddf1941","isDoNotAuth":false,"buggle":{"url":"https://buggle.medium.com","videoUrl":"https://cdn-videos-1.medium.com","audioUrl":"https://cdn-audio-1.medium.com"},"referrerType":5,"isMeteredOut":false,"meterConfig":{"maxUnlockCount":3,"windowLength":"MONTHLY"},"partnerProgramEmail":"partnerprogram@medium.com","userResearchPrompts":[{"promptId":"lo_post_page_4","type":0,"url":"www.calendly.com"},{"promptId":"lo_home_page","type":1,"url":"www.calendly.com"},{"promptId":"lo_profile_page","type":2,"url":"www.calendly.com"}],"recaptchaKey":"6LdAokEUAAAAAC7seICd4vtC8chDb3jIXDQulyUJ","signinWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"countryCode":"US","bypassMeter":false,"branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","paypal":{"clientMode":"production","oneYearGift":{"name":"Medium Membership (1 Year, Digital Gift Code)","description":"Unlimited access to the best and brightest stories on Medium. Gift codes can be redeemed at medium.com/redeem.","price":"50.00","currency":"USD","sku":"membership-gift-1-yr"}},"collectionConfig":{"mediumOwnedAndOperatedCollectionIds":["544c7006046e // Human Parts","bcc38c8f6edf // Matter","444d13b52878 // OneZero","8d6b8a439e32 // Elemental","92d2092dc598 // Gay Mag","1285ba81cada // Heated"]}}
// ]]></script><script charset="UTF-8" src="https://cdn-static-1.medium.com/_/fp/gen-js/main-base.bundle.h-S66qYGELCwGMjo-I5sGg.js" async=""></script><script>// <![CDATA[
window["obvInit"]({"value":{"id":"8218fa8a871f","versionId":"77580728ea52","creatorId":"57f1a655a613","creator":{"userId":"57f1a655a613","name":"Paul Christiano","username":"paulfchristiano","createdAt":1417286353352,"imageId":"1*BNjZCuQuRfIgcXCBMipuBw.jpeg","backgroundImageId":"","bio":"OpenAI","twitterScreenName":"","socialStats":{"userId":"57f1a655a613","usersFollowedCount":93,"usersFollowedByCount":821,"type":"SocialStats"},"social":{"userId":"lo_1HnsOvgcVrD4","targetUserId":"57f1a655a613","type":"Social"},"facebookAccountId":"1167284919","allowNotes":1,"mediumMemberAt":0,"isNsfw":false,"isWriterProgramEnrolled":true,"isQuarantined":false,"type":"User"},"homeCollection":{"id":"624d886c4aa4","name":"AI Alignment","slug":"ai-control","tags":[],"creatorId":"57f1a655a613","description":"Aligning AI systems with human interests.","shortDescription":"Aligning AI systems with human interests.","image":{"imageId":"1*N56Qc5-aHTcfGff0scntKQ.png","filter":"","backgroundSize":"","originalWidth":512,"originalHeight":512,"strategy":"resample","height":0,"width":0},"metadata":{"followerCount":2834,"activeAt":1548040822588},"virtuals":{"permissions":{"canPublish":false,"canPublishAll":false,"canRepublish":false,"canRemove":false,"canManageAll":false,"canSubmit":false,"canEditPosts":false,"canAddWriters":false,"canViewStats":false,"canSendNewsletter":false,"canViewLockedPosts":false,"canViewCloaked":false,"canEditOwnPosts":false,"canBeAssignedAuthor":false,"canEnrollInHightower":false,"canLockPostsForMediumMembers":false,"canLockOwnPostsForMediumMembers":false},"isSubscribed":false,"isNewsletterSubscribed":false,"isEnrolledInHightower":false,"isEligibleForHightower":false},"logo":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"collectionMastheadId":"29f3dcc2e4","domain":"ai-alignment.com","sections":[{"type":2,"collectionHeaderMetadata":{"title":"AI Alignment","backgroundImage":{},"logoImage":{},"alignment":2,"layout":4}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":3,"postIds":["157debfd1616","b49ad992940b","b959644d79c2"]}},{"type":1,"postListMetadata":{"source":1,"layout":4,"number":24,"postIds":[],"sectionHeader":"Latest"}}],"favicon":{"imageId":"1*cciPf4CUXd_Zyux0Jg0yBQ.png","filter":"","backgroundSize":"","originalWidth":400,"originalHeight":400,"strategy":"resample","height":0,"width":0},"colorPalette":{"defaultBackgroundSpectrum":{"colorPoints":[{"color":"#FF02B875","point":0},{"color":"#FF00AB6B","point":0.1},{"color":"#FF1C9963","point":0.2},{"color":"#FF092E20","point":1}],"backgroundColor":"#FFFFFFFF"},"highlightSpectrum":{"colorPoints":[{"color":"#FFFFFFFF","point":0},{"color":"#FFE9FDF0","point":0.1},{"color":"#FFE2FAEE","point":0.2},{"color":"#FFADFFCF","point":0.6},{"color":"#FF7DFFB3","point":1}],"backgroundColor":"#FFFFFFFF"}},"navItems":[],"colorBehavior":1,"instantArticlesState":0,"acceleratedMobilePagesState":0,"ampLogo":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"header":{"title":"AI Alignment","backgroundImage":{},"logoImage":{},"alignment":2,"layout":4},"paidForDomainAt":1490733089988,"type":"Collection"},"homeCollectionId":"624d886c4aa4","title":"Efficient and safely scalable","detectedLanguage":"en","latestVersion":"77580728ea52","latestPublishedVersion":"77580728ea52","hasUnpublishedEdits":false,"latestRev":1957,"createdAt":1458430565192,"updatedAt":1521070175653,"acceptedAt":0,"firstPublishedAt":1458784020844,"latestPublishedAt":1458784020844,"vote":false,"experimentalCss":"","displayAuthor":"","content":{"subtitle":"A precise but overambitious goal for AI control research.","bodyModel":{"paragraphs":[{"name":"531d","type":3,"text":"Efficient and safely scalable","markups":[]},{"name":"30e4","type":1,"text":"Precisely defining the goal of AI control research seems quite difficult. This post gives preliminary definitions of safe scalability and efficiency for AI control protocols, taking a step towards formalization. Roughly, these properties say that ‚Äúusing better machine learning primitives results in better systems‚Äù and ‚Äúthe control scheme does not impose significant overhead.‚Äù","markups":[{"type":1,"start":117,"end":133},{"type":1,"start":138,"end":148}]},{"name":"b32d","type":1,"text":"I think these properties are probably sufficient conditions for success, but they are also probably too ambitious to be realistic goals. I discuss a few possible ways to weaken these definitions.","markups":[]},{"name":"12bf","type":1,"text":"Both scalability and efficiency are defined with respect to a preference order ‚âª·¥∞ which tells us when one algorithm is ‚Äúbetter‚Äù another on some distribution D, according to the user‚Äôs preferences. I won‚Äôt offer any precise definition of ‚âª·¥∞, but I‚Äôll discuss a few informal candidates.","markups":[]},{"name":"2794","type":13,"text":"Motivation","markups":[]},{"name":"caf0","type":1,"text":"I‚Äôm interested in defining alignment formally for at least three reasons:","markups":[]},{"name":"89ca","type":9,"text":"Having a precise goal makes it easier to do good and well-targeted research. The AI control problem would feel much easier to me (both to work on and to talk to others about) if there were a precise, satisfactory, and achievable goal.","markups":[]},{"name":"0b19","type":9,"text":"A precise definition of alignment might be helpful when analyzing AI control schemes. For example, the analysis of ALBA calls for maintaining alignment as an inductive invariant as the agent becomes more powerful. Right now, there is little hope of making that argument formal.","markups":[{"type":3,"start":99,"end":119,"href":"https://medium.com/ai-control/alba-an-explicit-proposal-for-aligned-ai-17a55f60bbcf","title":"","rel":"","anchorType":0}]},{"name":"91e1","type":9,"text":"Trying to formalize alignment may shed light on what the key difficulties are, what assumptions are likely to be necessary, and so on. Trying to pin down slippery concepts is often a good idea .","markups":[]},{"name":"14b9","type":3,"text":"Definitions","markups":[]},{"name":"fca7","type":13,"text":"What is a control protocol?","markups":[]},{"name":"291d","type":1,"text":"Our AI control protocols will use machine learning primitives as building blocks, and construct a (hopefully aligned) AI out of them.","markups":[]},{"name":"3894","type":1,"text":"To instantiate a control protocol A ü…™…¢…¥, we provide some set of learning primitives that are required by the protocol. A ü…™…¢…¥ then instantiates any number of copies of each of those primitives. A ü…™…¢…¥ may choose what inputs to provide to those instances, and may use their outputs however it likes. A ü…™…¢…¥ may also interact with the user arbitrarily.","markups":[]},{"name":"8c2d","type":1,"text":"For simplicity, throughout the post we will assume that A ü…™…¢…¥ is built from an RL algorithm, and write A ü…™…¢…¥(A·¥ø·¥∏) for the algorithm obtained by using A·¥ø·¥∏. Note that A ü…™…¢…¥ can instantiate any number of distinct instances of A·¥ø·¥∏, can provide each of them distinct rewards, and so on.","markups":[]},{"name":"61d5","type":1,"text":"All of our definitions can be easily extended to any set of machine learning primitives, as long as we can define what it means for one implementation of a primitive to ‚Äúoutperform‚Äù another on a given distribution. I think that the definitions are most interesting when we can efficiently test whether one implementation outperforms another, and amongst such primitives RL is essentially universal (since we can use the test itself as a reward function).","markups":[]},{"name":"4318","type":13,"text":"Betterness","markups":[]},{"name":"a066","type":1,"text":"What does it mean for one algorithm to be better than another?","markups":[]},{"name":"20f0","type":1,"text":"We won‚Äôt answer that question. Instead, we take as given a family of preorders ‚â∫·¥∞ indexed by distributions D. These orders define when one program ‚Äúoutperforms‚Äù another on the distribution D, according to the user‚Äôs preferences.","markups":[]},{"name":"297f","type":1,"text":"Intuitively, we can imagine some (unobserved) utility function U characterizing the user‚Äôs preferences. U takes as input an (x, y) pair, and outputs a real number reflecting how good it is, according to the user‚Äôs preferences, for a program to output y given input x.","markups":[{"type":2,"start":125,"end":126},{"type":2,"start":128,"end":129},{"type":2,"start":251,"end":252},{"type":2,"start":265,"end":266}]},{"name":"8f6d","type":1,"text":"Then we could define:","markups":[]},{"name":"ae34","type":9,"text":"A ‚âº·¥∞ B ‚ü∫ ùîº[U(x, A(x))] ‚â§ ùîº[U(x, B(x))],","markups":[{"type":2,"start":14,"end":17},{"type":2,"start":19,"end":20},{"type":2,"start":31,"end":32},{"type":2,"start":33,"end":34},{"type":2,"start":36,"end":37}]},{"name":"bb87","type":1,"text":"where the expectations are taken over x drawn from D. We could also strengthen the condition by allowing A to score nearly as well on average over many episodes, or by requiring B to do at least as well as A for every utility function in some big set ùí∞. These changes make ‚â∫·¥∞ a preorder rather than a total order.","markups":[{"type":2,"start":38,"end":39}]},{"name":"c27a","type":1,"text":"We‚Äôll give a range of more plausible definitions in the final section, but this is a good concrete example to have in mind.","markups":[]},{"name":"5254","type":13,"text":"Safely scalable and efficient","markups":[]},{"name":"9d36","type":1,"text":"Intuitively, a control scheme is safely scalable if using better RL algorithms never results in worse performance. A control scheme is efficient if it can realize any level of performance with low overhead.","markups":[{"type":2,"start":33,"end":49},{"type":2,"start":135,"end":144}]},{"name":"d3f2","type":9,"text":"Safely scalable (with respect to ‚âª·¥∞). Given any A·¥ø·¥∏, B·¥ø·¥∏, and the ability to sample from some distribution D with A ü…™…¢…¥(A·¥ø·¥∏) ‚âª·¥∞ A ü…™…¢…¥(B·¥ø·¥∏), we can sample from a distribution D·¥ø·¥∏ over RL episodes on which A·¥ø·¥∏ outperforms B·¥ø·¥∏.","markups":[{"type":1,"start":0,"end":33}]},{"name":"dc13","type":9,"text":"Efficient (with respect to ‚âª·¥∞). Given any B, we can implement an RL agent B·¥ø·¥∏ such that, for every distribution D from which we can sample, A ü…™…¢…¥(B·¥ø·¥∏) ‚™∞·¥∞ B.","markups":[{"type":1,"start":0,"end":27}]},{"name":"1877","type":1,"text":"Efficiency is quantified by how much more time A ü…™…¢…¥(B·¥ø·¥∏) takes than B itself, and how often it queries the user. I‚Äôll say that a scheme is ‚Äúasymptotically efficient‚Äù if the difference in running times, and the number of queries to the user, is sublinear in the number of episodes T.","markups":[{"type":1,"start":141,"end":165}]},{"name":"3796","type":1,"text":"In order to be achievable this definition probably needs to be weakened. I think the most plausible way to weaken it is to make additional assumptions about the agent B in efficiency. For example, we could focus our attention on a particular approach to building AI systems, and assume that B is the kind of agent that might be produced by that approach. Particularly interesting are structural assumptions about how B itself is built out of the same building blocks that are available to A ü…™…¢…¥.","markups":[{"type":1,"start":172,"end":182}]},{"name":"770f","type":13,"text":"Hard to beat","markups":[]},{"name":"2539","type":1,"text":"Together efficiency and safe scalability imply a third property:","markups":[]},{"name":"1037","type":9,"text":"Hard to beat. Given any RL agent A·¥ø·¥∏, any agent B, and the ability to sample from a distribution D with B ‚âª·¥∞ A ü…™…¢…¥(A·¥ø·¥∏), we can implement an agent B·¥ø·¥∏ and sample from a distribution D·¥ø·¥∏ over RL episodes on which B·¥ø·¥∏ outperforms A·¥ø·¥∏.","markups":[{"type":1,"start":0,"end":12}]},{"name":"085f","type":1,"text":"If an algorithm is ‚Äúhard to beat,‚Äù then the only way to make it better (according to ‚âª·¥∞) is to improve the underlying RL algorithms. In some sense this is the strongest form of optimality that we can realistically hope for, since improving our RL algorithms will allow us to build ‚Äúbetter‚Äù AI systems for any reasonable notion of ‚Äúbetter.‚Äù","markups":[]},{"name":"a29e","type":1,"text":"To see that (efficient + scalable ‚Üí hard to beat), apply efficiency to find an agent A ü…™…¢…¥(B·¥ø·¥∏) ‚™∞·¥∞ B, use transitivity to infer that A ü…™…¢…¥(B·¥ø·¥∏) ‚âª·¥∞ A ü…™…¢…¥(A·¥ø·¥∏), and then to use safe scalability to sample from a distribution where B·¥ø·¥∏ outperforms A·¥ø·¥∏.","markups":[]},{"name":"7248","type":1,"text":"Being hard to beat is slightly weaker than being efficient + scalable while being almost as comforting. So it might also be useful as an easier goal.","markups":[]},{"name":"b895","type":13,"text":"Restrictions on the building blocks","markups":[]},{"name":"fa54","type":1,"text":"Rather than working with a generic RL algorithm, we might want to work with an RL algorithm that satisfies some additional property. For example, A ü…™…¢…¥(A·¥ø·¥∏) might only be safely scalable if A·¥ø·¥∏ is able to make good enough predictions about humans, or if A·¥ø·¥∏ is ‚Äútransparent‚Äù in an appropriate sense.","markups":[]},{"name":"4687","type":1,"text":"These restrictions can be incorporated into the definition of safe scalability and efficiency ‚Äî in safe scalability, we can strengthen the hypothesis by assuming that the learning algorithms satisfy the restrictions, and in efficiency we can strengthen the conclusion by assuming that the learning algorithms satisfy the restrictions.","markups":[]},{"name":"e051","type":1,"text":"To make the task easiest, we could strengthen the hypothesis of safe scalability without strengthening the conclusion of efficiency. For example, if we want to work with ‚Äútransparent‚Äù RL algorithms, we will probably not be able to strengthen the conclusion of efficiency ‚Äî we won‚Äôt be able to turn a black-box algorithm B into a transparent RL algorithm B·¥ø·¥∏. So we could instead aim for a scheme that is safely scalable when applied with transparent RL algorithms, and that is efficient when we are allowed to use arbitrary RL algorithms. The resulting control scheme would only be practically efficient to the extent that there are transparent nearly-state-of-the-art RL algorithms.","markups":[{"type":2,"start":81,"end":88}]},{"name":"b02c","type":1,"text":"For now I am interested in schemes that work under any remotely plausible assumptions:","markups":[{"type":2,"start":51,"end":54}]},{"name":"500c","type":9,"text":"Even a conditional result would be a big advance beyond our current understanding.","markups":[]},{"name":"6125","type":9,"text":"Conditional results could clarify our understanding of when AI control will and won‚Äôt succeed.","markups":[]},{"name":"2c45","type":9,"text":"Conditional results present natural targets for differential AI progress. For example, if we could formulate a transparency condition that was sufficient for building safe+efficient AI, this could help clarify the goals of research on transparency.","markups":[]},{"name":"889b","type":13,"text":"Related building blocks","markups":[]},{"name":"3471","type":1,"text":"We might also work with a number of different building blocks, and require them to have some relationship to each other. For example, we might want to use both a classifier and an RL agent, and assume that the classifier is in some sense more powerful than the RL agent (though it‚Äôs not yet clear to me what assumption of this form would actually be useful). Or we might work with a sequence of RL agents, and assume that each is only slightly more powerful than the last.","markups":[{"type":3,"start":283,"end":356,"href":"https://medium.com/ai-control/the-informed-oversight-problem-1b51b4f66b35#.dl1zzh3jm","title":"","rel":"","anchorType":0},{"type":3,"start":410,"end":471,"href":"https://medium.com/ai-control/alba-an-explicit-proposal-for-aligned-ai-17a55f60bbcf","title":"","rel":"","anchorType":0}]},{"name":"60f1","type":3,"text":"Non-solutions","markups":[]},{"name":"570a","type":13,"text":"Plain RL (+counterfactual oversight)","markups":[]},{"name":"1f5e","type":1,"text":"The simplest behavior for A ü…™…¢…¥ is to simply consult the underlying RL agent directly, and then to define a reward that induces aligned behavior.","markups":[]},{"name":"7d30","type":1,"text":"Perhaps the simplest reward function is a human‚Äôs evaluation: a human watches the agent and presses the reward button when the agent behaves well.","markups":[]},{"name":"f7c6","type":1,"text":"If the human has to monitor the agent during every episode, then this constitutes a huge efficiency hit and so our algorithm won‚Äôt be reasonably efficient.","markups":[]},{"name":"655e","type":1,"text":"More realistically, we could train our agent on a small subset of the data (for which the human does have to monitor the agent and press the reward button) and then use the learned policy to act even when there is no human monitor. If necessary, we could train online as in counterfactual oversight.","markups":[{"type":3,"start":274,"end":298,"href":"https://medium.com/ai-control/counterfactual-human-in-the-loop-a7822e36f399","title":"","rel":"","anchorType":0}]},{"name":"e293","type":1,"text":"This approach is asymptotically efficient (as long as the size of the training set is sublinear in the total number of episodes, as would be typical).","markups":[]},{"name":"7494","type":1,"text":"However, this scheme is not safely scalable for a reasonable order ‚âª·¥∞.","markups":[{"type":1,"start":24,"end":27}]},{"name":"da66","type":1,"text":"The problem is that the user‚Äôs judgments are not exactly aligned with the user‚Äôs preferences. For any given input x, there are some outputs y for which the user assigns y an ‚Äúerroneously‚Äù high expected value, whether due to error, to bias, or simply to not having enough time to understand the consequences of a proposed action.","markups":[{"type":2,"start":114,"end":115},{"type":2,"start":140,"end":141},{"type":2,"start":169,"end":170}]},{"name":"cfe4","type":1,"text":"So let A·¥ø·¥∏ be an RL agent which outputs actions which the user mistakenly rates highly, and let B·¥ø·¥∏ be an RL agent which outputs actions that are better than A·¥ø·¥∏‚Äôs outputs but which are rated lower by the user. As long as the user‚Äôs judgments don‚Äôt perfectly preserve the ordering of outcomes, then we can construct such a pair. Then we can have A ü…™…¢…¥(A·¥ø·¥∏) ‚âª·¥∞ A ü…™…¢…¥(B·¥ø·¥∏) for most distributions D, while B·¥ø·¥∏ outperforms A·¥ø·¥∏ on every distribution D·¥ø·¥∏","markups":[{"type":2,"start":426,"end":431}]},{"name":"8379","type":13,"text":"Plain imitation learning (+counterfactual oversight)","markups":[]},{"name":"eebc","type":1,"text":"Given observations of a human expert, we can give A·¥ø·¥∏ the problem ‚Äúpredict what output the human expert will produce on input x.‚Äù","markups":[{"type":2,"start":126,"end":127}]},{"name":"645e","type":1,"text":"After A·¥ø·¥∏ produces a prediction, with small probability we ask the human to actually produce an output y, and then we provide A·¥ø·¥∏ a payoff depending on the quality of its prediction. (There are a number of possible ways to score A·¥ø·¥∏, most involving two separate learners. For example, we could use a generative adversarial model, with a second instance of A·¥ø·¥∏ trying to distinguish the predicted output from the real human output. Or we could score A·¥ø·¥∏ based on a variational lower bound on the log probability it assigned to the particular prediction made by the user.)","markups":[{"type":2,"start":103,"end":104}]},{"name":"cdc5","type":1,"text":"This kind of imitation learning is not safely scalable: an agent which chooses superhuman actions will become strictly worse if we make them a perfect human-predictor, yet their performance in the RL game will improve.","markups":[]},{"name":"0d86","type":1,"text":"(Intuitively, imitation is safely scalable but is not efficient ‚Äî this example highlights a way in which our definitions fail to map well to the intuitive definitions of these concepts.)","markups":[{"type":2,"start":24,"end":26},{"type":2,"start":47,"end":54}]},{"name":"7557","type":13,"text":"ALBA","markups":[]},{"name":"3dbf","type":1,"text":"The current version of ALBA is not safely scalable + efficient, even under the generous assumptions made in the post. The key problem is its reliance on a sequence of throttled RL subagents.","markups":[{"type":3,"start":4,"end":27,"href":"https://medium.com/ai-control/alba-an-explicit-proposal-for-aligned-ai-17a55f60bbcf","title":"","rel":"","anchorType":0}]},{"name":"8b3d","type":1,"text":"The missing ingredients, roughly speaking, are the following:","markups":[]},{"name":"5d17","type":9,"text":"Speedup. Given black-box access to the agent B, we can produce a strictly less capable agent B‚Ä≤ such that Bootstrap(B‚Ä≤) ‚™∞·¥∞ B.","markups":[{"type":1,"start":0,"end":7},{"type":2,"start":65,"end":86}]},{"name":"3f28","type":9,"text":"Informed oversight. See here.","markups":[{"type":3,"start":20,"end":28,"href":"https://medium.com/ai-control/the-informed-oversight-problem-1b51b4f66b35","title":"","rel":"","anchorType":0},{"type":1,"start":0,"end":18}]},{"name":"8445","type":1,"text":"Speedup is impossible without some additional assumptions on B, and informed oversight probably also requires some additional assumptions (in order to make transparency possible). It‚Äôs not clear what kind of assumptions on B might be sufficient to carry out the analysis, and overall it looks like a daunting project.","markups":[]},{"name":"2641","type":3,"text":"Limitations","markups":[]},{"name":"3ecb","type":13,"text":"Too strong","markups":[]},{"name":"5bc3","type":1,"text":"I think the biggest problem with this definition is that it is too strong.","markups":[]},{"name":"a248","type":1,"text":"It‚Äôs not so strong as to be obviously impossible. But it looks almost obviously impossible. The discussions of RL and ALBA illustrate why the definition is so strong:","markups":[{"type":2,"start":28,"end":37},{"type":2,"start":63,"end":70}]},{"name":"69cf","type":9,"text":"In order to turn a black box agent B into an agent B·¥ø·¥∏ with A ü…™…¢…¥(B·¥ø·¥∏) ‚™∞·¥∞ B, we are essentially forced to take B·¥ø·¥∏ = B (since we can‚Äôt produce other derivative agents using black-box access to B).","markups":[]},{"name":"0da5","type":9,"text":"Then A ü…™…¢…¥ is essentially forced to be a training scheme for RL agents.","markups":[]},{"name":"b356","type":9,"text":"So in order to be safely scalable, A ü…™…¢…¥ needs to evaluate of the quality of the agent‚Äôs decisions ‚Äúwell enough‚Äù that optimizing its evaluations optimizes ‚âª·¥∞.","markups":[]},{"name":"4d4a","type":9,"text":"Moreover, A ü…™…¢…¥ can‚Äôt really use the RL agent‚Äôs help to make those decisions ‚Äî if A ü…™…¢…¥ is merely a training procedure, the RL agent need not output anything except on the support of D, and so we can‚Äôt get any useful work out of the agent. Thus A ü…™…¢…¥ is using the same evaluations for every agent.","markups":[]},{"name":"3329","type":9,"text":"If A ü…™…¢…¥ evaluates the agent‚Äôs behavior ‚Äúwell enough‚Äù for an arbitrary agent, then A ü…™…¢…¥ must be evaluating the agent‚Äôs behavior perfectly.","markups":[]},{"name":"afbe","type":9,"text":"It seems infeasible to produce such a perfect evaluations for any interesting ‚âª·¥∞.","markups":[]},{"name":"c4cb","type":1,"text":"How might we weaken the definition?","markups":[]},{"name":"cf97","type":9,"text":"Place some restriction on the set of agents B that we consider in efficiency. For example, we may restrict attention to the kinds of agents that could be produced by some particular AI research project in AI. I think that this is by far the most promising approach.","markups":[{"type":1,"start":66,"end":76}]},{"name":"49cb","type":9,"text":"As discussed in the section Restrictions on building blocks, we could only require safe scalability for a certain class of RL agents, thus moving some of the work to ensuring that state-of-the-art RL agents have the required properties.","markups":[{"type":1,"start":28,"end":59}]},{"name":"e3c1","type":9,"text":"We could use relations ‚âª·¥∞ that evaluate agents holistically in terms of a description of the distribution D (see below). For example, we might say that ‚ÄúA ‚âª·¥∞ B if the human believes that A would outperform B on the distribution D.‚Äù I don‚Äôt really see a way to make this work, but it might be worth thinking about.","markups":[{"type":2,"start":74,"end":85}]},{"name":"2af0","type":9,"text":"We could settle for an agent which is hard to beat instead of both efficient and safely scalable. I don‚Äôt think this really addresses the difficulty described above, but it does give us a tiny bit more traction.","markups":[]},{"name":"5702","type":9,"text":"We could swap the quantifier order, giving us access to B and D when trying to construct an agent B·¥ø·¥∏ with A ü…™…¢…¥(B·¥ø·¥∏) ‚™∞·¥∞ B. I don‚Äôt think this will help.","markups":[]},{"name":"c65a","type":1,"text":"I expect there are many other ways to weaken the definition, and of course we could pursue some combination of the above.","markups":[]},{"name":"5ef5","type":13,"text":"Improving RL algorithms is quite broad","markups":[]},{"name":"00c5","type":1,"text":"Even if A ü…™…¢…¥ is efficient and safely scalable, A ü…™…¢…¥(A·¥ø·¥∏) isn‚Äôt necessarily good even according to ‚âª·¥∞. In order to make A ü…™…¢…¥(A·¥ø·¥∏) actually be good, we may need to improve A·¥ø·¥∏. In some sense this is obvious and inevitable ‚Äî it‚Äôs like saying that even if we solve the control problem, AI progress will still make our AI systems work better.","markups":[{"type":2,"start":77,"end":81}]},{"name":"6e07","type":1,"text":"But in particular, the alignment of A ü…™…¢…¥(A·¥ø·¥∏) may depend on how A·¥ø·¥∏ performs on some very unnatural distribution over RL problems (e.g. on how well A·¥ø·¥∏ is able to predict the results of human deliberation about moral questions).","markups":[]},{"name":"f21b","type":1,"text":"Given how strong safe scalability and efficiency are, I don‚Äôt think this is a problem for this particular definition. That is, any such ‚Äúunnatural‚Äù distribution over RL problems would be necessary to achieving good behavior, even for very weak agents:","markups":[]},{"name":"a0c4","type":9,"text":"Given any aligned agent B we can apply efficiency to obtain an RL agent B·¥ø·¥∏.","markups":[]},{"name":"5f54","type":9,"text":"If B·¥ø·¥∏ always does well on these unnatural instances, then they were in some strong sense necessary in order to get good behavior. But note that B might be quite weak, so these ‚Äúunnatural‚Äù instances were necessary even to getting good behavior out of weak AI systems.","markups":[{"type":2,"start":90,"end":99}]},{"name":"69f4","type":9,"text":"If B·¥ø·¥∏ does poorly on these unnatural instances, then we can consider a very powerful agent A·¥ø·¥∏ that does equally poorly.","markups":[]},{"name":"22b4","type":9,"text":"By safe scalability, A ü…™…¢…¥(A·¥ø·¥∏) remains at-least-as-good-as-B for that RL agent A·¥ø·¥∏.","markups":[]},{"name":"0697","type":1,"text":"This argument would still go through if we restricted B to the kinds of AI‚Äôs that we might actually produce. (The conclusion would be that the unnatural RL instances are in fact necessary, for the kinds of AI that we might actually build, which is just as good.)","markups":[{"type":2,"start":189,"end":237}]},{"name":"2a5b","type":1,"text":"If we weakened the definition enough we might encounter a more troubling version of this unnatural-RL-instances problem, but even then I think that reducing the alignment problem to a concrete RL problem would probably represent significant progress in and of itself. So overall I‚Äôm not concerned about this potential bug.","markups":[]},{"name":"23f4","type":13,"text":"Missing definition of ‚âª·¥∞","markups":[]},{"name":"9f3d","type":1,"text":"We don‚Äôt provide any definition of ‚âª·¥∞; that definition needs to be quite subtle and is doing a lot of the work of formalizing our goals. See the discussion in the next section.","markups":[]},{"name":"c8ed","type":3,"text":"Defining ‚âª·¥∞","markups":[]},{"name":"df5a","type":13,"text":"Human judgment","markups":[]},{"name":"e9c4","type":1,"text":"For sufficiently subhuman agents we could define:","markups":[]},{"name":"be0f","type":9,"text":"Draw a random x from D, compute A(x) and B(x), and give them both to a human judge (along with the input x) to decide which is better. A ‚âª·¥∞ B if the human prefers A(x) with probability at least 2/3.","markups":[{"type":2,"start":14,"end":15},{"type":2,"start":34,"end":35},{"type":2,"start":43,"end":44},{"type":2,"start":165,"end":166}]},{"name":"8b92","type":1,"text":"For this definition of ‚â∫, the RL agent described above is in fact efficient and safely scalable.","markups":[]},{"name":"f2e9","type":1,"text":"But being safely scalable in this sense doesn‚Äôt seem very useful, since the human‚Äôs judgment about ‚Äúwhich action is good‚Äù need not be correct, and the human would substantially prefer an agent that chooses actions which are actually good.","markups":[{"type":2,"start":224,"end":232}]},{"name":"f3c7","type":13,"text":"Human judgment on reflection","markups":[]},{"name":"cdc7","type":1,"text":"We could try to fix this definition with an alternative informal definition:","markups":[]},{"name":"5dac","type":9,"text":"Draw a random x from D, compute A(x) and B(x). Give a human judge an extremely long time to reflect, and access to extremely powerful tools. A ‚âª·¥∞ B if, upon extensive reflection, the human prefers A(x) with probability at least 2/3.","markups":[{"type":3,"start":66,"end":139,"href":"https://ordinaryideas.wordpress.com/2012/04/21/indirect-normativity-write-up/","title":"","rel":"","anchorType":0},{"type":2,"start":14,"end":15},{"type":2,"start":34,"end":35},{"type":2,"start":43,"end":44},{"type":2,"start":199,"end":200}]},{"name":"6ddd","type":1,"text":"This definition leads to a very strong notion of safe scalability. Unfortunately that strong notion is too strong, and it is clearly intractable to build a hard-to-beat agent in this sense.","markups":[{"type":2,"start":103,"end":106}]},{"name":"4794","type":1,"text":"For example, consider some hard question that bears on what strategies will have good long-term effects. This question is beyond our abilities currently, but we will be able to answer it with sufficient reflection. If B guesses the correct answer to that question and A does not, then A ‚â∫·¥∞ B, where D is the a point distribution concentrated on a decision where that question matters. If B guesses the wrong answer, then B ‚â∫·¥∞ A. But by efficiency + safe scalability, we can essentially produce a pair of agents A·¥ø·¥∏ and B·¥ø·¥∏ and sample from a distribution D·¥ø·¥∏ such that A ‚â∫·¥∞ B iff B·¥ø·¥∏ outperforms A·¥ø·¥∏ on D ·¥ø·¥∏. But then we can test which of A and B is correct about the hard question, contradicting its supposed hardness.","markups":[]},{"name":"96d8","type":13,"text":"Holistic judgment","markups":[]},{"name":"1854","type":1,"text":"A very different approach would be to directly elicit the human‚Äôs judgment about the relative merits of A and B. That is:","markups":[]},{"name":"e159","type":9,"text":"Give a human judge a description of A and B, and the sampling procedure for D, and ask them which they expect to perform better. A ‚âª·¥∞ B if the human thinks that A would make significantly better decisions than B, on inputs sampled from D.","markups":[]},{"name":"48e2","type":1,"text":"In some sense this definition gets very directly at what we care about. Suppose that some alternative AI control research program produced B, and that we would be happier using B than A. Then we are precisely satisfying this definition of A ‚â∫·¥∞ B.","markups":[]},{"name":"e008","type":1,"text":"An obvious problem with this approach is that determining which of A and B is better may itself be a very hard problem ‚Äî indeed, it‚Äôs easy to believe that it includes all of the difficulty of the alignment problem.","markups":[]},{"name":"628c","type":1,"text":"The definition of efficiency still has teeth if we restrict our attention to algorithms B that ‚Äúexplain themselves,‚Äù e.g. that are accompanied with significant documentation and explanation. The description of the agent B could embody the entire output of the alternative research program that produced it.","markups":[{"type":1,"start":28,"end":29}]},{"name":"edbf","type":1,"text":"So this definition of betterness is adequate if we think that there are efficient and good decision-making protocols which are demonstrably good to existing humans. This definition is very unsatisfying if we think that evaluating a possible proposal, even given the best available arguments, is the core difficulty of AI control. This might be either because those arguments are necessarily extremely complex, or because there will be many bad proposals that are also supported by extremely convincing-looking arguments.","markups":[{"type":2,"start":127,"end":139}]},{"name":"08c8","type":13,"text":"What we really want","markups":[]},{"name":"5df8","type":1,"text":"Intuitively, I would like a definition along the lines of:","markups":[]},{"name":"0415","type":9,"text":"Draw a random x from D, compute A(x) and B(x). Give a human judge the same information, abilities, and insights, that A and B used to compute these quantities. A ‚âª·¥∞ B if the human prefers A(x) with probability at least 2/3.","markups":[{"type":2,"start":14,"end":15},{"type":2,"start":34,"end":35},{"type":2,"start":43,"end":44},{"type":2,"start":190,"end":191}]},{"name":"aebe","type":1,"text":"This definition smuggles all of the complexity into imagining that the human has the same ‚Äúinformation, abilities, and insights‚Äù as the AI they are evaluating. I don‚Äôt have any candidate formalization of this idea, nor am I especially optimistic about being able to formalize it.","markups":[]},{"name":"4b26","type":1,"text":"I do feel like I can reason about this definition intuitively and that it roughly captures my intuitive desiderata. This makes me more optimistic that there is some satisfactory definition of ‚âª.","markups":[{"type":2,"start":160,"end":164}]},{"name":"5d9a","type":1,"text":"Note that this definition is closely related to the goal in the informed oversight problem, which is roughly to ensure that the overseer ‚Äúknows everything the AI knows.‚Äù In the informed oversight problem we are willing to assume that the overseer is significantly more powerful than the system they are overseeing. That may well be a necessary assumption to actually ensure that the overseer ‚Äúknows everything the AI knows,‚Äù but it probably isn‚Äôt needed to define what it would mean for the overseer to ‚Äúknow everything the AI knows.‚Äù","markups":[{"type":3,"start":60,"end":90,"href":"https://medium.com/ai-control/the-informed-oversight-problem-1b51b4f66b35","title":"","rel":"","anchorType":0}]},{"name":"daa8","type":3,"text":"Conclusion","markups":[]},{"name":"075d","type":1,"text":"We can try to define the goals of AI control by thinking about how AI systems relate to the underlying machine learning primitives. Such a framework wouldn‚Äôt cover all possible approaches to AI control, but where applicable it could be a great way to organize research and a useful analysis tool.","markups":[]},{"name":"e937","type":1,"text":"This post gave a step in that direction, but did not yet succeed. I would love to see other attempts, and I think there is a good chance that it will be possible to find a satisfying problem statement for AI control.","markups":[]}],"sections":[{"name":"c867","startIndex":0}]},"postDisplay":{"coverless":true}},"virtuals":{"statusForCollection":"APPROVED","allowNotes":true,"previewImage":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"wordCount":3855,"imageCount":0,"readingTime":14.547169811320755,"subtitle":"A precise but overambitious goal for AI control research.","publishedInCount":1,"usersBySocialRecommends":[],"noIndex":false,"recommends":4,"socialRecommends":[],"isBookmarked":false,"tags":[],"socialRecommendsCount":0,"responsesCreatedCount":0,"links":{"entries":[{"url":"https://medium.com/ai-control/the-informed-oversight-problem-1b51b4f66b35","alts":[{"type":3,"url":"medium://p/1b51b4f66b35"},{"type":2,"url":"medium://p/1b51b4f66b35"}]},{"url":"https://medium.com/ai-control/the-informed-oversight-problem-1b51b4f66b35#.dl1zzh3jm","alts":[{"type":2,"url":"medium://p/1b51b4f66b35"},{"type":3,"url":"medium://p/1b51b4f66b35"}]},{"url":"https://ordinaryideas.wordpress.com/2012/04/21/indirect-normativity-write-up/","alts":[{"type":1,"url":"https://cdn.ampproject.org/c/s/ordinaryideas.wordpress.com/2012/04/21/indirect-normativity-write-up/amp/"}]},{"url":"https://medium.com/ai-control/counterfactual-human-in-the-loop-a7822e36f399","alts":[{"type":2,"url":"medium://p/a7822e36f399"},{"type":3,"url":"medium://p/a7822e36f399"}]},{"url":"https://medium.com/ai-control/alba-an-explicit-proposal-for-aligned-ai-17a55f60bbcf","alts":[{"type":2,"url":"medium://ai-control/alba-an-explicit-proposal-for-aligned-ai-17a55f60bbcf"},{"type":3,"url":"medium://ai-control/alba-an-explicit-proposal-for-aligned-ai-17a55f60bbcf"}]}],"version":"0.3","generatedAt":1472039437103},"isLockedPreviewOnly":false,"metaDescription":"","totalClapCount":4,"sectionCount":1,"readingList":0,"topics":[]},"coverless":true,"slug":"efficient-and-safely-scalable","translationSourcePostId":"","translationSourceCreatorId":"","isApprovedTranslation":false,"inResponseToPostId":"","inResponseToRemovedAt":0,"isTitleSynthesized":false,"allowResponses":true,"importedUrl":"","importedPublishedAt":0,"visibility":0,"uniqueSlug":"efficient-and-safely-scalable-8218fa8a871f","previewContent":{"bodyModel":{"paragraphs":[{"name":"previewTitle","type":3,"text":"Efficient and safely scalable","alignment":1},{"name":"previewSubtitle","type":13,"text":"A precise but overambitious goal for AI control research.","alignment":1},{"name":"previewSnippet0","type":1,"text":"Precisely defining the goal of AI control research seems quite difficult. This post gives preliminary definitions of safe scalability and efficiency for AI‚Ä¶","alignment":1}],"sections":[{"startIndex":0}]},"isFullContent":false,"subtitle":"A precise but overambitious goal for AI control research."},"license":0,"inResponseToMediaResourceId":"","canonicalUrl":"https://ai-alignment.com/efficient-and-safely-scalable-8218fa8a871f","approvedHomeCollectionId":"624d886c4aa4","approvedHomeCollection":{"id":"624d886c4aa4","name":"AI Alignment","slug":"ai-control","tags":[],"creatorId":"57f1a655a613","description":"Aligning AI systems with human interests.","shortDescription":"Aligning AI systems with human interests.","image":{"imageId":"1*N56Qc5-aHTcfGff0scntKQ.png","filter":"","backgroundSize":"","originalWidth":512,"originalHeight":512,"strategy":"resample","height":0,"width":0},"metadata":{"followerCount":2834,"activeAt":1548040822588},"virtuals":{"permissions":{"canPublish":false,"canPublishAll":false,"canRepublish":false,"canRemove":false,"canManageAll":false,"canSubmit":false,"canEditPosts":false,"canAddWriters":false,"canViewStats":false,"canSendNewsletter":false,"canViewLockedPosts":false,"canViewCloaked":false,"canEditOwnPosts":false,"canBeAssignedAuthor":false,"canEnrollInHightower":false,"canLockPostsForMediumMembers":false,"canLockOwnPostsForMediumMembers":false},"isSubscribed":false,"isNewsletterSubscribed":false,"isEnrolledInHightower":false,"isEligibleForHightower":false},"logo":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"collectionMastheadId":"29f3dcc2e4","domain":"ai-alignment.com","sections":[{"type":2,"collectionHeaderMetadata":{"title":"AI Alignment","backgroundImage":{},"logoImage":{},"alignment":2,"layout":4}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":3,"postIds":["157debfd1616","b49ad992940b","b959644d79c2"]}},{"type":1,"postListMetadata":{"source":1,"layout":4,"number":24,"postIds":[],"sectionHeader":"Latest"}}],"favicon":{"imageId":"1*cciPf4CUXd_Zyux0Jg0yBQ.png","filter":"","backgroundSize":"","originalWidth":400,"originalHeight":400,"strategy":"resample","height":0,"width":0},"colorPalette":{"defaultBackgroundSpectrum":{"colorPoints":[{"color":"#FF02B875","point":0},{"color":"#FF00AB6B","point":0.1},{"color":"#FF1C9963","point":0.2},{"color":"#FF092E20","point":1}],"backgroundColor":"#FFFFFFFF"},"highlightSpectrum":{"colorPoints":[{"color":"#FFFFFFFF","point":0},{"color":"#FFE9FDF0","point":0.1},{"color":"#FFE2FAEE","point":0.2},{"color":"#FFADFFCF","point":0.6},{"color":"#FF7DFFB3","point":1}],"backgroundColor":"#FFFFFFFF"}},"navItems":[],"colorBehavior":1,"instantArticlesState":0,"acceleratedMobilePagesState":0,"ampLogo":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"header":{"title":"AI Alignment","backgroundImage":{},"logoImage":{},"alignment":2,"layout":4},"paidForDomainAt":1490733089988,"type":"Collection"},"newsletterId":"","webCanonicalUrl":"https://ai-alignment.com/efficient-and-safely-scalable-8218fa8a871f","mediumUrl":"https://ai-alignment.com/efficient-and-safely-scalable-8218fa8a871f","migrationId":"","notifyFollowers":true,"notifyTwitter":false,"notifyFacebook":false,"responseHiddenOnParentPostAt":0,"isSeries":false,"isSubscriptionLocked":false,"seriesLastAppendedAt":0,"audioVersionDurationSec":0,"sequenceId":"","isNsfw":false,"isEligibleForRevenue":false,"isBlockedFromHightower":false,"deletedAt":0,"lockedPostSource":0,"hightowerMinimumGuaranteeStartsAt":0,"hightowerMinimumGuaranteeEndsAt":0,"featureLockRequestAcceptedAt":0,"mongerRequestType":1,"layerCake":0,"socialTitle":"","socialDek":"","editorialPreviewTitle":"","editorialPreviewDek":"","curationEligibleAt":0,"type":"Post"},"mentionedUsers":[],"collaborators":[],"hideMeter":false,"collectionUserRelations":[],"mode":null,"references":{"User":{"57f1a655a613":{"userId":"57f1a655a613","name":"Paul Christiano","username":"paulfchristiano","createdAt":1417286353352,"imageId":"1*BNjZCuQuRfIgcXCBMipuBw.jpeg","backgroundImageId":"","bio":"OpenAI","twitterScreenName":"","socialStats":{"userId":"57f1a655a613","usersFollowedCount":93,"usersFollowedByCount":821,"type":"SocialStats"},"social":{"userId":"lo_1HnsOvgcVrD4","targetUserId":"57f1a655a613","type":"Social"},"facebookAccountId":"1167284919","allowNotes":1,"mediumMemberAt":0,"isNsfw":false,"isWriterProgramEnrolled":true,"isQuarantined":false,"type":"User"}},"Collection":{"624d886c4aa4":{"id":"624d886c4aa4","name":"AI Alignment","slug":"ai-control","tags":[],"creatorId":"57f1a655a613","description":"Aligning AI systems with human interests.","shortDescription":"Aligning AI systems with human interests.","image":{"imageId":"1*N56Qc5-aHTcfGff0scntKQ.png","filter":"","backgroundSize":"","originalWidth":512,"originalHeight":512,"strategy":"resample","height":0,"width":0},"metadata":{"followerCount":2834,"activeAt":1548040822588},"virtuals":{"permissions":{"canPublish":false,"canPublishAll":false,"canRepublish":false,"canRemove":false,"canManageAll":false,"canSubmit":false,"canEditPosts":false,"canAddWriters":false,"canViewStats":false,"canSendNewsletter":false,"canViewLockedPosts":false,"canViewCloaked":false,"canEditOwnPosts":false,"canBeAssignedAuthor":false,"canEnrollInHightower":false,"canLockPostsForMediumMembers":false,"canLockOwnPostsForMediumMembers":false},"isSubscribed":false,"isNewsletterSubscribed":false,"isEnrolledInHightower":false,"isEligibleForHightower":false},"logo":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"collectionMastheadId":"29f3dcc2e4","domain":"ai-alignment.com","sections":[{"type":2,"collectionHeaderMetadata":{"title":"AI Alignment","backgroundImage":{},"logoImage":{},"alignment":2,"layout":4}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":3,"postIds":["157debfd1616","b49ad992940b","b959644d79c2"]}},{"type":1,"postListMetadata":{"source":1,"layout":4,"number":24,"postIds":[],"sectionHeader":"Latest"}}],"favicon":{"imageId":"1*cciPf4CUXd_Zyux0Jg0yBQ.png","filter":"","backgroundSize":"","originalWidth":400,"originalHeight":400,"strategy":"resample","height":0,"width":0},"colorPalette":{"defaultBackgroundSpectrum":{"colorPoints":[{"color":"#FF02B875","point":0},{"color":"#FF00AB6B","point":0.1},{"color":"#FF1C9963","point":0.2},{"color":"#FF092E20","point":1}],"backgroundColor":"#FFFFFFFF"},"highlightSpectrum":{"colorPoints":[{"color":"#FFFFFFFF","point":0},{"color":"#FFE9FDF0","point":0.1},{"color":"#FFE2FAEE","point":0.2},{"color":"#FFADFFCF","point":0.6},{"color":"#FF7DFFB3","point":1}],"backgroundColor":"#FFFFFFFF"}},"navItems":[],"colorBehavior":1,"instantArticlesState":0,"acceleratedMobilePagesState":0,"ampLogo":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"header":{"title":"AI Alignment","backgroundImage":{},"logoImage":{},"alignment":2,"layout":4},"paidForDomainAt":1490733089988,"type":"Collection"}},"Social":{"57f1a655a613":{"userId":"lo_1HnsOvgcVrD4","targetUserId":"57f1a655a613","type":"Social"}},"SocialStats":{"57f1a655a613":{"userId":"57f1a655a613","usersFollowedCount":93,"usersFollowedByCount":821,"type":"SocialStats"}}}})
// ]]></script><script id="parsely-cfg" src="//d1z2jf7jlzjs58.cloudfront.net/keys/medium.com/p.js"></script><script type="text/javascript">(function(b,r,a,n,c,h,_,s,d,k){if(!b[n]||!b[n]._q){for(;s<_.length;)c(h,_[s++]);d=r.createElement(a);d.async=1;d.src="https://cdn.branch.io/branch-latest.min.js";k=r.getElementsByTagName(a)[0];k.parentNode.insertBefore(d,k);b[n]=h}})(window,document,"script","branch",function(b,r){b[r]=function(){b._q.push([r,arguments])}},{_q:[],_v:1},"addListener applyCode autoAppIndex banner closeBanner closeJourney creditHistory credits data deepview deepviewCta first getCode init link logout redeem referrals removeListener sendSMS setBranchViewData setIdentity track validateCode trackCommerceEvent logEvent".split(" "), 0); branch.init('key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm', {'no_journeys': true, 'disable_exit_animation': true, 'disable_entry_animation': true, 'tracking_disabled':  false }, function(err, data) {});</script><div class="surface-scrollOverlay"></div><script charset="UTF-8" src="https://cdn-static-1.medium.com/_/fp/gen-js/main-common-async.bundle.qFZkgzLZ5TYXIerh_w9awQ.js"></script><script charset="UTF-8" src="https://cdn-static-1.medium.com/_/fp/gen-js/main-notes.bundle.V05mXLtyLz2Mj5DzEML26A.js"></script></body></html>