<!DOCTYPE html><html xmlns:cc="http://creativecommons.org/ns#"><head prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# medium-com: http://ogp.me/ns/fb/medium-com#"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=contain"><title>The reward engineering problem – AI Alignment</title><link rel="canonical" href="https://ai-alignment.com/the-reward-engineering-problem-30285c779450"><meta name="title" content="The reward engineering problem – AI Alignment"><meta name="referrer" content="always"><meta name="description" content="Today we usually train reinforcement learning agents to perform narrow tasks with simple goals. We may eventually want to train RL agents to behave “well” in open-ended environments where there is no…"><meta name="theme-color" content="#000000"><meta property="og:title" content="The reward engineering problem – AI Alignment"><meta property="twitter:title" content="The reward engineering problem"><meta property="og:url" content="https://ai-alignment.com/the-reward-engineering-problem-30285c779450"><meta property="fb:app_id" content="542599432471018"><meta property="og:description" content="How can we define rewards which incentivize weak RL agents to behave in a desirable way?"><meta name="twitter:description" content="How can we define rewards which incentivize weak RL agents to behave in a desirable way?"><link rel="author" href="https://ai-alignment.com/@paulfchristiano"><meta name="author" content="Paul Christiano"><meta property="og:type" content="article"><meta name="twitter:card" content="summary"><meta property="article:publisher" content="https://www.facebook.com/medium"><meta property="article:author" content="1167284919"><meta name="robots" content="index, follow"><meta property="article:published_time" content="2016-05-30T23:31:10.254Z"><meta name="twitter:site" content="@Medium"><meta property="og:site_name" content="AI Alignment"><meta name="twitter:label1" value="Reading time"><meta name="twitter:data1" value="9 min read"><meta name="twitter:app:name:iphone" content="Medium"><meta name="twitter:app:id:iphone" content="828256236"><meta name="twitter:app:url:iphone" content="medium://p/30285c779450"><meta property="al:ios:app_name" content="Medium"><meta property="al:ios:app_store_id" content="828256236"><meta property="al:android:package" content="com.medium.reader"><meta property="al:android:app_name" content="Medium"><meta property="al:ios:url" content="medium://p/30285c779450"><meta property="al:android:url" content="medium://p/30285c779450"><meta property="al:web:url" content="https://ai-alignment.com/the-reward-engineering-problem-30285c779450"><link rel="search" type="application/opensearchdescription+xml" title="Medium" href="/osd.xml"><link rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/30285c779450"><script async="" src="https://cdn.branch.io/branch-latest.min.js"></script><script type="application/ld+json">{"@context":"http://schema.org","@type":"NewsArticle","image":{"@type":"ImageObject","width":545,"height":106,"url":"https://cdn-images-1.medium.com/max/545/1*OMF3fSqH8t4xBJ9-6oZDZw.png"},"url":"https://ai-alignment.com/the-reward-engineering-problem-30285c779450","dateCreated":"2016-05-30T23:31:10.254Z","datePublished":"2016-05-30T23:31:10.254Z","dateModified":"2018-04-12T17:48:27.578Z","headline":"The reward engineering problem","name":"The reward engineering problem","articleId":"30285c779450","thumbnailUrl":"https://cdn-images-1.medium.com/max/545/1*OMF3fSqH8t4xBJ9-6oZDZw.png","keywords":["Tag:Machine Learning","Tag:Artificial Intelligence","Publication:ai-control","LockedPostSource:0","Elevated:false","LayerCake:0"],"author":{"@type":"Person","name":"Paul Christiano","url":"https://ai-alignment.com/@paulfchristiano"},"creator":["Paul Christiano"],"publisher":{"@type":"Organization","name":"AI Alignment","url":"https://ai-alignment.com","logo":{"@type":"ImageObject","width":308,"height":60,"url":"https://cdn-images-1.medium.com/max/308/1*OMF3fSqH8t4xBJ9-6oZDZw.png"}},"mainEntityOfPage":"https://ai-alignment.com/the-reward-engineering-problem-30285c779450"}</script><meta name="parsely-link" content="https://ai-alignment.com/the-reward-engineering-problem-30285c779450"><link rel="stylesheet" href="https://cdn-static-1.medium.com/_/fp/css/main-branding-base.sMRbh_65n82B91860QdvTg.css"><script>!function(n,e){var t,o,i,c=[],f={passive:!0,capture:!0},r=new Date,a="pointerup",u="pointercancel";function p(n,c){t||(t=c,o=n,i=new Date,w(e),s())}function s(){o>=0&&o<i-r&&(c.forEach(function(n){n(o,t)}),c=[])}function l(t){if(t.cancelable){var o=(t.timeStamp>1e12?new Date:performance.now())-t.timeStamp;"pointerdown"==t.type?function(t,o){function i(){p(t,o),r()}function c(){r()}function r(){e(a,i,f),e(u,c,f)}n(a,i,f),n(u,c,f)}(o,t):p(o,t)}}function w(n){["click","mousedown","keydown","touchstart","pointerdown"].forEach(function(e){n(e,l,f)})}w(n),self.perfMetrics=self.perfMetrics||{},self.perfMetrics.onFirstInputDelay=function(n){c.push(n),s()}}(addEventListener,removeEventListener);</script><script>if (window.top !== window.self) window.top.location = window.self.location.href;var OB_startTime = new Date().getTime(); var OB_loadErrors = []; function _onerror(e) { OB_loadErrors.push(e) }; if (document.addEventListener) document.addEventListener("error", _onerror, true); else if (document.attachEvent) document.attachEvent("onerror", _onerror); function _asyncScript(u) {var d = document, f = d.getElementsByTagName("script")[0], s = d.createElement("script"); s.type = "text/javascript"; s.async = true; s.src = u; f.parentNode.insertBefore(s, f);}function _asyncStyles(u) {var d = document, f = d.getElementsByTagName("script")[0], s = d.createElement("link"); s.rel = "stylesheet"; s.href = u; f.parentNode.insertBefore(s, f); return s}(new Image()).src = "/_/stat?event=pixel.load&origin=" + encodeURIComponent(location.origin);</script><script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date; ga("create", "UA-24232453-2", "auto", {"allowLinker": true, "legacyCookieDomain": window.location.hostname}); ga("send", "pageview");</script><script async="" src="https://www.google-analytics.com/analytics.js"></script><script>(function () {var height = window.innerHeight || document.documentElement.clientHeight || document.body.clientHeight; var width = window.innerWidth || document.documentElement.clientWidth || document.body.clientWidth; document.write("<style>section.section-image--fullBleed.is-backgrounded {padding-top: " + Math.round(1.1 * height) + "px;}section.section-image--fullScreen.is-backgrounded, section.section-image--coverFade.is-backgrounded {min-height: " + height + "px; padding-top: " + Math.round(0.5 * height) + "px;}.u-height100vh {height: " + height + "px !important;}.u-height110vh {height: " + Math.round(1.1 * height) + "px !important;}.u-minHeight100vh {min-height: " + height + "px !important;}.u-maxHeight100vh {max-height: " + height + "px !important;}section.section-image--coverFade {height: " + height + "px;}.section-aspectRatioViewportPlaceholder, .section-aspectRatioViewportCropPlaceholder {max-height: " + height + "px;}.section-aspectRatioViewportBottomSpacer, .section-aspectRatioViewportBottomPlaceholder {max-height: " + Math.round(0.5 * height) + "px;}.zoomable:before {top: " + (-1 * height) + "px; left: " + (-1 * width) + "px; padding: " + height + "px " + width + "px;}</style>");})()</script><style>section.section-image--fullBleed.is-backgrounded {padding-top: 660px;}section.section-image--fullScreen.is-backgrounded, section.section-image--coverFade.is-backgrounded {min-height: 600px; padding-top: 300px;}.u-height100vh {height: 600px !important;}.u-height110vh {height: 660px !important;}.u-minHeight100vh {min-height: 600px !important;}.u-maxHeight100vh {max-height: 600px !important;}section.section-image--coverFade {height: 600px;}.section-aspectRatioViewportPlaceholder, .section-aspectRatioViewportCropPlaceholder {max-height: 600px;}.section-aspectRatioViewportBottomSpacer, .section-aspectRatioViewportBottomPlaceholder {max-height: 300px;}.zoomable:before {top: -600px; left: -800px; padding: 600px 800px;}</style><!--[if lt IE 9]><script charset="UTF-8" src="https://cdn-static-1.medium.com/_/fp/js/shiv.RI2ePTZ5gFmMgLzG5bEVAA.js"></script><![endif]--><link rel="icon" href="https://cdn-images-1.medium.com/fit/c/128/128/1*cciPf4CUXd_Zyux0Jg0yBQ.png" class="js-favicon"><link rel="apple-touch-icon" sizes="152x152" href="https://cdn-images-1.medium.com/fit/c/152/152/1*N56Qc5-aHTcfGff0scntKQ.png"><link rel="apple-touch-icon" sizes="120x120" href="https://cdn-images-1.medium.com/fit/c/120/120/1*N56Qc5-aHTcfGff0scntKQ.png"><link rel="apple-touch-icon" sizes="76x76" href="https://cdn-images-1.medium.com/fit/c/76/76/1*N56Qc5-aHTcfGff0scntKQ.png"><link rel="apple-touch-icon" sizes="60x60" href="https://cdn-images-1.medium.com/fit/c/60/60/1*N56Qc5-aHTcfGff0scntKQ.png"><link rel="mask-icon" href="https://cdn-static-1.medium.com/_/fp/icons/monogram-mask.KPLCSFEZviQN0jQ7veN2RQ.svg" color="#171717"><meta property="og:image" content=""><style type="text/css">.metabar,.u-fixed,footer { display: none}</style></head><body itemscope="" class="postShowScreen browser-chrome os-mac v-glyph v-glyph--m2 is-js is-resizing" data-action-scope="_actionscope_0"><script>document.body.className = document.body.className.replace(/(^|\s)is-noJs(\s|$)/, "$1is-js$2")</script><div class="site-main surface-container" id="container"><div class="butterBar butterBar--error" data-action-scope="_actionscope_1"></div><div class="surface" id="_obv.shell._surface_1557467436949" style="display: block; visibility: visible;"><div class="screenContent surface-content is-supplementalPostContentLoaded" data-used="true" data-action-scope="_actionscope_2"><canvas class="canvas-renderer" width="800" height="600"></canvas><div class="container u-maxWidth740 u-xs-margin0 notesPositionContainer js-notesPositionContainer"><div class="notesMarkers" data-action-scope="_actionscope_4"></div></div><div class="metabar u-clearfix u-boxShadow4px12pxBlackLightest u-fixed u-backgroundTransparentWhiteDarkest u-xs-sizeFullViewportWidth js-metabar"><div class="branch-journeys-top"></div><div class="js-metabarMiddle metabar-inner u-marginAuto u-maxWidth1032 u-flexCenter u-justifyContentSpaceBetween u-height65 u-xs-height56 u-paddingHorizontal20"><div class="metabar-block u-flex1 u-flexCenter"><div class="u-xs-hide js-metabarLogoLeft"><a href="https://medium.com/" data-log-event="home" class="siteNav-logo u-fillTransparentBlackDarker u-flex0 u-flexCenter u-paddingTop0"><span class="svgIcon svgIcon--logoMonogram svgIcon--45px is-flushLeft u-flex0 u-flexCenter u-paddingTop0"><svg class="svgIcon-use" width="45" height="45"><path d="M5 40V5h35v35H5zm8.56-12.627c0 .555-.027.687-.318 1.03l-2.457 2.985v.396h6.974v-.396l-2.456-2.985c-.291-.343-.344-.502-.344-1.03V18.42l6.127 13.364h.714l5.256-13.364v10.644c0 .29 0 .342-.185.528l-1.848 1.796v.396h9.19v-.396l-1.822-1.796c-.184-.186-.21-.238-.21-.528V15.937c0-.291.026-.344.21-.528l1.823-1.797v-.396h-6.471l-4.622 11.542-5.203-11.542h-6.79v.396l2.14 2.64c.239.292.291.37.291.768v10.353z"></path></svg></span><span class="u-textScreenReader">Homepage</span></a></div><div class="u-xs-show js-metabarLogoLeft"><a href="https://medium.com/" data-log-event="home" class="siteNav-logo u-fillTransparentBlackDarker u-flex0 u-flexCenter u-paddingTop0"><span class="svgIcon svgIcon--logoMonogram svgIcon--45px is-flushLeft u-flex0 u-flexCenter u-paddingTop0"><svg class="svgIcon-use" width="45" height="45"><path d="M5 40V5h35v35H5zm8.56-12.627c0 .555-.027.687-.318 1.03l-2.457 2.985v.396h6.974v-.396l-2.456-2.985c-.291-.343-.344-.502-.344-1.03V18.42l6.127 13.364h.714l5.256-13.364v10.644c0 .29 0 .342-.185.528l-1.848 1.796v.396h9.19v-.396l-1.822-1.796c-.184-.186-.21-.238-.21-.528V15.937c0-.291.026-.344.21-.528l1.823-1.797v-.396h-6.471l-4.622 11.542-5.203-11.542h-6.79v.396l2.14 2.64c.239.292.291.37.291.768v10.353z"></path></svg></span><span class="u-textScreenReader">Homepage</span></a></div><div class="u-flexCenter u-height65 u-xs-height56"><span class="u-inlineBlock u-height28 u-xs-height24 u-verticalAlignTop u-marginRight20 u-marginLeft15 u-borderRightLighter"></span></div><div class="u-flexCenter u-height65 u-xs-height56 u-marginRight18"><div class="u-xs-show"><a class="link u-baseColor--link avatar avatar--roundedRectangle" href="https://ai-alignment.com?source=avatar-lo_JuU2p2EvGepj-624d886c4aa4" title="Go to AI Alignment" aria-label="Go to AI Alignment" data-action-source="avatar-lo_JuU2p2EvGepj-624d886c4aa4" data-collection-slug="ai-control"><img src="https://cdn-images-1.medium.com/fit/c/32/32/1*N56Qc5-aHTcfGff0scntKQ.png" class="avatar-image avatar-image--icon" alt="AI Alignment"></a></div><div class="u-xs-hide"><a href="https://ai-alignment.com?source=logo-lo_JuU2p2EvGepj---624d886c4aa4" class="u-flexCenter js-collectionLogoOrName"><span class="u-noWrapWithEllipsis u-maxWidth1032 u-uiTextBold u-fontSize26 u-textColorDarker">AI Alignment</span></a></div></div></div><div class="metabar-block u-flex0 u-flexCenter"><div class="u-flexCenter u-height65 u-xs-height56"><div class="buttonSet buttonSet--wide u-lineHeightInherit"><a class="button button--primary button--chromeless u-accentColor--buttonNormal is-inSiteNavBar u-xs-hide js-signInButton" href="https://medium.com/m/signin?redirect=https%3A%2F%2Fai-alignment.com%2Fthe-reward-engineering-problem-30285c779450&amp;source=--------------------------nav_reg&amp;operation=login" data-action="sign-in-prompt" data-redirect="https://ai-alignment.com/the-reward-engineering-problem-30285c779450" data-action-source="--------------------------nav_reg">Sign in</a><a class="button button--primary button--withChrome u-accentColor--buttonNormal is-inSiteNavBar js-signUpButton" href="https://medium.com/m/signin?redirect=https%3A%2F%2Fai-alignment.com%2Fthe-reward-engineering-problem-30285c779450&amp;source=--------------------------nav_reg&amp;operation=register" data-action="sign-up-prompt" data-redirect="https://ai-alignment.com/the-reward-engineering-problem-30285c779450" data-action-source="--------------------------nav_reg">Get started</a></div></div></div></div></div><div class="metabar metabar--spacer js-metabarSpacer u-height65 u-xs-height56"></div><main role="main"><article class=" u-minHeight100vhOffset65 u-overflowHidden postArticle postArticle--full is-withAccentColors u-marginBottom40" lang="en"><div class="postArticle-content js-postField js-notesSource js-trackPostScrolls" data-post-id="30285c779450" data-source="post_page" data-collection-id="624d886c4aa4" data-tracking-context="postPage" data-scroll="native"><section name="9bd7" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h1 name="4104" id="4104" class="graf graf--h3 graf--leading graf--title">The reward engineering problem</h1><div class="uiScale uiScale-ui--regular uiScale-caption--regular u-flexCenter u-marginVertical24 u-fontSize15 js-postMetaLockup"><div class="u-flex0"><a class="link u-baseColor--link avatar" href="https://ai-alignment.com/@paulfchristiano?source=post_header_lockup" data-action="show-user-card" data-action-source="post_header_lockup" data-action-value="57f1a655a613" data-action-type="hover" data-user-id="57f1a655a613" data-collection-slug="ai-control" dir="auto"><img src="https://cdn-images-1.medium.com/fit/c/50/50/1*BNjZCuQuRfIgcXCBMipuBw.jpeg" class="avatar-image u-size50x50" alt="Go to the profile of Paul Christiano"></a></div><div class="u-flex1 u-paddingLeft15 u-overflowHidden"><div class="u-paddingBottom3"><a class="ds-link ds-link--styleSubtle ui-captionStrong u-inlineBlock link link--darken link--darker" href="https://ai-alignment.com/@paulfchristiano" data-action="show-user-card" data-action-value="57f1a655a613" data-action-type="hover" data-user-id="57f1a655a613" data-collection-slug="ai-control" dir="auto">Paul Christiano</a><span class="followState js-followState" data-user-id="57f1a655a613"><button class="button button--smallest u-noUserSelect button--withChrome u-baseColor--buttonNormal button--withHover button--unblock js-unblockButton u-marginLeft10 u-xs-hide" data-action="sign-up-prompt" data-sign-in-action="toggle-block-user" data-requires-token="true" data-redirect="https://ai-alignment.com/the-reward-engineering-problem-30285c779450" data-action-source="post_header_lockup"><span class="button-label  button-defaultState">Blocked</span><span class="button-label button-hoverState">Unblock</span></button><button class="button button--primary button--smallest button--dark u-noUserSelect button--withChrome u-accentColor--buttonDark button--follow js-followButton u-marginLeft10 u-xs-hide" data-action="sign-up-prompt" data-sign-in-action="toggle-subscribe-user" data-requires-token="true" data-redirect="https://medium.com/_/subscribe/user/57f1a655a613" data-action-source="post_header_lockup-57f1a655a613-------------------------follow_byline"><span class="button-label  button-defaultState js-buttonLabel">Follow</span><span class="button-label button-activeState">Following</span></button></span></div><div class="ui-caption u-noWrapWithEllipsis js-testPostMetaInlineSupplemental"><time datetime="2016-05-30T23:31:10.254Z">May 30, 2016</time><span class="middotDivider u-fontSize12"></span><span class="readingTime" title="9 min read"></span></div></div></div><p name="67a5" id="67a5" class="graf graf--p graf-after--h3">Today we usually train reinforcement learning agents to perform narrow tasks with simple goals. We may eventually want to train RL agents to behave “well” in open-ended environments where there is no simple goal.</p><p name="7255" id="7255" class="graf graf--p graf-after--p">Suppose that we are trying to train an RL agent <strong class="markup--strong markup--p-strong">A</strong>. In each episode, <strong class="markup--strong markup--p-strong">A</strong> interacts with an environment, producing a transcript τ. We then <em class="markup--em markup--p-em">evaluate</em> that transcript, producing a reward <em class="markup--em markup--p-em">r</em> ∈ [0, 1]. <strong class="markup--strong markup--p-strong">A</strong> is trained is to maximize its reward.</p><p name="26d0" id="26d0" class="graf graf--p graf-after--p">We would like to set up the rewards so that <strong class="markup--strong markup--p-strong">A</strong> will learn to behave well — that is, such that <em class="markup--em markup--p-em">if</em> <strong class="markup--strong markup--p-strong">A</strong> learns to receive a high reward, <em class="markup--em markup--p-em">then</em> we will be happy with <strong class="markup--strong markup--p-strong">A</strong>’s behavior.</p><p name="c11c" id="c11c" class="graf graf--p graf-after--p">To make the problem feasible, we assume that we have access to another agent <strong class="markup--strong markup--p-strong">H</strong> which</p><ol class="postList"><li name="700f" id="700f" class="graf graf--li graf-after--p">is “smarter” than <strong class="markup--strong markup--li-strong">A</strong>, and</li><li name="dcdf" id="dcdf" class="graf graf--li graf-after--li">makes “good” decisions.</li></ol><p name="90d6" id="90d6" class="graf graf--p graf-after--li">In order to evaluate transcript τ, we allow ourselves to make any number of calls to <strong class="markup--strong markup--p-strong">H</strong>, and to use any other tools that are available. The question is: how do we carry out the evaluation, so that the optimal strategy for <strong class="markup--strong markup--p-strong">A</strong> is to also make “good” decisions?</p><p name="9925" id="9925" class="graf graf--p graf-after--p"><a href="https://medium.com/@paulfchristiano/30285c779450" data-href="https://medium.com/@paulfchristiano/30285c779450" class="markup--anchor markup--p-anchor" target="_blank">Following Daniel Dewey</a>, I’ll call this the <em class="markup--em markup--p-em">reward engineering problem</em>.</p><p name="3d71" id="3d71" class="graf graf--p graf-after--p">Note that our evaluation process may be quite expensive, and actually implementing it may be infeasible. To build a working system, we would need to combine this evaluation with <a href="https://medium.com/ai-control/semi-supervised-reinforcement-learning-cf7d5375197f#.rm5dypm4a" data-href="https://medium.com/ai-control/semi-supervised-reinforcement-learning-cf7d5375197f#.rm5dypm4a" class="markup--anchor markup--p-anchor" target="_blank">semi-supervised RL</a> and <a href="https://medium.com/ai-control/learning-with-catastrophes-59387b55cc30#.vctnbxafg" data-href="https://medium.com/ai-control/learning-with-catastrophes-59387b55cc30#.vctnbxafg" class="markup--anchor markup--p-anchor" target="_blank">learning with catastrophes</a>.</p><h4 name="1ebd" id="1ebd" class="graf graf--h4 graf-after--p">Possible approaches and remaining problems</h4><p name="a589" id="a589" class="graf graf--p graf-after--h4">I know of 3 basic approaches to reward engineering:</p><ol class="postList"><li name="e1a0" id="e1a0" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Direct supervision</strong>. Use <strong class="markup--strong markup--li-strong">H</strong> to evaluate <strong class="markup--strong markup--li-strong">A</strong>’s behavior, and train <strong class="markup--strong markup--li-strong">A</strong> to maximize <strong class="markup--strong markup--li-strong">H</strong>’s evaluations. In some contexts we could <a href="https://medium.com/ai-control/optimizing-with-comparisons-c02b8c0d7877#.jx6i2cxxu" data-href="https://medium.com/ai-control/optimizing-with-comparisons-c02b8c0d7877#.jx6i2cxxu" class="markup--anchor markup--li-anchor" target="_blank">compare two behaviors</a> instead of evaluating one in isolation.</li><li name="1095" id="1095" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Imitation learning</strong>. Use <strong class="markup--strong markup--li-strong">H</strong> to generate a bunch of transcripts, and train <strong class="markup--strong markup--li-strong">A</strong> to produce similar-looking transcripts. For example, we could train a model to distinguish <strong class="markup--strong markup--li-strong">A</strong>’s behavior from <strong class="markup--strong markup--li-strong">H</strong>’s behavior, and reward <strong class="markup--strong markup--li-strong">A</strong> when it fools the distinguisher.</li><li name="ca47" id="ca47" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Inverse reinforcement learning</strong>. Use <strong class="markup--strong markup--li-strong">H</strong> to generate a bunch of transcripts, and then infer a reward function which is being approximately optimized by <strong class="markup--strong markup--li-strong">H</strong>. Use this reward function to evaluate <strong class="markup--strong markup--li-strong">A</strong>’s behavior.</li></ol><p name="66a8" id="66a8" class="graf graf--p graf-after--li">All of these approaches are promising but face significant challenges. I’ll describe some of these problems in the next 3 sections.</p><h3 name="8bcc" id="8bcc" class="graf graf--h3 graf-after--p">1. Direct supervision</h3><p name="98e4" id="98e4" class="graf graf--p graf-after--h3">In direct supervision, <strong class="markup--strong markup--p-strong">H</strong> looks at a transcript of <strong class="markup--strong markup--p-strong">A</strong>’s behavior, and estimates how good that transcript is.</p><p name="e67e" id="e67e" class="graf graf--p graf-after--p">To see the problem with this scheme, suppose that <strong class="markup--strong markup--p-strong">A</strong> has been asked to draw a picture, and <strong class="markup--strong markup--p-strong">A</strong> does it by copying an existing picture with some modifications. If originality is especially important, then this may be a very “bad” policy. But even if <strong class="markup--strong markup--p-strong">H</strong> is much smarter than <strong class="markup--strong markup--p-strong">A</strong>, it may be hard to tell that the picture is not original — creating a derivative work only requires looking at a single existing picture, while checking if a work is derivative requires considering <em class="markup--em markup--p-em">every </em>picture.</p><p name="c2c5" id="c2c5" class="graf graf--p graf-after--p">More formally: in order for direct supervision to be effective, <a href="https://medium.com/ai-control/adequate-oversight-25fadf1edce9#.1aj4sfjiu" data-href="https://medium.com/ai-control/adequate-oversight-25fadf1edce9#.1aj4sfjiu" class="markup--anchor markup--p-anchor" target="_blank"><strong class="markup--strong markup--p-strong">H</strong> needs to be better-informed than <strong class="markup--strong markup--p-strong">A</strong> about what is “good.”</a> If this condition is satisfied, then from <strong class="markup--strong markup--p-strong">A</strong>’s perspective, estimating <strong class="markup--strong markup--p-strong">H</strong>’s estimate of goodness is equivalent to estimating actual goodness. This condition is superficially plausible — after all, we did assume that <strong class="markup--strong markup--p-strong">H</strong> is smarter than <strong class="markup--strong markup--p-strong">A</strong>.</p><p name="cb40" id="cb40" class="graf graf--p graf-after--p">The problem is that when <strong class="markup--strong markup--p-strong">A</strong> picks an action, <strong class="markup--strong markup--p-strong">A</strong> is especially well-informed about that action — the computation which produced the action provides evidence about it, and <strong class="markup--strong markup--p-strong">H </strong>may not have access to that evidence.</p><h4 name="12df" id="12df" class="graf graf--h4 graf-after--p">Transparency</h4><p name="4e13" id="4e13" class="graf graf--p graf-after--h4">One response is to let <strong class="markup--strong markup--p-strong">H</strong> see <em class="markup--em markup--p-em">how</em> <strong class="markup--strong markup--p-strong">A</strong> computed its action. If <strong class="markup--strong markup--p-strong">H</strong> can understand that process, then <strong class="markup--strong markup--p-strong">H</strong> may be able to effectively evaluate the action.</p><p name="73ab" id="73ab" class="graf graf--p graf-after--p">Sometimes this is straightforward: for example, if <strong class="markup--strong markup--p-strong">A</strong> uses an attention mechanism to look at a particular painting and copy it, we can simply tell <strong class="markup--strong markup--p-strong">H </strong>what <strong class="markup--strong markup--p-strong">A</strong> looked at.</p><p name="d1cc" id="d1cc" class="graf graf--p graf-after--p">In other contexts it might be much more challenging. For example, <strong class="markup--strong markup--p-strong">A</strong> may copy an image by “memorizing” the image in its weights, rather than by “looking at” the image at test time.</p><p name="e187" id="e187" class="graf graf--p graf-after--p">One approach to these challenging cases is to train <strong class="markup--strong markup--p-strong">A</strong> to produce actions <em class="markup--em markup--p-em">and</em> to produce explanations that are maximally helpful for evaluating those actions. For example, we may train <strong class="markup--strong markup--p-strong">A</strong> to produce images <em class="markup--em markup--p-em">and</em> to point out similarities between its output and training images.</p><p name="bf1e" id="bf1e" class="graf graf--p graf-after--p">This is a challenging problem for several reasons. One issue is that producing these explanations involves a huge “action space” and a very complex objective. A more subtle problem is that there are two conflicting objectives: <strong class="markup--strong markup--p-strong">A</strong> wants to produce actions that <strong class="markup--strong markup--p-strong">H</strong> evaluates as “good,” but providing useful information will sometimes lead <strong class="markup--strong markup--p-strong">H</strong> to produce a lower evaluation. Training <strong class="markup--strong markup--p-strong">A</strong> to do both tasks requires a new approach.</p><h4 name="2d0e" id="2d0e" class="graf graf--h4 graf-after--p">Other problems</h4><p name="7262" id="7262" class="graf graf--p graf-after--h4">We can imagine other failure modes of direct supervision. For example, <strong class="markup--strong markup--p-strong">A</strong> may find an action that exploits one of <strong class="markup--strong markup--p-strong">H</strong>’s biases or blind spots in order to receive a high rating.</p><p name="ab80" id="ab80" class="graf graf--p graf-after--p">We hope that these “attacks” can only succeed if <strong class="markup--strong markup--p-strong">H</strong> is ignorant about the process that produced a given action, and so can be resolved by whatever form of transparency allows <strong class="markup--strong markup--p-strong">H</strong> to accurately evaluate <strong class="markup--strong markup--p-strong">A</strong>’s actions in general.</p><p name="3b91" id="3b91" class="graf graf--p graf-after--p">That is, if <strong class="markup--strong markup--p-strong">A</strong> carefully explains to <strong class="markup--strong markup--p-strong">H</strong> how an action was chosen to exploit <strong class="markup--strong markup--p-strong">H</strong>’s biases, then <strong class="markup--strong markup--p-strong">H</strong> can hopefully avoid being exploited. This seems especially plausible given that <strong class="markup--strong markup--p-strong">H</strong> is smarter than <strong class="markup--strong markup--p-strong">A</strong>.</p><h3 name="2c89" id="2c89" class="graf graf--h3 graf-after--p">2. Imitation learning</h3><p name="6d37" id="6d37" class="graf graf--p graf-after--h3">Imitation learning has two conceptual problems:</p><ul class="postList"><li name="a929" id="a929" class="graf graf--li graf-after--p">If <strong class="markup--strong markup--li-strong">H</strong> is more competent than <strong class="markup--strong markup--li-strong">A</strong>, then <strong class="markup--strong markup--li-strong">A</strong> will generally be unable to imitate <strong class="markup--strong markup--li-strong">H</strong>’s behavior.</li><li name="8ae8" id="8ae8" class="graf graf--li graf-after--li">We don’t have a totally satisfactory framework for reducing imitation learning to an optimization problem.</li></ul><h4 name="53ec" id="53ec" class="graf graf--h4 graf-after--li">What if A can’t imitate&nbsp;H?</h4><p name="12ab" id="12ab" class="graf graf--p graf-after--h4">Suppose that <strong class="markup--strong markup--p-strong">A</strong> has been asked to build a block tower. <strong class="markup--strong markup--p-strong">H</strong> can quickly stack the blocks, and 99% of the time the tower stays standing; 1% of the time <strong class="markup--strong markup--p-strong">H</strong> messes up and the tower falls down. <strong class="markup--strong markup--p-strong">A</strong> is not as capable as <strong class="markup--strong markup--p-strong">H</strong>, and so if it tries to stack the blocks quickly the tower falls down 100% of the time.</p><p name="1708" id="1708" class="graf graf--p graf-after--p">The “best” behavior for <strong class="markup--strong markup--p-strong">A </strong>may be to stack the blocks more slowly, so that the tower can stay standing. But this behavior is hard to induce with imitation learning, because <strong class="markup--strong markup--p-strong">H</strong> <em class="markup--em markup--p-em">never</em> stacks the blocks slowly. Instead, an imitation learner is more likely to try to stack the blocks quickly and fail (since at least <strong class="markup--strong markup--p-strong">H </strong>does this 1% of the time).</p><p name="232e" id="232e" class="graf graf--p graf-after--p">One response to this problem is to have <strong class="markup--strong markup--p-strong">H</strong> “dumb down” its behavior so that it can be copied by <strong class="markup--strong markup--p-strong">A</strong>.</p><p name="f4f9" id="f4f9" class="graf graf--p graf-after--p">However, this process may be challenging for <strong class="markup--strong markup--p-strong">H</strong>. Finding a way to do a task which is within <strong class="markup--strong markup--p-strong">A</strong>’s abilities may be much harder than simply doing the task — for example, it may require a deep understanding of <strong class="markup--strong markup--p-strong">A</strong>’s limitations and capabilities.</p><p name="9c6d" id="9c6d" class="graf graf--p graf-after--p">I’ve proposed a procedure, “<a href="https://medium.com/ai-control/mimicry-maximization-and-meeting-halfway-c149dd23fc17#.l513cw5l0" data-href="https://medium.com/ai-control/mimicry-maximization-and-meeting-halfway-c149dd23fc17#.l513cw5l0" class="markup--anchor markup--p-anchor" target="_blank">meeting halfway</a>,” for addressing this problem. The idea is that we train a discriminator to distinguish <strong class="markup--strong markup--p-strong">H</strong>’s behavior from <strong class="markup--strong markup--p-strong">A</strong>’s behavior, and use the discriminator’s output to help <strong class="markup--strong markup--p-strong">H</strong> behave in an “<strong class="markup--strong markup--p-strong">A</strong>-like” way. This proposal faces many challenges, and it’s not at all clear if it can work.</p><h4 name="5211" id="5211" class="graf graf--h4 graf-after--p">How do you train an imitator?</h4><p name="02cc" id="02cc" class="graf graf--p graf-after--h4">The plagiarism example from the last section is also a challenge for imitation learning. Suppose that <strong class="markup--strong markup--p-strong">A </strong>has been asked to draw a picture. <strong class="markup--strong markup--p-strong">H </strong>would draw a completely original picture. How can we train <strong class="markup--strong markup--p-strong">A</strong> to draw an original picture?</p><p name="758b" id="758b" class="graf graf--p graf-after--p">The most plausible existing approach is probably generative adversarial networks. In this approach, a discriminator is trained to distinguish <strong class="markup--strong markup--p-strong">A</strong>’s behavior from <strong class="markup--strong markup--p-strong">H</strong>’s behavior, and <strong class="markup--strong markup--p-strong">A</strong> is trained to fool the discriminator.</p><p name="f634" id="f634" class="graf graf--p graf-after--p">But suppose that <strong class="markup--strong markup--p-strong">A </strong>draws a picture by copying an existing image. It may be hard for the discriminator to learn to distinguish “original image” from “derivative of existing image,” for exactly the same reasons discussed before. And so <strong class="markup--strong markup--p-strong">A</strong> may receive just as high a reward by copying an existing image as by drawing a novel picture.</p><p name="c8df" id="c8df" class="graf graf--p graf-after--p">Unfortunately, solving this problem seems even more difficult for reinforcement learning. We can’t give the discriminator any access to <strong class="markup--strong markup--p-strong">A</strong>’s internal state, since the discriminator isn’t supposed to know whether it is looking at data that came from <strong class="markup--strong markup--p-strong">A</strong> or from <strong class="markup--strong markup--p-strong">H</strong>.</p><p name="a87a" id="a87a" class="graf graf--p graf-after--p">Instead, it might be easier to use an alternative to the generative adversarial networks framework. There are some plausible contenders, but nothing is currently known that could plausibly scale to general behavior in complex environments. (Though the obstacles are not always obvious.)</p><h3 name="a48a" id="a48a" class="graf graf--h3 graf-after--p">3. Inverse reinforcement learning</h3><p name="6255" id="6255" class="graf graf--p graf-after--h3">In IRL, we try to infer a reward function that <strong class="markup--strong markup--p-strong">H </strong>is approximately maximizing. We can then use that reward function to train <strong class="markup--strong markup--p-strong">A</strong>.</p><p name="5495" id="5495" class="graf graf--p graf-after--p">This approach is closely connected to imitation learning, and faces exactly analogous difficulties:</p><ul class="postList"><li name="7b7d" id="7b7d" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">H</strong>’s behavior does not give much information about the reward function in regions far from <strong class="markup--strong markup--li-strong">H</strong>’s trajectory.</li><li name="0182" id="0182" class="graf graf--li graf-after--li">If we first learn a reward function and then use it to train <strong class="markup--strong markup--li-strong">A,</strong> then the reward function is essentially a direct supervisor and faces exactly the same difficulties.</li></ul><p name="85dc" id="85dc" class="graf graf--p graf-after--li">The second problem seems to be the most serious: unless we find a resolution to that problem, then direct supervision seems more promising than IRL. (Though IRL <a href="https://medium.com/ai-control/learn-policies-or-goals-348add76b8eb#.rvsv6syfl" data-href="https://medium.com/ai-control/learn-policies-or-goals-348add76b8eb#.rvsv6syfl" class="markup--anchor markup--p-anchor" target="_blank">may still be a useful technique for the resulting RL problem</a> — understanding the supervisor’s values is a critical subtask of solving an RL problem defined by direct supervision.)</p><h4 name="1dc3" id="1dc3" class="graf graf--h4 graf-after--p"><strong class="markup--strong markup--h4-strong">H’s behavior is not sufficiently informative</strong></h4><p name="bf9c" id="bf9c" class="graf graf--p graf-after--h4">Consider the block tower example from the last section. If <strong class="markup--strong markup--p-strong">H</strong> always quickly builds a perfect block tower, then <strong class="markup--strong markup--p-strong">H</strong>’s behavior does not give any evidence about tradeoffs between different imperfections: how much should <strong class="markup--strong markup--p-strong">A</strong> be willing to compromise on quality to get the job done faster? If the tower can only be tall <em class="markup--em markup--p-em">or</em> stable, which is preferred?</p><p name="7ad0" id="7ad0" class="graf graf--p graf-after--p">To get around this difficulty, we would like to elicit information from <strong class="markup--strong markup--p-strong">H </strong>other than trajectories. For example, we might ask <strong class="markup--strong markup--p-strong">H </strong>questions, and use those questions as evidence about <strong class="markup--strong markup--p-strong">H</strong>’s reward function.</p><p name="82aa" id="82aa" class="graf graf--p graf-after--p">Incorporating this information is much less straightforward than incorporating information from <strong class="markup--strong markup--p-strong">H</strong>’s behavior. For example, updating on <strong class="markup--strong markup--p-strong">H</strong>’s statements require an explicit model of how <strong class="markup--strong markup--p-strong">H</strong> believes its statements relate to its goals, even though we can’t directly observe that relationship. This is much more complex than existing approaches like MaxEnt IRL, which fit a simple model directly to <strong class="markup--strong markup--p-strong">H</strong>’s behavior.</p><p name="4e1e" id="4e1e" class="graf graf--p graf-after--p">These issues are central in “cooperative IRL.” For now there are many open problems.</p><h4 name="7207" id="7207" class="graf graf--h4 graf-after--p">The major difficulties of direct supervision still&nbsp;apply</h4><p name="c192" id="c192" class="graf graf--p graf-after--h4">The bigger problem for IRL is how to represent the reward function:</p><ul class="postList"><li name="00ef" id="00ef" class="graf graf--li graf-after--p">If the reward function is represented by a concrete, learned function from trajectories to rewards, then we are back in the situation of direct supervision.</li><li name="0783" id="0783" class="graf graf--li graf-after--li">Instead the reward function may act on an abstract space of “possible worlds.” This approach potentially avoids the difficulties of direct supervision, but it seems to require a particular form of model-based RL. It’s not clear if this constraint will be compatible with the most effective approaches to reinforcement learning.</li></ul><p name="139b" id="139b" class="graf graf--p graf-after--li">Ideally we would find a better representation that incorporates the best of both worlds — avoiding the difficulties of direct supervision, without seriously restricting the form of <strong class="markup--strong markup--p-strong">A</strong>.</p><p name="d60b" id="d60b" class="graf graf--p graf-after--p">Alternatively, we could hope that powerful RL agents have an appropriate model-based architecture. Or we could do research on appropriate forms of model-based RL to increase the probability that they are competitive.</p><h3 name="5939" id="5939" class="graf graf--h3 graf-after--p">Research directions</h3><p name="80ad" id="80ad" class="graf graf--p graf-after--h3">Each of the problems discussed in this post is a possible direction for research. I think that three problems are especially promising:</p><ul class="postList"><li name="da43" id="da43" class="graf graf--li graf-after--p">Training ML systems to produce the kind of auxiliary information that could make direct supervision reliable. There are open theoretical questions about how this training should be done — and huge practical obstacles to actually making it work.</li><li name="80f1" id="80f1" class="graf graf--li graf-after--li">Developing alternative objectives for imitation learning or generative modeling. There has been a lot of recent progress in this area, and it is probably worth doing more conceptual work to see if we can find new frameworks.</li><li name="2492" id="2492" class="graf graf--li graf-after--li">Experimenting with “meeting halfway,” or with other practical approaches for producing imitable demonstrations.</li></ul><h3 name="ff7c" id="ff7c" class="graf graf--h3 graf-after--li">Conclusion</h3><p name="19d1" id="19d1" class="graf graf--p graf-after--h3">If we cannot solve the reward engineering problem in practice, it seems unlikely that we will be able to train robustly beneficial RL agents.</p><p name="7866" id="7866" class="graf graf--p graf-after--p">Conversely, if we can solve the reward engineering problem, then I believe that solution could be leveraged into an attack on the whole value alignment problem (along <a href="https://medium.com/ai-control/alba-an-explicit-proposal-for-aligned-ai-17a55f60bbcf" data-href="https://medium.com/ai-control/alba-an-explicit-proposal-for-aligned-ai-17a55f60bbcf" class="markup--anchor markup--p-anchor" target="_blank">these lines</a> — I will discuss this in more detail over my next few posts).</p><p name="66b4" id="66b4" class="graf graf--p graf-after--p">Reward engineering is not only an important question for AI control, but also appears to be tractable today; there are both theoretical and experimental lines of attack. I’m optimistic that we will understand this problem much better over the coming years, and I think that will be very good news for AI control.</p><p name="b84c" id="b84c" class="graf graf--p graf-after--p graf--trailing"><em class="markup--em markup--p-em">(This research was supported as part of the </em><a href="http://futureoflife.org" data-href="http://futureoflife.org" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank"><em class="markup--em markup--p-em">Future of Life Institute</em></a><em class="markup--em markup--p-em"> FLI-RFP-AI1 program, grant #2015–143898.)</em></p></div></div></section></div><footer class="u-paddingTop10"><div class="container u-maxWidth740"><div class="row"><div class="col u-size12of12"></div></div><div class="row"><div class="col u-size12of12 js-postTags"><div class="u-paddingBottom10"><ul class="tags tags--postTags tags--borderless"><li><a class="link u-baseColor--link" href="https://ai-alignment.com/tagged/machine-learning?source=post" data-action-source="post" data-collection-slug="ai-control">Machine Learning</a></li><li><a class="link u-baseColor--link" href="https://ai-alignment.com/tagged/artificial-intelligence?source=post" data-action-source="post" data-collection-slug="ai-control">Artificial Intelligence</a></li></ul></div></div></div><div class="postActions js-postActionsFooter "><div class="u-flexCenter"><div class="u-flex1"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="30285c779450" data-is-icon-29px="true" data-is-circle="true" data-has-recommend-list="true" data-source="post_actions_footer-----30285c779450---------------------clap_footer" data-clap-string-singular="clap" data-clap-string-plural="claps"><div class="u-relative u-foreground"><button class="button button--large button--circle button--withChrome u-baseColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--darker clapButton--largePill u-relative u-foreground u-xs-paddingLeft13 u-width60 u-height60 u-accentColor--textNormal u-accentColor--buttonNormal clap-onboardingcollection" data-action="sign-up-prompt" data-sign-in-action="multivote" data-requires-token="true" data-redirect="https://medium.com/_/vote/p/30285c779450" data-action-source="post_actions_footer-----30285c779450---------------------clap_footer" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--33px u-relative u-topNegative2 u-xs-top0"><svg class="svgIcon-use" width="33" height="33"><path d="M28.86 17.342l-3.64-6.402c-.292-.433-.712-.729-1.163-.8a1.124 1.124 0 0 0-.889.213c-.63.488-.742 1.181-.33 2.061l1.222 2.587 1.4 2.46c2.234 4.085 1.511 8.007-2.145 11.663-.26.26-.526.49-.797.707 1.42-.084 2.881-.683 4.292-2.094 3.822-3.823 3.565-7.876 2.05-10.395zm-6.252 11.075c3.352-3.35 3.998-6.775 1.978-10.469l-3.378-5.945c-.292-.432-.712-.728-1.163-.8a1.122 1.122 0 0 0-.89.213c-.63.49-.742 1.182-.33 2.061l1.72 3.638a.502.502 0 0 1-.806.568l-8.91-8.91a1.335 1.335 0 0 0-1.887 1.886l5.292 5.292a.5.5 0 0 1-.707.707l-5.292-5.292-1.492-1.492c-.503-.503-1.382-.505-1.887 0a1.337 1.337 0 0 0 0 1.886l1.493 1.492 5.292 5.292a.499.499 0 0 1-.353.854.5.5 0 0 1-.354-.147L5.642 13.96a1.338 1.338 0 0 0-1.887 0 1.338 1.338 0 0 0 0 1.887l2.23 2.228 3.322 3.324a.499.499 0 0 1-.353.853.502.502 0 0 1-.354-.146l-3.323-3.324a1.333 1.333 0 0 0-1.886 0 1.325 1.325 0 0 0-.39.943c0 .356.138.691.39.943l6.396 6.397c3.528 3.53 8.86 5.313 12.821 1.353zM12.73 9.26l5.68 5.68-.49-1.037c-.518-1.107-.426-2.13.224-2.89l-3.303-3.304a1.337 1.337 0 0 0-1.886 0 1.326 1.326 0 0 0-.39.944c0 .217.067.42.165.607zm14.787 19.184c-1.599 1.6-3.417 2.392-5.353 2.392-.349 0-.7-.03-1.058-.082a7.922 7.922 0 0 1-3.667.887c-3.049 0-6.115-1.626-8.359-3.87l-6.396-6.397A2.315 2.315 0 0 1 2 19.724a2.327 2.327 0 0 1 1.923-2.296l-.875-.875a2.339 2.339 0 0 1 0-3.3 2.33 2.33 0 0 1 1.24-.647l-.139-.139c-.91-.91-.91-2.39 0-3.3.884-.884 2.421-.882 3.301 0l.138.14a2.335 2.335 0 0 1 3.948-1.24l.093.092c.091-.423.291-.828.62-1.157a2.336 2.336 0 0 1 3.3 0l3.384 3.386a2.167 2.167 0 0 1 1.271-.173c.534.086 1.03.354 1.441.765.11-.549.415-1.034.911-1.418a2.12 2.12 0 0 1 1.661-.41c.727.117 1.385.565 1.853 1.262l3.652 6.423c1.704 2.832 2.025 7.377-2.205 11.607zM13.217.484l-1.917.882 2.37 2.837-.454-3.719zm8.487.877l-1.928-.86-.44 3.697 2.368-2.837zM16.5 3.293L15.478-.005h2.044L16.5 3.293z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--33px u-relative u-topNegative2 u-xs-top0"><svg class="svgIcon-use" width="33" height="33"><g fill-rule="evenodd"><path d="M29.58 17.1l-3.854-6.78c-.365-.543-.876-.899-1.431-.989a1.491 1.491 0 0 0-1.16.281c-.42.327-.65.736-.7 1.207v.001l3.623 6.367c2.46 4.498 1.67 8.802-2.333 12.807-.265.265-.536.505-.81.728 1.973-.222 3.474-1.286 4.45-2.263 4.166-4.165 3.875-8.6 2.215-11.36zm-4.831.82l-3.581-6.3c-.296-.439-.725-.742-1.183-.815a1.105 1.105 0 0 0-.89.213c-.647.502-.755 1.188-.33 2.098l1.825 3.858a.601.601 0 0 1-.197.747.596.596 0 0 1-.77-.067L10.178 8.21c-.508-.506-1.393-.506-1.901 0a1.335 1.335 0 0 0-.393.95c0 .36.139.698.393.95v.001l5.61 5.61a.599.599 0 1 1-.848.847l-5.606-5.606c-.001 0-.002 0-.003-.002L5.848 9.375a1.349 1.349 0 0 0-1.902 0 1.348 1.348 0 0 0 0 1.901l1.582 1.582 5.61 5.61a.6.6 0 0 1-.848.848l-5.61-5.61c-.51-.508-1.393-.508-1.9 0a1.332 1.332 0 0 0-.394.95c0 .36.139.697.393.952l2.363 2.362c.002.001.002.002.002.003l3.52 3.52a.6.6 0 0 1-.848.847l-3.522-3.523h-.001a1.336 1.336 0 0 0-.95-.393 1.345 1.345 0 0 0-.949 2.295l6.779 6.78c3.715 3.713 9.327 5.598 13.49 1.434 3.527-3.528 4.21-7.13 2.086-11.015zM11.817 7.727c.06-.328.213-.64.466-.893.64-.64 1.755-.64 2.396 0l3.232 3.232c-.82.783-1.09 1.833-.764 2.992l-5.33-5.33z"></path><path d="M13.285.48l-1.916.881 2.37 2.837z"></path><path d="M21.719 1.361L19.79.501l-.44 3.697z"></path><path d="M16.502 3.298L15.481 0h2.043z"></path></g></svg></span></span></button><div class="clapUndo u-width60 u-round u-height32 u-absolute u-borderBox u-paddingRight5 u-transition--transform200Springu-backgroundGrayLighter js-clapUndo" style="top: 14px; padding: 2px;"><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon u-floatRight" data-action="multivote-undo" data-action-value="30285c779450"><span class="svgIcon svgIcon--removeThin svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M20.13 8.11l-5.61 5.61-5.609-5.61-.801.801 5.61 5.61-5.61 5.61.801.8 5.61-5.609 5.61 5.61.8-.801-5.609-5.61 5.61-5.61" fill-rule="evenodd"></path></svg></span></button></div></div><span class="u-relative u-background js-actionMultirecommendCount u-marginLeft16"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-textColorDarker" data-action="show-recommends" data-action-value="30285c779450">121 claps</button><span class="u-xs-hide"></span></span></div></div><div class="buttonSet u-flex0"><a class="button button--dark button--chromeless u-baseColor--buttonDark button--withIcon button--withSvgIcon button--dark button--chromeless u-xs-hide u-marginRight12" href="https://medium.com/p/30285c779450/share/twitter" title="Share on Twitter" aria-label="Share on Twitter" target="_blank" data-action-source="post_actions_footer"><span class="button-defaultState"><span class="svgIcon svgIcon--twitterFilled svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M22.053 7.54a4.474 4.474 0 0 0-3.31-1.455 4.526 4.526 0 0 0-4.526 4.524c0 .35.04.7.082 1.05a12.9 12.9 0 0 1-9.3-4.77c-.39.69-.61 1.46-.65 2.26.03 1.6.83 2.99 2.02 3.79-.72-.02-1.41-.22-2.02-.57-.01.02-.01.04 0 .08-.01 2.17 1.55 4 3.63 4.44-.39.08-.79.13-1.21.16-.28-.03-.57-.05-.81-.08.54 1.77 2.21 3.08 4.2 3.15a9.564 9.564 0 0 1-5.66 1.94c-.34-.03-.7-.06-1.05-.08 2 1.27 4.38 2.02 6.94 2.02 8.31 0 12.86-6.9 12.84-12.85.02-.24.01-.43 0-.65.89-.62 1.65-1.42 2.26-2.34-.82.38-1.69.62-2.59.72a4.37 4.37 0 0 0 1.94-2.51c-.84.53-1.81.9-2.83 1.13z"></path></svg></span></span></a><a class="button button--dark button--chromeless u-baseColor--buttonDark button--withIcon button--withSvgIcon button--dark button--chromeless u-xs-hide u-marginRight12" href="https://medium.com/p/30285c779450/share/facebook" title="Share on Facebook" aria-label="Share on Facebook" target="_blank" data-action-source="post_actions_footer"><span class="button-defaultState"><span class="svgIcon svgIcon--facebookSquare svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M23.209 5H5.792A.792.792 0 0 0 5 5.791V23.21c0 .437.354.791.792.791h9.303v-7.125H12.72v-2.968h2.375v-2.375c0-2.455 1.553-3.662 3.741-3.662 1.049 0 1.95.078 2.213.112v2.565h-1.517c-1.192 0-1.469.567-1.469 1.397v1.963h2.969l-.594 2.968h-2.375L18.11 24h5.099a.791.791 0 0 0 .791-.791V5.79a.791.791 0 0 0-.791-.79"></path></svg></span></span></a><button class="button button--large button--dark button--chromeless u-baseColor--buttonDark button--withIcon button--withSvgIcon u-xs-show u-marginRight10" title="Share this story on Twitter or Facebook" aria-label="Share this story on Twitter or Facebook" data-action="show-share-popover" data-action-source="post_actions_footer"><span class="svgIcon svgIcon--share svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M20.385 8H19a.5.5 0 1 0 .011 1h1.39c.43 0 .84.168 1.14.473.31.305.48.71.48 1.142v10.77c0 .43-.17.837-.47 1.142-.3.305-.71.473-1.14.473H8.62c-.43 0-.84-.168-1.144-.473a1.603 1.603 0 0 1-.473-1.142v-10.77c0-.43.17-.837.48-1.142A1.599 1.599 0 0 1 8.62 9H10a.502.502 0 0 0 0-1H8.615c-.67 0-1.338.255-1.85.766-.51.51-.765 1.18-.765 1.85v10.77c0 .668.255 1.337.766 1.848.51.51 1.18.766 1.85.766h11.77c.668 0 1.337-.255 1.848-.766.51-.51.766-1.18.766-1.85v-10.77c0-.668-.255-1.337-.766-1.848A2.61 2.61 0 0 0 20.384 8zm-8.67-2.508L14 3.207v8.362c0 .27.224.5.5.5s.5-.23.5-.5V3.2l2.285 2.285a.49.49 0 0 0 .704-.001.511.511 0 0 0 0-.708l-3.14-3.14a.504.504 0 0 0-.71 0L11 4.776a.501.501 0 0 0 .71.706" fill-rule="evenodd"></path></svg></span></button><button class="button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon" data-action="scroll-to-responses" data-action-source="post_actions_footer"><span class="svgIcon svgIcon--response svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M21.27 20.058c1.89-1.826 2.754-4.17 2.754-6.674C24.024 8.21 19.67 4 14.1 4 8.53 4 4 8.21 4 13.384c0 5.175 4.53 9.385 10.1 9.385 1.007 0 2-.14 2.95-.41.285.25.592.49.918.7 1.306.87 2.716 1.31 4.19 1.31.276-.01.494-.14.6-.36a.625.625 0 0 0-.052-.65c-.61-.84-1.042-1.71-1.282-2.58a5.417 5.417 0 0 1-.154-.75zm-3.85 1.324l-.083-.28-.388.12a9.72 9.72 0 0 1-2.85.424c-4.96 0-8.99-3.706-8.99-8.262 0-4.556 4.03-8.263 8.99-8.263 4.95 0 8.77 3.71 8.77 8.27 0 2.25-.75 4.35-2.5 5.92l-.24.21v.32c0 .07 0 .19.02.37.03.29.1.6.19.92.19.7.49 1.4.89 2.08-.93-.14-1.83-.49-2.67-1.06-.34-.22-.88-.48-1.16-.74z"></path></svg></span></button><button class="button button--large button--dark button--chromeless is-touchIconFadeInPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="sign-up-prompt" data-sign-in-action="add-to-bookmarks" data-requires-token="true" data-redirect="https://medium.com/_/bookmark/p/30285c779450" data-action-source="post_actions_footer"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--29px u-marginRight4"><svg class="svgIcon-use" width="29" height="29"><path d="M19.385 4h-9.77A2.623 2.623 0 0 0 7 6.615V23.01a1.022 1.022 0 0 0 1.595.847l5.905-4.004 5.905 4.004A1.022 1.022 0 0 0 22 23.011V6.62A2.625 2.625 0 0 0 19.385 4zM21 23l-5.91-3.955-.148-.107a.751.751 0 0 0-.884 0l-.147.107L8 23V6.615C8 5.725 8.725 5 9.615 5h9.77C20.275 5 21 5.725 21 6.615V23z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--29px u-marginRight4"><svg class="svgIcon-use" width="29" height="29"><path d="M19.385 4h-9.77A2.623 2.623 0 0 0 7 6.615V23.01a1.022 1.022 0 0 0 1.595.847l5.905-4.004 5.905 4.004A1.022 1.022 0 0 0 22 23.011V6.62A2.625 2.625 0 0 0 19.385 4z" fill-rule="evenodd"></path></svg></span></span></button><button class="button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon js-moreActionsButton" title="More actions" aria-label="More actions" data-action="more-actions"><span class="svgIcon svgIcon--more svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="-480.5 272.5 21 21"><path d="M-463 284.6c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5zm-7-.9c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5zm-7-.9c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5z"></path></svg></span></button></div></div></div></div><div class="u-maxWidth740 u-paddingTop20 u-marginTop20 u-borderTopLightest container u-paddingBottom20 u-xs-paddingBottom10 js-postAttributionFooterContainer"><div class="row js-postFooterInfo"><div class="col u-size6of12 u-xs-size12of12"><li class="uiScale uiScale-ui--small uiScale-caption--regular u-block u-paddingBottom18 js-cardUser"><div class="u-marginLeft20 u-floatRight"><span class="followState js-followState" data-user-id="57f1a655a613"><button class="button button--small u-noUserSelect button--withChrome u-baseColor--buttonNormal button--withHover button--unblock js-unblockButton" data-action="sign-up-prompt" data-sign-in-action="toggle-block-user" data-requires-token="true" data-redirect="https://ai-alignment.com/the-reward-engineering-problem-30285c779450" data-action-source="footer_card"><span class="button-label  button-defaultState">Blocked</span><span class="button-label button-hoverState">Unblock</span></button><button class="button button--primary button--small u-noUserSelect button--withChrome u-accentColor--buttonNormal button--follow js-followButton" data-action="sign-up-prompt" data-sign-in-action="toggle-subscribe-user" data-requires-token="true" data-redirect="https://medium.com/_/subscribe/user/57f1a655a613" data-action-source="footer_card-57f1a655a613-------------------------follow_footer"><span class="button-label  button-defaultState js-buttonLabel">Follow</span><span class="button-label button-activeState">Following</span></button></span></div><div class="u-tableCell"><a class="link u-baseColor--link avatar" href="https://ai-alignment.com/@paulfchristiano?source=footer_card" title="Go to the profile of Paul Christiano" aria-label="Go to the profile of Paul Christiano" data-action-source="footer_card" data-user-id="57f1a655a613" data-collection-slug="ai-control" dir="auto"><img src="https://cdn-images-1.medium.com/fit/c/60/60/1*BNjZCuQuRfIgcXCBMipuBw.jpeg" class="avatar-image avatar-image--small" alt="Go to the profile of Paul Christiano"></a></div><div class="u-tableCell u-verticalAlignMiddle u-breakWord u-paddingLeft15"><h3 class="ui-h3 u-fontSize18 u-lineHeightTighter u-marginBottom4"><a class="link link--primary u-accentColor--hoverTextNormal" href="https://ai-alignment.com/@paulfchristiano" property="cc:attributionName" title="Go to the profile of Paul Christiano" aria-label="Go to the profile of Paul Christiano" rel="author cc:attributionUrl" data-user-id="57f1a655a613" data-collection-slug="ai-control" dir="auto">Paul Christiano</a></h3><p class="ui-body u-fontSize14 u-lineHeightBaseSans u-textColorDark u-marginBottom4">OpenAI</p></div></li></div><div class="col u-size6of12 u-xs-size12of12 u-xs-marginTop30"><li class="uiScale uiScale-ui--small uiScale-caption--regular u-block u-paddingBottom18 js-cardCollection"><div class="u-marginLeft20 u-floatRight"><button class="button button--primary button--small u-noUserSelect button--withChrome u-accentColor--buttonNormal js-relationshipButton" data-action="sign-up-prompt" data-sign-in-action="toggle-follow-collection" data-requires-token="true" data-redirect="https://medium.com/_/subscribe/collection/ai-control" data-action-source="footer_card----624d886c4aa4----------------------follow_footer" data-collection-id="624d886c4aa4"><span class="button-label  js-buttonLabel">Follow</span></button></div><div class="u-tableCell "><a class="link u-baseColor--link avatar avatar--roundedRectangle" href="https://ai-alignment.com?source=footer_card" title="Go to AI Alignment" aria-label="Go to AI Alignment" data-action-source="footer_card" data-collection-slug="ai-control"><img src="https://cdn-images-1.medium.com/fit/c/60/60/1*N56Qc5-aHTcfGff0scntKQ.png" class="avatar-image u-size60x60" alt="AI Alignment"></a></div><div class="u-tableCell u-verticalAlignMiddle u-breakWord u-paddingLeft15"><h3 class="ui-h3 u-fontSize18 u-lineHeightTighter u-marginBottom4"><a class="link link--primary u-accentColor--hoverTextNormal" href="https://ai-alignment.com?source=footer_card" rel="collection" data-action-source="footer_card" data-collection-slug="ai-control">AI Alignment</a></h3><p class="ui-body u-fontSize14 u-lineHeightBaseSans u-textColorDark u-marginBottom4">Aligning AI systems with human interests.</p><div class="buttonSet"></div></div></li></div></div></div><div class="js-postFooterPlacements" data-post-id="30285c779450" data-collection-id="624d886c4aa4" data-scroll="native"><div class="streamItem streamItem--placementCardGrid js-streamItem"><div class="u-clearfix u-backgroundGrayLightest"><div class="row u-marginAuto u-maxWidth1032 u-paddingTop30 u-paddingBottom40"><div class="col u-padding8 u-xs-size12of12 u-size4of12"><div class="uiScale uiScale-ui--small uiScale-caption--regular u-height280 u-width100pct u-backgroundWhite u-borderCardBorder u-boxShadow u-borderBox u-borderRadius4 js-trackPostPresentation" data-post-id="c0bee00365bd" data-source="placement_card_footer_grid---------0-41" data-tracking-context="placement"><div class="u-padding15 u-borderBox u-flexColumn u-sizeFull"><a class="link link--noUnderline u-baseColor--link u-flex1 u-flexColumn" href="https://ai-alignment.com/universality-and-consequentialism-within-hch-c0bee00365bd?source=placement_card_footer_grid---------0-41" data-action-source="placement_card_footer_grid---------0-41"><div class="uiScale uiScale-ui--regular uiScale-caption--small u-textColorNormal u-marginBottom7">More from AI Alignment</div><div class="ui-h3 ui-clamp2 u-textColorDarkest u-contentSansBold u-fontSize24 u-maxHeight2LineHeightTighter u-lineClamp2 u-textOverflowEllipsis u-letterSpacingTight u-paddingBottom2">Universality and consequentialism within HCH</div><div class="ui-body ui-clamp2 u-lineClamp2 u-textOverflowEllipsis u-maxHeight2LineHeightTighter">One exotic reason HCH can fail to be universal is the emergence of malicious patterns of behavior; universality may help address this risk.</div></a><div class="u-paddingBottom10 u-flex0 u-flexCenter"><div class="u-flex1 u-minWidth0 u-marginRight10"><div class="u-flexCenter"><div class="postMetaInline-avatar u-flex0"><a class="link u-baseColor--link avatar" href="https://ai-alignment.com/@paulfchristiano" data-action="show-user-card" data-action-value="57f1a655a613" data-action-type="hover" data-user-id="57f1a655a613" data-collection-slug="ai-control" dir="auto"><img src="https://cdn-images-1.medium.com/fit/c/36/36/1*BNjZCuQuRfIgcXCBMipuBw.jpeg" class="avatar-image u-size36x36 u-xs-size32x32" alt="Go to the profile of Paul Christiano"></a></div><div class="postMetaInline postMetaInline-authorLockup ui-captionStrong u-flex1 u-noWrapWithEllipsis"><a class="ds-link ds-link--styleSubtle link link--darken link--darker" href="https://ai-alignment.com/@paulfchristiano?source=placement_card_footer_grid---------0-41" data-action="show-user-card" data-action-source="placement_card_footer_grid---------0-41" data-action-value="57f1a655a613" data-action-type="hover" data-user-id="57f1a655a613" data-collection-slug="ai-control" dir="auto">Paul Christiano</a><div class="ui-caption u-fontSize12 u-baseColor--textNormal u-textColorNormal js-postMetaInlineSupplemental"><a class="link link--darken" href="https://ai-alignment.com/universality-and-consequentialism-within-hch-c0bee00365bd?source=placement_card_footer_grid---------0-41" data-action="open-post" data-action-value="https://ai-alignment.com/universality-and-consequentialism-within-hch-c0bee00365bd?source=placement_card_footer_grid---------0-41" data-action-source="preview-listing"><time datetime="2019-01-10T03:50:05.776Z">Jan 9</time></a><span class="middotDivider u-fontSize12"></span><span class="readingTime" title="9 min read"></span></div></div></div></div><div class="u-flex0 u-flexCenter"><div class="buttonSet"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="c0bee00365bd" data-is-label-padded="true" data-source="placement_card_footer_grid-----c0bee00365bd----0-41----------------clap_preview"><div class="u-relative u-foreground"><button class="button button--primary button--chromeless u-accentColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--darker" data-action="sign-up-prompt" data-sign-in-action="multivote" data-requires-token="true" data-redirect="https://medium.com/_/vote/p/c0bee00365bd" data-action-source="placement_card_footer_grid-----c0bee00365bd----0-41----------------clap_preview" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M11.739 0l.761 2.966L13.261 0z"></path><path d="M14.815 3.776l1.84-2.551-1.43-.471z"></path><path d="M8.378 1.224l1.84 2.551L9.81.753z"></path><path d="M20.382 21.622c-1.04 1.04-2.115 1.507-3.166 1.608.168-.14.332-.29.492-.45 2.885-2.886 3.456-5.982 1.69-9.211l-1.101-1.937-.955-2.02c-.315-.676-.235-1.185.245-1.556a.836.836 0 0 1 .66-.16c.342.056.66.28.879.605l2.856 5.023c1.179 1.962 1.379 5.119-1.6 8.098m-13.29-.528l-5.02-5.02a1 1 0 0 1 .707-1.701c.255 0 .512.098.707.292l2.607 2.607a.442.442 0 0 0 .624-.624L4.11 14.04l-1.75-1.75a.998.998 0 1 1 1.41-1.413l4.154 4.156a.44.44 0 0 0 .624 0 .44.44 0 0 0 0-.624l-4.152-4.153-1.172-1.171a.998.998 0 0 1 0-1.41 1.018 1.018 0 0 1 1.41 0l1.172 1.17 4.153 4.152a.437.437 0 0 0 .624 0 .442.442 0 0 0 0-.624L6.43 8.222a.988.988 0 0 1-.291-.705.99.99 0 0 1 .29-.706 1 1 0 0 1 1.412 0l6.992 6.993a.443.443 0 0 0 .71-.501l-1.35-2.856c-.315-.676-.235-1.185.246-1.557a.85.85 0 0 1 .66-.16c.342.056.659.28.879.606L18.628 14c1.573 2.876 1.067 5.545-1.544 8.156-1.396 1.397-3.144 1.966-5.063 1.652-1.713-.286-3.463-1.248-4.928-2.714zM10.99 5.976l2.562 2.562c-.497.607-.563 1.414-.155 2.284l.265.562-4.257-4.257a.98.98 0 0 1-.117-.445c0-.267.104-.517.292-.706a1.023 1.023 0 0 1 1.41 0zm8.887 2.06c-.375-.557-.902-.916-1.486-1.011a1.738 1.738 0 0 0-1.342.332c-.376.29-.61.656-.712 1.065a2.1 2.1 0 0 0-1.095-.562 1.776 1.776 0 0 0-.992.128l-2.636-2.636a1.883 1.883 0 0 0-2.658 0 1.862 1.862 0 0 0-.478.847 1.886 1.886 0 0 0-2.671-.012 1.867 1.867 0 0 0-.503.909c-.754-.754-1.992-.754-2.703-.044a1.881 1.881 0 0 0 0 2.658c-.288.12-.605.288-.864.547a1.884 1.884 0 0 0 0 2.659l.624.622a1.879 1.879 0 0 0-.91 3.16l5.019 5.02c1.595 1.594 3.515 2.645 5.408 2.959a7.16 7.16 0 0 0 1.173.098c1.026 0 1.997-.24 2.892-.7.279.04.555.065.828.065 1.53 0 2.969-.628 4.236-1.894 3.338-3.338 3.083-6.928 1.738-9.166l-2.868-5.043z"></path></g></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M11.738 0l.762 2.966L13.262 0z"></path><path d="M16.634 1.224l-1.432-.47-.408 3.022z"></path><path d="M9.79.754l-1.431.47 1.84 2.552z"></path><path d="M22.472 13.307l-3.023-5.32c-.287-.426-.689-.705-1.123-.776a1.16 1.16 0 0 0-.911.221c-.297.231-.474.515-.535.84.017.022.036.04.053.063l2.843 5.001c1.95 3.564 1.328 6.973-1.843 10.144a8.46 8.46 0 0 1-.549.501c1.205-.156 2.328-.737 3.351-1.76 3.268-3.268 3.041-6.749 1.737-8.914"></path><path d="M12.58 9.887c-.156-.83.096-1.569.692-2.142L10.78 5.252c-.5-.504-1.378-.504-1.879 0-.178.18-.273.4-.329.63l4.008 4.005z"></path><path d="M15.812 9.04c-.218-.323-.539-.55-.88-.606a.814.814 0 0 0-.644.153c-.176.137-.713.553-.24 1.566l1.43 3.025a.539.539 0 1 1-.868.612L7.2 6.378a.986.986 0 1 0-1.395 1.395l4.401 4.403a.538.538 0 1 1-.762.762L5.046 8.54 3.802 7.295a.99.99 0 0 0-1.396 0 .981.981 0 0 0 0 1.394L3.647 9.93l4.402 4.403a.537.537 0 0 1 0 .761.535.535 0 0 1-.762 0L2.89 10.696a.992.992 0 0 0-1.399-.003.983.983 0 0 0 0 1.395l1.855 1.854 2.763 2.765a.538.538 0 0 1-.76.761l-2.765-2.764a.982.982 0 0 0-1.395 0 .989.989 0 0 0 0 1.395l5.32 5.32c3.371 3.372 6.64 4.977 10.49 1.126C19.74 19.8 20.271 17 18.62 13.982L15.812 9.04z"></path></g></svg></span></span></button></div><span class="u-relative u-background js-actionMultirecommendCount u-marginLeft5"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-disablePointerEvents u-marginLeft4" data-action="show-recommends" data-action-value="c0bee00365bd">18</button></span></div></div><div class="u-height20 u-borderRightLighter u-inlineBlock u-relative u-marginRight10 u-marginLeft12"></div><div class="buttonSet"><button class="button button--chromeless is-touchIconFadeInPulse u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="sign-up-prompt" data-sign-in-action="add-to-bookmarks" data-requires-token="true" data-redirect="https://medium.com/_/bookmark/p/c0bee00365bd" data-action-source="placement_card_footer_grid-----c0bee00365bd----0-41----------------bookmark_preview"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126a.508.508 0 0 0 .708-.03.5.5 0 0 0 .118-.285H19V6zm-6.838 9.97L7 19.636V6c0-.55.45-1 1-1h9c.55 0 1 .45 1 1v13.637l-5.162-3.668a.49.49 0 0 0-.676 0z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126c.205.183.52.17.708-.03a.5.5 0 0 0 .118-.285H19V6z"></path></svg></span></span></button></div></div></div></div></div></div><div class="col u-padding8 u-xs-size12of12 u-size4of12"><div class="uiScale uiScale-ui--small uiScale-caption--regular u-height280 u-width100pct u-backgroundWhite u-borderCardBorder u-boxShadow u-borderBox u-borderRadius4 js-trackPostPresentation" data-post-id="f92ecfa9f3ce" data-source="placement_card_footer_grid---------1-60" data-tracking-context="placement"><a class="link link--noUnderline u-baseColor--link" href="https://towardsdatascience.com/td-in-reinforcement-learning-the-easy-way-f92ecfa9f3ce?source=placement_card_footer_grid---------1-60" data-action-source="placement_card_footer_grid---------1-60"><div class="u-backgroundCover u-backgroundColorGrayLight u-height100 u-width100pct u-borderBottomLight u-borderRadiusTop4" style="background-image: url(&quot;https://cdn-images-1.medium.com/fit/c/400/120/1*fDNG8FOhPb7_0xmjHy3wiw.png&quot;); background-position: 50% 50% !important;"></div></a><div class="u-padding15 u-borderBox u-flexColumn u-height180"><a class="link link--noUnderline u-baseColor--link u-flex1" href="https://towardsdatascience.com/td-in-reinforcement-learning-the-easy-way-f92ecfa9f3ce?source=placement_card_footer_grid---------1-60" data-action-source="placement_card_footer_grid---------1-60"><div class="uiScale uiScale-ui--regular uiScale-caption--small u-textColorNormal u-marginBottom7"><div class="u-floatRight u-textColorNormal"><span class="svgIcon svgIcon--star svgIcon--15px"><svg class="svgIcon-use" width="15" height="15"><path d="M7.438 2.324c.034-.099.09-.099.123 0l1.2 3.53a.29.29 0 0 0 .26.19h3.884c.11 0 .127.049.038.111L9.8 8.327a.271.271 0 0 0-.099.291l1.2 3.53c.034.1-.011.131-.098.069l-3.142-2.18a.303.303 0 0 0-.32 0l-3.145 2.182c-.087.06-.132.03-.099-.068l1.2-3.53a.271.271 0 0 0-.098-.292L2.056 6.146c-.087-.06-.071-.112.038-.112h3.884a.29.29 0 0 0 .26-.19l1.2-3.52z"></path></svg></span></div><div class="u-noWrapWithEllipsis u-marginRight40">Related reads</div></div><div class="ui-h3 ui-clamp2 u-textColorDarkest u-contentSansBold u-fontSize24 u-maxHeight2LineHeightTighter u-lineClamp2 u-textOverflowEllipsis u-letterSpacingTight u-paddingBottom2">TD in Reinforcement Learning, the Easy Way</div></a><div class="u-paddingBottom10 u-flex0 u-flexCenter"><div class="u-flex1 u-minWidth0 u-marginRight10"><div class="u-flexCenter"><div class="postMetaInline-avatar u-flex0"><a class="link u-baseColor--link avatar" href="https://towardsdatascience.com/@zsalloum" data-action="show-user-card" data-action-value="1f2b933522e2" data-action-type="hover" data-user-id="1f2b933522e2" data-collection-slug="towards-data-science" dir="auto"><img src="https://cdn-images-1.medium.com/fit/c/36/36/1*kAENWVwzuw04FVoOuN1ZSw.jpeg" class="avatar-image u-size36x36 u-xs-size32x32" alt="Go to the profile of Ziad SALLOUM"></a></div><div class="postMetaInline postMetaInline-authorLockup ui-captionStrong u-flex1 u-noWrapWithEllipsis"><a class="ds-link ds-link--styleSubtle link link--darken link--darker" href="https://towardsdatascience.com/@zsalloum?source=placement_card_footer_grid---------1-60" data-action="show-user-card" data-action-source="placement_card_footer_grid---------1-60" data-action-value="1f2b933522e2" data-action-type="hover" data-user-id="1f2b933522e2" data-collection-slug="towards-data-science" dir="auto">Ziad SALLOUM</a><div class="ui-caption u-fontSize12 u-baseColor--textNormal u-textColorNormal js-postMetaInlineSupplemental"><a class="link link--darken" href="https://towardsdatascience.com/td-in-reinforcement-learning-the-easy-way-f92ecfa9f3ce?source=placement_card_footer_grid---------1-60" data-action="open-post" data-action-value="https://towardsdatascience.com/td-in-reinforcement-learning-the-easy-way-f92ecfa9f3ce?source=placement_card_footer_grid---------1-60" data-action-source="preview-listing"><time datetime="2018-11-28T01:01:24.814Z">Nov 27, 2018</time></a><span class="middotDivider u-fontSize12"></span><span class="readingTime" title="8 min read"></span><span class="u-paddingLeft4"><span class="svgIcon svgIcon--star svgIcon--15px"><svg class="svgIcon-use" width="15" height="15"><path d="M7.438 2.324c.034-.099.09-.099.123 0l1.2 3.53a.29.29 0 0 0 .26.19h3.884c.11 0 .127.049.038.111L9.8 8.327a.271.271 0 0 0-.099.291l1.2 3.53c.034.1-.011.131-.098.069l-3.142-2.18a.303.303 0 0 0-.32 0l-3.145 2.182c-.087.06-.132.03-.099-.068l1.2-3.53a.271.271 0 0 0-.098-.292L2.056 6.146c-.087-.06-.071-.112.038-.112h3.884a.29.29 0 0 0 .26-.19l1.2-3.52z"></path></svg></span></span></div></div></div></div><div class="u-flex0 u-flexCenter"><div class="buttonSet"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="f92ecfa9f3ce" data-is-label-padded="true" data-source="placement_card_footer_grid-----f92ecfa9f3ce----1-60----------------clap_preview"><div class="u-relative u-foreground"><button class="button button--primary button--chromeless u-accentColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--darker" data-action="sign-up-prompt" data-sign-in-action="multivote" data-requires-token="true" data-redirect="https://medium.com/_/vote/p/f92ecfa9f3ce" data-action-source="placement_card_footer_grid-----f92ecfa9f3ce----1-60----------------clap_preview" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M11.739 0l.761 2.966L13.261 0z"></path><path d="M14.815 3.776l1.84-2.551-1.43-.471z"></path><path d="M8.378 1.224l1.84 2.551L9.81.753z"></path><path d="M20.382 21.622c-1.04 1.04-2.115 1.507-3.166 1.608.168-.14.332-.29.492-.45 2.885-2.886 3.456-5.982 1.69-9.211l-1.101-1.937-.955-2.02c-.315-.676-.235-1.185.245-1.556a.836.836 0 0 1 .66-.16c.342.056.66.28.879.605l2.856 5.023c1.179 1.962 1.379 5.119-1.6 8.098m-13.29-.528l-5.02-5.02a1 1 0 0 1 .707-1.701c.255 0 .512.098.707.292l2.607 2.607a.442.442 0 0 0 .624-.624L4.11 14.04l-1.75-1.75a.998.998 0 1 1 1.41-1.413l4.154 4.156a.44.44 0 0 0 .624 0 .44.44 0 0 0 0-.624l-4.152-4.153-1.172-1.171a.998.998 0 0 1 0-1.41 1.018 1.018 0 0 1 1.41 0l1.172 1.17 4.153 4.152a.437.437 0 0 0 .624 0 .442.442 0 0 0 0-.624L6.43 8.222a.988.988 0 0 1-.291-.705.99.99 0 0 1 .29-.706 1 1 0 0 1 1.412 0l6.992 6.993a.443.443 0 0 0 .71-.501l-1.35-2.856c-.315-.676-.235-1.185.246-1.557a.85.85 0 0 1 .66-.16c.342.056.659.28.879.606L18.628 14c1.573 2.876 1.067 5.545-1.544 8.156-1.396 1.397-3.144 1.966-5.063 1.652-1.713-.286-3.463-1.248-4.928-2.714zM10.99 5.976l2.562 2.562c-.497.607-.563 1.414-.155 2.284l.265.562-4.257-4.257a.98.98 0 0 1-.117-.445c0-.267.104-.517.292-.706a1.023 1.023 0 0 1 1.41 0zm8.887 2.06c-.375-.557-.902-.916-1.486-1.011a1.738 1.738 0 0 0-1.342.332c-.376.29-.61.656-.712 1.065a2.1 2.1 0 0 0-1.095-.562 1.776 1.776 0 0 0-.992.128l-2.636-2.636a1.883 1.883 0 0 0-2.658 0 1.862 1.862 0 0 0-.478.847 1.886 1.886 0 0 0-2.671-.012 1.867 1.867 0 0 0-.503.909c-.754-.754-1.992-.754-2.703-.044a1.881 1.881 0 0 0 0 2.658c-.288.12-.605.288-.864.547a1.884 1.884 0 0 0 0 2.659l.624.622a1.879 1.879 0 0 0-.91 3.16l5.019 5.02c1.595 1.594 3.515 2.645 5.408 2.959a7.16 7.16 0 0 0 1.173.098c1.026 0 1.997-.24 2.892-.7.279.04.555.065.828.065 1.53 0 2.969-.628 4.236-1.894 3.338-3.338 3.083-6.928 1.738-9.166l-2.868-5.043z"></path></g></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M11.738 0l.762 2.966L13.262 0z"></path><path d="M16.634 1.224l-1.432-.47-.408 3.022z"></path><path d="M9.79.754l-1.431.47 1.84 2.552z"></path><path d="M22.472 13.307l-3.023-5.32c-.287-.426-.689-.705-1.123-.776a1.16 1.16 0 0 0-.911.221c-.297.231-.474.515-.535.84.017.022.036.04.053.063l2.843 5.001c1.95 3.564 1.328 6.973-1.843 10.144a8.46 8.46 0 0 1-.549.501c1.205-.156 2.328-.737 3.351-1.76 3.268-3.268 3.041-6.749 1.737-8.914"></path><path d="M12.58 9.887c-.156-.83.096-1.569.692-2.142L10.78 5.252c-.5-.504-1.378-.504-1.879 0-.178.18-.273.4-.329.63l4.008 4.005z"></path><path d="M15.812 9.04c-.218-.323-.539-.55-.88-.606a.814.814 0 0 0-.644.153c-.176.137-.713.553-.24 1.566l1.43 3.025a.539.539 0 1 1-.868.612L7.2 6.378a.986.986 0 1 0-1.395 1.395l4.401 4.403a.538.538 0 1 1-.762.762L5.046 8.54 3.802 7.295a.99.99 0 0 0-1.396 0 .981.981 0 0 0 0 1.394L3.647 9.93l4.402 4.403a.537.537 0 0 1 0 .761.535.535 0 0 1-.762 0L2.89 10.696a.992.992 0 0 0-1.399-.003.983.983 0 0 0 0 1.395l1.855 1.854 2.763 2.765a.538.538 0 0 1-.76.761l-2.765-2.764a.982.982 0 0 0-1.395 0 .989.989 0 0 0 0 1.395l5.32 5.32c3.371 3.372 6.64 4.977 10.49 1.126C19.74 19.8 20.271 17 18.62 13.982L15.812 9.04z"></path></g></svg></span></span></button></div><span class="u-relative u-background js-actionMultirecommendCount u-marginLeft5"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-disablePointerEvents u-marginLeft4" data-action="show-recommends" data-action-value="f92ecfa9f3ce">58</button></span></div></div><div class="u-height20 u-borderRightLighter u-inlineBlock u-relative u-marginRight10 u-marginLeft12"></div><div class="buttonSet"><button class="button button--chromeless is-touchIconFadeInPulse u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="sign-up-prompt" data-sign-in-action="add-to-bookmarks" data-requires-token="true" data-redirect="https://medium.com/_/bookmark/p/f92ecfa9f3ce" data-action-source="placement_card_footer_grid-----f92ecfa9f3ce----1-60----------------bookmark_preview"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126a.508.508 0 0 0 .708-.03.5.5 0 0 0 .118-.285H19V6zm-6.838 9.97L7 19.636V6c0-.55.45-1 1-1h9c.55 0 1 .45 1 1v13.637l-5.162-3.668a.49.49 0 0 0-.676 0z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126c.205.183.52.17.708-.03a.5.5 0 0 0 .118-.285H19V6z"></path></svg></span></span></button></div></div></div></div></div></div><div class="col u-padding8 u-xs-size12of12 u-size4of12"><div class="uiScale uiScale-ui--small uiScale-caption--regular u-height280 u-width100pct u-backgroundWhite u-borderCardBorder u-boxShadow u-borderBox u-borderRadius4 js-trackPostPresentation" data-post-id="b8427df61665" data-source="placement_card_footer_grid---------2-60" data-tracking-context="placement"><a class="link link--noUnderline u-baseColor--link" href="https://towardsdatascience.com/soft-actor-critic-demystified-b8427df61665?source=placement_card_footer_grid---------2-60" data-action-source="placement_card_footer_grid---------2-60"><div class="u-backgroundCover u-backgroundColorGrayLight u-height100 u-width100pct u-borderBottomLight u-borderRadiusTop4" style="background-image: url(&quot;https://cdn-images-1.medium.com/fit/c/400/120/0*eW8daqyW6HfSjf31.jpg&quot;); background-position: 50% 50% !important;"></div></a><div class="u-padding15 u-borderBox u-flexColumn u-height180"><a class="link link--noUnderline u-baseColor--link u-flex1" href="https://towardsdatascience.com/soft-actor-critic-demystified-b8427df61665?source=placement_card_footer_grid---------2-60" data-action-source="placement_card_footer_grid---------2-60"><div class="uiScale uiScale-ui--regular uiScale-caption--small u-textColorNormal u-marginBottom7">Related reads</div><div class="ui-h3 ui-clamp2 u-textColorDarkest u-contentSansBold u-fontSize24 u-maxHeight2LineHeightTighter u-lineClamp2 u-textOverflowEllipsis u-letterSpacingTight u-paddingBottom2">Soft Actor-Critic Demystified</div></a><div class="u-paddingBottom10 u-flex0 u-flexCenter"><div class="u-flex1 u-minWidth0 u-marginRight10"><div class="u-flexCenter"><div class="postMetaInline-avatar u-flex0"><a class="link u-baseColor--link avatar" href="https://towardsdatascience.com/@vaishakvk" data-action="show-user-card" data-action-value="61d2676ad14" data-action-type="hover" data-user-id="61d2676ad14" data-collection-slug="towards-data-science" dir="auto"><img src="https://cdn-images-1.medium.com/fit/c/36/36/1*tziD1xyW4eYiysJ60_YcKg.png" class="avatar-image u-size36x36 u-xs-size32x32" alt="Go to the profile of Vaishak V.Kumar"></a></div><div class="postMetaInline postMetaInline-authorLockup ui-captionStrong u-flex1 u-noWrapWithEllipsis"><a class="ds-link ds-link--styleSubtle link link--darken link--darker" href="https://towardsdatascience.com/@vaishakvk?source=placement_card_footer_grid---------2-60" data-action="show-user-card" data-action-source="placement_card_footer_grid---------2-60" data-action-value="61d2676ad14" data-action-type="hover" data-user-id="61d2676ad14" data-collection-slug="towards-data-science" dir="auto">Vaishak V.Kumar</a><div class="ui-caption u-fontSize12 u-baseColor--textNormal u-textColorNormal js-postMetaInlineSupplemental"><a class="link link--darken" href="https://towardsdatascience.com/soft-actor-critic-demystified-b8427df61665?source=placement_card_footer_grid---------2-60" data-action="open-post" data-action-value="https://towardsdatascience.com/soft-actor-critic-demystified-b8427df61665?source=placement_card_footer_grid---------2-60" data-action-source="preview-listing"><time datetime="2019-01-08T22:31:25.353Z">Jan 8</time></a><span class="middotDivider u-fontSize12"></span><span class="readingTime" title="11 min read"></span></div></div></div></div><div class="u-flex0 u-flexCenter"><div class="buttonSet"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="b8427df61665" data-is-label-padded="true" data-source="placement_card_footer_grid-----b8427df61665----2-60----------------clap_preview"><div class="u-relative u-foreground"><button class="button button--primary button--chromeless u-accentColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--darker" data-action="sign-up-prompt" data-sign-in-action="multivote" data-requires-token="true" data-redirect="https://medium.com/_/vote/p/b8427df61665" data-action-source="placement_card_footer_grid-----b8427df61665----2-60----------------clap_preview" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M11.739 0l.761 2.966L13.261 0z"></path><path d="M14.815 3.776l1.84-2.551-1.43-.471z"></path><path d="M8.378 1.224l1.84 2.551L9.81.753z"></path><path d="M20.382 21.622c-1.04 1.04-2.115 1.507-3.166 1.608.168-.14.332-.29.492-.45 2.885-2.886 3.456-5.982 1.69-9.211l-1.101-1.937-.955-2.02c-.315-.676-.235-1.185.245-1.556a.836.836 0 0 1 .66-.16c.342.056.66.28.879.605l2.856 5.023c1.179 1.962 1.379 5.119-1.6 8.098m-13.29-.528l-5.02-5.02a1 1 0 0 1 .707-1.701c.255 0 .512.098.707.292l2.607 2.607a.442.442 0 0 0 .624-.624L4.11 14.04l-1.75-1.75a.998.998 0 1 1 1.41-1.413l4.154 4.156a.44.44 0 0 0 .624 0 .44.44 0 0 0 0-.624l-4.152-4.153-1.172-1.171a.998.998 0 0 1 0-1.41 1.018 1.018 0 0 1 1.41 0l1.172 1.17 4.153 4.152a.437.437 0 0 0 .624 0 .442.442 0 0 0 0-.624L6.43 8.222a.988.988 0 0 1-.291-.705.99.99 0 0 1 .29-.706 1 1 0 0 1 1.412 0l6.992 6.993a.443.443 0 0 0 .71-.501l-1.35-2.856c-.315-.676-.235-1.185.246-1.557a.85.85 0 0 1 .66-.16c.342.056.659.28.879.606L18.628 14c1.573 2.876 1.067 5.545-1.544 8.156-1.396 1.397-3.144 1.966-5.063 1.652-1.713-.286-3.463-1.248-4.928-2.714zM10.99 5.976l2.562 2.562c-.497.607-.563 1.414-.155 2.284l.265.562-4.257-4.257a.98.98 0 0 1-.117-.445c0-.267.104-.517.292-.706a1.023 1.023 0 0 1 1.41 0zm8.887 2.06c-.375-.557-.902-.916-1.486-1.011a1.738 1.738 0 0 0-1.342.332c-.376.29-.61.656-.712 1.065a2.1 2.1 0 0 0-1.095-.562 1.776 1.776 0 0 0-.992.128l-2.636-2.636a1.883 1.883 0 0 0-2.658 0 1.862 1.862 0 0 0-.478.847 1.886 1.886 0 0 0-2.671-.012 1.867 1.867 0 0 0-.503.909c-.754-.754-1.992-.754-2.703-.044a1.881 1.881 0 0 0 0 2.658c-.288.12-.605.288-.864.547a1.884 1.884 0 0 0 0 2.659l.624.622a1.879 1.879 0 0 0-.91 3.16l5.019 5.02c1.595 1.594 3.515 2.645 5.408 2.959a7.16 7.16 0 0 0 1.173.098c1.026 0 1.997-.24 2.892-.7.279.04.555.065.828.065 1.53 0 2.969-.628 4.236-1.894 3.338-3.338 3.083-6.928 1.738-9.166l-2.868-5.043z"></path></g></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M11.738 0l.762 2.966L13.262 0z"></path><path d="M16.634 1.224l-1.432-.47-.408 3.022z"></path><path d="M9.79.754l-1.431.47 1.84 2.552z"></path><path d="M22.472 13.307l-3.023-5.32c-.287-.426-.689-.705-1.123-.776a1.16 1.16 0 0 0-.911.221c-.297.231-.474.515-.535.84.017.022.036.04.053.063l2.843 5.001c1.95 3.564 1.328 6.973-1.843 10.144a8.46 8.46 0 0 1-.549.501c1.205-.156 2.328-.737 3.351-1.76 3.268-3.268 3.041-6.749 1.737-8.914"></path><path d="M12.58 9.887c-.156-.83.096-1.569.692-2.142L10.78 5.252c-.5-.504-1.378-.504-1.879 0-.178.18-.273.4-.329.63l4.008 4.005z"></path><path d="M15.812 9.04c-.218-.323-.539-.55-.88-.606a.814.814 0 0 0-.644.153c-.176.137-.713.553-.24 1.566l1.43 3.025a.539.539 0 1 1-.868.612L7.2 6.378a.986.986 0 1 0-1.395 1.395l4.401 4.403a.538.538 0 1 1-.762.762L5.046 8.54 3.802 7.295a.99.99 0 0 0-1.396 0 .981.981 0 0 0 0 1.394L3.647 9.93l4.402 4.403a.537.537 0 0 1 0 .761.535.535 0 0 1-.762 0L2.89 10.696a.992.992 0 0 0-1.399-.003.983.983 0 0 0 0 1.395l1.855 1.854 2.763 2.765a.538.538 0 0 1-.76.761l-2.765-2.764a.982.982 0 0 0-1.395 0 .989.989 0 0 0 0 1.395l5.32 5.32c3.371 3.372 6.64 4.977 10.49 1.126C19.74 19.8 20.271 17 18.62 13.982L15.812 9.04z"></path></g></svg></span></span></button></div><span class="u-relative u-background js-actionMultirecommendCount u-marginLeft5"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-disablePointerEvents u-marginLeft4" data-action="show-recommends" data-action-value="b8427df61665">208</button></span></div></div><div class="u-height20 u-borderRightLighter u-inlineBlock u-relative u-marginRight10 u-marginLeft12"></div><div class="buttonSet"><button class="button button--chromeless is-touchIconFadeInPulse u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="sign-up-prompt" data-sign-in-action="add-to-bookmarks" data-requires-token="true" data-redirect="https://medium.com/_/bookmark/p/b8427df61665" data-action-source="placement_card_footer_grid-----b8427df61665----2-60----------------bookmark_preview"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126a.508.508 0 0 0 .708-.03.5.5 0 0 0 .118-.285H19V6zm-6.838 9.97L7 19.636V6c0-.55.45-1 1-1h9c.55 0 1 .45 1 1v13.637l-5.162-3.668a.49.49 0 0 0-.676 0z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126c.205.183.52.17.708-.03a.5.5 0 0 0 .118-.285H19V6z"></path></svg></span></span></button></div></div></div></div></div></div></div></div></div></div><div class="u-padding0 u-clearfix u-backgroundGrayLightest u-print-hide supplementalPostContent js-responsesWrapper" data-action-scope="_actionscope_5"><div class="container u-maxWidth740"><div class="responsesStreamWrapper u-maxWidth640 u-hide js-responsesStreamWrapper"><div class="container responsesStream-title u-paddingTop15"><div class="row"><header class="heading"><div class="u-clearfix"><div class="heading-content u-floatLeft"><span class="heading-title heading-title--semibold">Responses</span></div></div></header></div></div><div class="responsesStream js-responsesStream"></div><div class="container u-hide js-showOtherResponses"><div class="row"><button class="button button--primary button--withChrome u-accentColor--buttonNormal responsesStream-showOtherResponses cardChromeless u-width100pct u-marginVertical20 u-heightAuto" data-action="show-other-responses">Show all responses</button></div></div><div class="responsesStream js-responsesStreamOther"></div></div></div></div><div class="supplementalPostContent js-heroPromo"></div></footer></article></main><aside class="u-marginAuto u-maxWidth1032 js-postLeftSidebar"><div class="u-foreground u-top0 u-transition--fadeOut300 u-fixed u-sm-hide js-postShareWidget" data-scroll="fixed" style="transform: translateY(150px);"><div class="u-breakWord u-md-hide u-width131"><div class="u-width131 collection-title u-fontWeightBold u-fontSize18 u-lineHeightTight"><a href="https://ai-alignment.com?source=logo-lo_JuU2p2EvGepj">AI Alignment</a></div><div class="u-width131 u-multiline-clamp u-textColorNormal u-fontSize14 u-lineHeightTight u-paddingTop3">Aligning AI systems with human interests.</div><div class="u-paddingTop15 u-paddingBottom30 u-borderBottomLight u-marginBottom30"><button class="button button--primary button--small u-noUserSelect button--withChrome u-accentColor--buttonNormal js-relationshipButton" data-action="sign-up-prompt" data-sign-in-action="toggle-follow-collection" data-requires-token="true" data-redirect="https://medium.com/_/subscribe/collection/ai-control" data-action-source="post_sidebar----624d886c4aa4----------------------post_sidebar" data-collection-id="624d886c4aa4"><span class="button-label  js-buttonLabel">Follow</span></button></div></div><ul><li class="u-marginVertical10"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="30285c779450" data-is-icon-29px="true" data-has-recommend-list="true" data-source="post_share_widget-----30285c779450---------------------clap_sidebar"><div class="u-relative u-foreground"><button class="button button--primary button--large button--chromeless u-accentColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--darker" data-action="sign-up-prompt" data-sign-in-action="multivote" data-requires-token="true" data-redirect="https://medium.com/_/vote/p/30285c779450" data-action-source="post_share_widget-----30285c779450---------------------clap_sidebar" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><g fill-rule="evenodd"><path d="M13.739 1l.761 2.966L15.261 1z"></path><path d="M16.815 4.776l1.84-2.551-1.43-.471z"></path><path d="M10.378 2.224l1.84 2.551-.408-3.022z"></path><path d="M22.382 22.622c-1.04 1.04-2.115 1.507-3.166 1.608.168-.14.332-.29.492-.45 2.885-2.886 3.456-5.982 1.69-9.211l-1.101-1.937-.955-2.02c-.315-.676-.235-1.185.245-1.556a.836.836 0 0 1 .66-.16c.342.056.66.28.879.605l2.856 5.023c1.179 1.962 1.379 5.119-1.6 8.098m-13.29-.528l-5.02-5.02a1 1 0 0 1 .707-1.701c.255 0 .512.098.707.292l2.607 2.607a.442.442 0 0 0 .624-.624L6.11 15.04l-1.75-1.75a.998.998 0 1 1 1.41-1.413l4.154 4.156a.44.44 0 0 0 .624 0 .44.44 0 0 0 0-.624l-4.152-4.153-1.172-1.171a.998.998 0 0 1 0-1.41 1.018 1.018 0 0 1 1.41 0l1.172 1.17 4.153 4.152a.437.437 0 0 0 .624 0 .442.442 0 0 0 0-.624L8.43 9.222a.988.988 0 0 1-.291-.705.99.99 0 0 1 .29-.706 1 1 0 0 1 1.412 0l6.992 6.993a.443.443 0 0 0 .71-.501l-1.35-2.856c-.315-.676-.235-1.185.246-1.557a.85.85 0 0 1 .66-.16c.342.056.659.28.879.606L20.628 15c1.573 2.876 1.067 5.545-1.544 8.156-1.396 1.397-3.144 1.966-5.063 1.652-1.713-.286-3.463-1.248-4.928-2.714zM12.99 6.976l2.562 2.562c-.497.607-.563 1.414-.155 2.284l.265.562-4.257-4.257a.98.98 0 0 1-.117-.445c0-.267.104-.517.292-.706a1.023 1.023 0 0 1 1.41 0zm8.887 2.06c-.375-.557-.902-.916-1.486-1.011a1.738 1.738 0 0 0-1.342.332c-.376.29-.61.656-.712 1.065a2.1 2.1 0 0 0-1.095-.562 1.776 1.776 0 0 0-.992.128l-2.636-2.636a1.883 1.883 0 0 0-2.658 0 1.862 1.862 0 0 0-.478.847 1.886 1.886 0 0 0-2.671-.012 1.867 1.867 0 0 0-.503.909c-.754-.754-1.992-.754-2.703-.044a1.881 1.881 0 0 0 0 2.658c-.288.12-.605.288-.864.547a1.884 1.884 0 0 0 0 2.659l.624.622a1.879 1.879 0 0 0-.91 3.16l5.019 5.02c1.595 1.594 3.515 2.645 5.408 2.959a7.16 7.16 0 0 0 1.173.098c1.026 0 1.997-.24 2.892-.7.279.04.555.065.828.065 1.53 0 2.969-.628 4.236-1.894 3.338-3.338 3.083-6.928 1.738-9.166l-2.868-5.043z"></path></g></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><g fill-rule="evenodd"><path d="M13.738 1l.762 2.966L15.262 1z"></path><path d="M18.634 2.224l-1.432-.47-.408 3.022z"></path><path d="M11.79 1.754l-1.431.47 1.84 2.552z"></path><path d="M24.472 14.307l-3.023-5.32c-.287-.426-.689-.705-1.123-.776a1.16 1.16 0 0 0-.911.221c-.297.231-.474.515-.535.84.017.022.036.04.053.063l2.843 5.001c1.95 3.564 1.328 6.973-1.843 10.144a8.46 8.46 0 0 1-.549.501c1.205-.156 2.328-.737 3.351-1.76 3.268-3.268 3.041-6.749 1.737-8.914"></path><path d="M14.58 10.887c-.156-.83.096-1.569.692-2.142L12.78 6.252c-.5-.504-1.378-.504-1.879 0-.178.18-.273.4-.329.63l4.008 4.005z"></path><path d="M17.812 10.04c-.218-.323-.539-.55-.88-.606a.814.814 0 0 0-.644.153c-.176.137-.713.553-.24 1.566l1.43 3.025a.539.539 0 1 1-.868.612L9.2 7.378a.986.986 0 1 0-1.395 1.395l4.401 4.403a.538.538 0 1 1-.762.762L7.046 9.54 5.802 8.295a.99.99 0 0 0-1.396 0 .981.981 0 0 0 0 1.394l1.241 1.241 4.402 4.403a.537.537 0 0 1 0 .761.535.535 0 0 1-.762 0L4.89 11.696a.992.992 0 0 0-1.399-.003.983.983 0 0 0 0 1.395l1.855 1.854 2.763 2.765a.538.538 0 0 1-.76.761l-2.765-2.764a.982.982 0 0 0-1.395 0 .989.989 0 0 0 0 1.395l5.32 5.32c3.371 3.372 6.64 4.977 10.49 1.126C21.74 20.8 22.271 18 20.62 14.982l-2.809-4.942z"></path></g></svg></span></span></button></div><span class="u-relative u-background js-actionMultirecommendCount u-marginLeft5"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton" data-action="show-recommends" data-action-value="30285c779450">121</button></span></div></li><li class="u-marginVertical10 u-marginLeft3"><button class="button button--large button--dark button--chromeless is-touchIconFadeInPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="sign-up-prompt" data-sign-in-action="add-to-bookmarks" data-requires-token="true" data-redirect="https://medium.com/_/bookmark/p/30285c779450" data-action-source="post_share_widget-----30285c779450---------------------bookmark_sidebar"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M19.385 4h-9.77A2.623 2.623 0 0 0 7 6.615V23.01a1.022 1.022 0 0 0 1.595.847l5.905-4.004 5.905 4.004A1.022 1.022 0 0 0 22 23.011V6.62A2.625 2.625 0 0 0 19.385 4zM21 23l-5.91-3.955-.148-.107a.751.751 0 0 0-.884 0l-.147.107L8 23V6.615C8 5.725 8.725 5 9.615 5h9.77C20.275 5 21 5.725 21 6.615V23z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M19.385 4h-9.77A2.623 2.623 0 0 0 7 6.615V23.01a1.022 1.022 0 0 0 1.595.847l5.905-4.004 5.905 4.004A1.022 1.022 0 0 0 22 23.011V6.62A2.625 2.625 0 0 0 19.385 4z" fill-rule="evenodd"></path></svg></span></span></button></li><li class="u-marginVertical10 u-marginLeft3"><a class="button button--dark button--chromeless u-baseColor--buttonDark button--withIcon button--withSvgIcon button--dark button--chromeless" href="https://medium.com/p/30285c779450/share/twitter" title="Share on Twitter" aria-label="Share on Twitter" target="_blank" data-action-source="post_share_widget"><span class="button-defaultState"><span class="svgIcon svgIcon--twitterFilled svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M22.053 7.54a4.474 4.474 0 0 0-3.31-1.455 4.526 4.526 0 0 0-4.526 4.524c0 .35.04.7.082 1.05a12.9 12.9 0 0 1-9.3-4.77c-.39.69-.61 1.46-.65 2.26.03 1.6.83 2.99 2.02 3.79-.72-.02-1.41-.22-2.02-.57-.01.02-.01.04 0 .08-.01 2.17 1.55 4 3.63 4.44-.39.08-.79.13-1.21.16-.28-.03-.57-.05-.81-.08.54 1.77 2.21 3.08 4.2 3.15a9.564 9.564 0 0 1-5.66 1.94c-.34-.03-.7-.06-1.05-.08 2 1.27 4.38 2.02 6.94 2.02 8.31 0 12.86-6.9 12.84-12.85.02-.24.01-.43 0-.65.89-.62 1.65-1.42 2.26-2.34-.82.38-1.69.62-2.59.72a4.37 4.37 0 0 0 1.94-2.51c-.84.53-1.81.9-2.83 1.13z"></path></svg></span></span></a></li><li class="u-marginVertical10 u-marginLeft3"><a class="button button--dark button--chromeless u-baseColor--buttonDark button--withIcon button--withSvgIcon button--dark button--chromeless" href="https://medium.com/p/30285c779450/share/facebook" title="Share on Facebook" aria-label="Share on Facebook" target="_blank" data-action-source="post_share_widget"><span class="button-defaultState"><span class="svgIcon svgIcon--facebookSquare svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M23.209 5H5.792A.792.792 0 0 0 5 5.791V23.21c0 .437.354.791.792.791h9.303v-7.125H12.72v-2.968h2.375v-2.375c0-2.455 1.553-3.662 3.741-3.662 1.049 0 1.95.078 2.213.112v2.565h-1.517c-1.192 0-1.469.567-1.469 1.397v1.963h2.969l-.594 2.968h-2.375L18.11 24h5.099a.791.791 0 0 0 .791-.791V5.79a.791.791 0 0 0-.791-.79"></path></svg></span></span></a></li></ul></div></aside><div class="u-fixed u-bottom0 u-width100pct u-backgroundWhite u-boxShadowTop u-borderBox u-paddingTop10 u-paddingBottom10 u-zIndexMetabar u-xs-hide js-stickyFooter"><div class="u-maxWidth700 u-marginAuto u-flexCenter"><div class="u-fontSize16 u-flex1 u-flexCenter"><div class="u-flex0 u-inlineBlock u-paddingRight20"><a class="link u-baseColor--link avatar avatar--roundedRectangle" href="https://ai-alignment.com" title="Go to AI Alignment" aria-label="Go to AI Alignment" data-collection-slug="ai-control"><img src="https://cdn-images-1.medium.com/fit/c/40/40/1*N56Qc5-aHTcfGff0scntKQ.png" class="avatar-image avatar-image--smaller" alt="AI Alignment"></a></div><div class="u-flex1 u-inlineBlock">Never miss a story from<strong> AI Alignment</strong>, when you sign up for Medium. <a class="link u-baseColor--link link--accent u-accentColor--textNormal u-accentColor--textDarken" href="https://medium.com/@Medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg" data-action-source="sticky_footer">Learn more</a></div></div><div class="u-marginLeft50"><button class="button button--primary button--dark is-active u-noUserSelect button--withChrome u-accentColor--buttonDark u-uiTextSemibold u-textUppercase u-fontSize12 button--followCollection js-followCollectionButton" data-action="sign-up-prompt" data-sign-in-action="toggle-subscribe-collection" data-requires-token="true" data-redirect="https://medium.com/_/subscribe/collection/ai-control" data-action-source="sticky_footer----624d886c4aa4----------------------follow_metabar"><span class="button-label  button-defaultState js-buttonLabel">Get updates</span><span class="button-label button-activeState">Get updates</span></button></div></div></div><style class="js-collectionStyle">
.u-accentColor--borderLight {border-color: #02B875 !important;}
.u-accentColor--borderNormal {border-color: #02B875 !important;}
.u-accentColor--borderDark {border-color: #1C9963 !important;}
.u-accentColor--iconLight .svgIcon,.u-accentColor--iconLight.svgIcon {fill: #02B875 !important;}
.u-accentColor--iconNormal .svgIcon,.u-accentColor--iconNormal.svgIcon {fill: #02B875 !important;}
.u-accentColor--iconDark .svgIcon,.u-accentColor--iconDark.svgIcon {fill: #1C9963 !important;}
.u-accentColor--textNormal {color: #1C9963 !important;}
.u-accentColor--hoverTextNormal:hover {color: #1C9963 !important;}
.u-accentColor--textNormal.u-accentColor--textDarken:hover {color: #1C9963 !important;}
.u-accentColor--textDark {color: #1C9963 !important;}
.u-accentColor--backgroundLight {background-color: #02B875 !important;}
.u-accentColor--backgroundNormal {background-color: #02B875 !important;}
.u-accentColor--backgroundDark {background-color: #1C9963 !important;}
.u-accentColor--buttonDark {border-color: #1C9963 !important; color: #1C9963 !important;}
.u-accentColor--buttonDark:hover {border-color: #1C9963 !important;}
.u-accentColor--buttonDark .icon:before,.u-accentColor--buttonDark .svgIcon{color: #1C9963 !important; fill: #1C9963 !important;}
.u-accentColor--buttonNormal:not(.clapButton--largePill) {border-color: #02B875 !important; color: #1C9963 !important;}
.u-accentColor--buttonNormal:hover {border-color: #1C9963 !important;}
.u-accentColor--buttonNormal .icon:before,.u-accentColor--buttonNormal .svgIcon{color: #02B875 !important; fill: #02B875 !important;}
.u-accentColor--buttonNormal.button--filled .icon:before,.u-accentColor--buttonNormal.button--filled .svgIcon{color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-accentColor--buttonDark.button--filled,.u-accentColor--buttonDark.button--withChrome.is-active,.u-accentColor--fillWhenActive.is-active {background-color: #1C9963 !important; border-color: #1C9963 !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-accentColor--buttonNormal.button--filled:not(.clapButton--largePill),.u-accentColor--buttonNormal.button--withChrome.is-active:not(.clapButton--largePill) {background-color: #02B875 !important; border-color: #02B875 !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.postArticle.is-withAccentColors .markup--user,.postArticle.is-withAccentColors .markup--query {color: #1C9963 !important;}
.u-accentColor--highlightFaint {background-color: rgba(233, 253, 240, 1) !important;}
.u-accentColor--highlightStrong.is-active .svgIcon {fill: rgba(125, 255, 179, 1) !important;}
.postArticle.is-withAccentColors .markup--quote.is-other {background-color: rgba(233, 253, 240, 1) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--quote.is-other {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(233, 253, 240, 1), rgba(233, 253, 240, 1));}
.postArticle.is-withAccentColors .markup--quote.is-me {background-color: rgba(173, 255, 207, 1) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--quote.is-me {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(173, 255, 207, 1), rgba(173, 255, 207, 1));}
.postArticle.is-withAccentColors .markup--quote.is-targeted {background-color: rgba(125, 255, 179, 1) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--quote.is-targeted {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(125, 255, 179, 1), rgba(125, 255, 179, 1));}
.postArticle.is-withAccentColors .markup--quote.is-selected {background-color: rgba(125, 255, 179, 1) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--quote.is-selected {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(125, 255, 179, 1), rgba(125, 255, 179, 1));}
.postArticle.is-withAccentColors .markup--highlight {background-color: rgba(125, 255, 179, 1) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--highlight {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(125, 255, 179, 1), rgba(125, 255, 179, 1));}.u-baseColor--iconNormal.avatar-halo {fill: rgba(0, 0, 0, 0.4980392156862745) !important;}</style><style class="js-collectionStyleConstant">.u-imageBgColor {background-color: rgba(0, 0, 0, 0.24705882352941178);}
.u-imageSpectrum .u-baseColor--borderLight {border-color: rgba(255, 255, 255, 0.6980392156862745) !important;}
.u-imageSpectrum .u-baseColor--borderNormal {border-color: rgba(255, 255, 255, 0.8980392156862745) !important;}
.u-imageSpectrum .u-baseColor--borderDark {border-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--iconLight .svgIcon,.u-imageSpectrum .u-baseColor--iconLight.svgIcon {fill: rgba(255, 255, 255, 0.8) !important;}
.u-imageSpectrum .u-baseColor--iconNormal .svgIcon,.u-imageSpectrum .u-baseColor--iconNormal.svgIcon {fill: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--iconDark .svgIcon,.u-imageSpectrum .u-baseColor--iconDark.svgIcon {fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--textNormal {color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--textNormal.u-baseColor--textDarken:hover {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--textDark {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--textDarker {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--backgroundLight {background-color: rgba(255, 255, 255, 0.8980392156862745) !important;}
.u-imageSpectrum .u-baseColor--backgroundNormal {background-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--backgroundDark {background-color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--buttonLight {border-color: rgba(255, 255, 255, 0.6980392156862745) !important; color: rgba(255, 255, 255, 0.8) !important;}
.u-imageSpectrum .u-baseColor--buttonLight:hover {border-color: rgba(255, 255, 255, 0.6980392156862745) !important;}
.u-imageSpectrum .u-baseColor--buttonLight .icon:before,.u-imageSpectrum .u-baseColor--buttonLight .svgIcon {color: rgba(255, 255, 255, 0.8) !important; fill: rgba(255, 255, 255, 0.8) !important;}
.u-imageSpectrum .u-baseColor--buttonDark {border-color: rgba(255, 255, 255, 0.9490196078431372) !important; color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--buttonDark:hover {border-color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--buttonDark .icon:before,.u-imageSpectrum .u-baseColor--buttonDark .svgIcon {color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--buttonNormal {border-color: rgba(255, 255, 255, 0.8980392156862745) !important; color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--buttonNormal:hover {border-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--buttonNormal .icon:before,.u-imageSpectrum .u-baseColor--buttonNormal .svgIcon {color: rgba(255, 255, 255, 0.9490196078431372) !important; fill: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--buttonDark.button--filled,.u-imageSpectrum .u-baseColor--buttonDark.button--withChrome.is-active {background-color: rgba(255, 255, 255, 1) !important; border-color: rgba(255, 255, 255, 1) !important; color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}
.u-imageSpectrum .u-baseColor--buttonNormal.button--filled,.u-imageSpectrum .u-baseColor--buttonNormal.button--withChrome.is-active {background-color: rgba(255, 255, 255, 0.9490196078431372) !important; border-color: rgba(255, 255, 255, 0.9490196078431372) !important; color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}
.u-imageSpectrum .u-baseColor--link {color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--link.link--darkenOnHover:hover {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--link.link--darken:hover,.u-imageSpectrum .u-baseColor--link.link--darken:focus,.u-imageSpectrum .u-baseColor--link.link--darken:active {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--link.link--dark {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--link.link--dark.link--darken:hover,.u-imageSpectrum .u-baseColor--link.link--dark.link--darken:focus,.u-imageSpectrum .u-baseColor--link.link--dark.link--darken:active {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--link.link--darker {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--placeholderNormal ::-webkit-input-placeholder {color: rgba(255, 255, 255, 0.8);}
.u-imageSpectrum .u-baseColor--placeholderNormal ::-moz-placeholder {color: rgba(255, 255, 255, 0.8);}
.u-imageSpectrum .u-baseColor--placeholderNormal :-ms-input-placeholder {color: rgba(255, 255, 255, 0.8);}
.u-imageSpectrum .svgIcon--logoWordmark {stroke: none !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .svgIcon--logoMonogram {stroke: none !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum  .ui-h1,.u-imageSpectrum  .ui-h2,.u-imageSpectrum  .ui-h3,.u-imageSpectrum  .ui-h4,.u-imageSpectrum  .ui-brand1,.u-imageSpectrum  .ui-brand2,.u-imageSpectrum  .ui-captionStrong {color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum  .ui-body,.u-imageSpectrum  .ui-caps {color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum  .ui-summary,.u-imageSpectrum  .ui-caption {color: rgba(255, 255, 255, 0.8) !important; fill: rgba(255, 255, 255, 0.8) !important;}
.u-imageSpectrum .u-accentColor--borderLight {border-color: rgba(255, 255, 255, 0.6980392156862745) !important;}
.u-imageSpectrum .u-accentColor--borderNormal {border-color: rgba(255, 255, 255, 0.8980392156862745) !important;}
.u-imageSpectrum .u-accentColor--borderDark {border-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--iconLight .svgIcon,.u-imageSpectrum .u-accentColor--iconLight.svgIcon {fill: rgba(255, 255, 255, 0.8) !important;}
.u-imageSpectrum .u-accentColor--iconNormal .svgIcon,.u-imageSpectrum .u-accentColor--iconNormal.svgIcon {fill: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--iconDark .svgIcon,.u-imageSpectrum .u-accentColor--iconDark.svgIcon {fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--textNormal {color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--hoverTextNormal:hover {color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--textNormal.u-accentColor--textDarken:hover {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--textDark {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--backgroundLight {background-color: rgba(255, 255, 255, 0.8980392156862745) !important;}
.u-imageSpectrum .u-accentColor--backgroundNormal {background-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--backgroundDark {background-color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--buttonDark {border-color: rgba(255, 255, 255, 0.9490196078431372) !important; color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--buttonDark:hover {border-color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--buttonDark .icon:before,.u-imageSpectrum .u-accentColor--buttonDark .svgIcon{color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--buttonNormal:not(.clapButton--largePill) {border-color: rgba(255, 255, 255, 0.8980392156862745) !important; color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--buttonNormal:hover {border-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--buttonNormal .icon:before,.u-imageSpectrum .u-accentColor--buttonNormal .svgIcon{color: rgba(255, 255, 255, 0.9490196078431372) !important; fill: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--buttonNormal.button--filled .icon:before,.u-imageSpectrum .u-accentColor--buttonNormal.button--filled .svgIcon{color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}
.u-imageSpectrum .u-accentColor--buttonDark.button--filled,.u-imageSpectrum .u-accentColor--buttonDark.button--withChrome.is-active,.u-imageSpectrum .u-accentColor--fillWhenActive.is-active {background-color: rgba(255, 255, 255, 1) !important; border-color: rgba(255, 255, 255, 1) !important; color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}
.u-imageSpectrum .u-accentColor--buttonNormal.button--filled:not(.clapButton--largePill),.u-imageSpectrum .u-accentColor--buttonNormal.button--withChrome.is-active:not(.clapButton--largePill) {background-color: rgba(255, 255, 255, 0.9490196078431372) !important; border-color: rgba(255, 255, 255, 0.9490196078431372) !important; color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}
.u-imageSpectrum .postArticle.is-withAccentColors .markup--user,.u-imageSpectrum .postArticle.is-withAccentColors .markup--query {color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--highlightFaint {background-color: rgba(255, 255, 255, 0.2) !important;}
.u-imageSpectrum .u-accentColor--highlightStrong.is-active .svgIcon {fill: rgba(255, 255, 255, 0.6) !important;}
.postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-other {background-color: rgba(255, 255, 255, 0.2) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-other {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.2), rgba(255, 255, 255, 0.2));}
.postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-me {background-color: rgba(255, 255, 255, 0.4) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-me {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.4), rgba(255, 255, 255, 0.4));}
.postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-targeted {background-color: rgba(255, 255, 255, 0.6) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-targeted {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.6), rgba(255, 255, 255, 0.6));}
.postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-selected {background-color: rgba(255, 255, 255, 0.6) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-selected {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.6), rgba(255, 255, 255, 0.6));}
.postArticle.is-withAccentColors .u-imageSpectrum .markup--highlight {background-color: rgba(255, 255, 255, 0.6) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--highlight {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.6), rgba(255, 255, 255, 0.6));}.u-resetSpectrum .u-tintBgColor {background-color: rgba(255, 255, 255, 1) !important;}.u-resetSpectrum .u-tintBgColor .u-fadeLeft:before {background-image: linear-gradient(to right, rgba(255, 255, 255, 1) 0%, rgba(255, 255, 255, 0) 100%) !important;}.u-resetSpectrum .u-tintBgColor .u-fadeRight:after {background-image: linear-gradient(to right, rgba(255, 255, 255, 0) 0%, rgba(255, 255, 255, 1) 100%) !important;}
.u-resetSpectrum .u-baseColor--borderLight {border-color: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--borderNormal {border-color: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--borderDark {border-color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--iconLight .svgIcon,.u-resetSpectrum .u-baseColor--iconLight.svgIcon {fill: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--iconNormal .svgIcon,.u-resetSpectrum .u-baseColor--iconNormal.svgIcon {fill: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--iconDark .svgIcon,.u-resetSpectrum .u-baseColor--iconDark.svgIcon {fill: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--textNormal {color: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--textNormal.u-baseColor--textDarken:hover {color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--textDark {color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--textDarker {color: rgba(0, 0, 0, 0.8) !important;}
.u-resetSpectrum .u-baseColor--backgroundLight {background-color: rgba(0, 0, 0, 0.09803921568627451) !important;}
.u-resetSpectrum .u-baseColor--backgroundNormal {background-color: rgba(0, 0, 0, 0.2) !important;}
.u-resetSpectrum .u-baseColor--backgroundDark {background-color: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonLight {border-color: rgba(0, 0, 0, 0.2980392156862745) !important; color: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonLight:hover {border-color: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonLight .icon:before,.u-resetSpectrum .u-baseColor--buttonLight .svgIcon {color: rgba(0, 0, 0, 0.2980392156862745) !important; fill: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonDark {border-color: rgba(0, 0, 0, 0.6) !important; color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--buttonDark:hover {border-color: rgba(0, 0, 0, 0.8) !important;}
.u-resetSpectrum .u-baseColor--buttonDark .icon:before,.u-resetSpectrum .u-baseColor--buttonDark .svgIcon {color: rgba(0, 0, 0, 0.6) !important; fill: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--buttonNormal {border-color: rgba(0, 0, 0, 0.4980392156862745) !important; color: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonNormal:hover {border-color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--buttonNormal .icon:before,.u-resetSpectrum .u-baseColor--buttonNormal .svgIcon {color: rgba(0, 0, 0, 0.4980392156862745) !important; fill: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonDark.button--filled,.u-resetSpectrum .u-baseColor--buttonDark.button--withChrome.is-active {background-color: rgba(0, 0, 0, 0.2980392156862745) !important; border-color: rgba(0, 0, 0, 0.2980392156862745) !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-resetSpectrum .u-baseColor--buttonNormal.button--filled,.u-resetSpectrum .u-baseColor--buttonNormal.button--withChrome.is-active {background-color: rgba(0, 0, 0, 0.2) !important; border-color: rgba(0, 0, 0, 0.2) !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-resetSpectrum .u-baseColor--link {color: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--link.link--darkenOnHover:hover {color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--link.link--darken:hover,.u-resetSpectrum .u-baseColor--link.link--darken:focus,.u-resetSpectrum .u-baseColor--link.link--darken:active {color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--link.link--dark {color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--link.link--dark.link--darken:hover,.u-resetSpectrum .u-baseColor--link.link--dark.link--darken:focus,.u-resetSpectrum .u-baseColor--link.link--dark.link--darken:active {color: rgba(0, 0, 0, 0.8) !important;}
.u-resetSpectrum .u-baseColor--link.link--darker {color: rgba(0, 0, 0, 0.8) !important;}
.u-resetSpectrum .u-baseColor--placeholderNormal ::-webkit-input-placeholder {color: rgba(0, 0, 0, 0.2980392156862745);}
.u-resetSpectrum .u-baseColor--placeholderNormal ::-moz-placeholder {color: rgba(0, 0, 0, 0.2980392156862745);}
.u-resetSpectrum .u-baseColor--placeholderNormal :-ms-input-placeholder {color: rgba(0, 0, 0, 0.2980392156862745);}
.u-resetSpectrum .svgIcon--logoWordmark {stroke: none !important; fill: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .svgIcon--logoMonogram {stroke: none !important; fill: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum  .ui-h1,.u-resetSpectrum  .ui-h2,.u-resetSpectrum  .ui-h3,.u-resetSpectrum  .ui-h4,.u-resetSpectrum  .ui-brand1,.u-resetSpectrum  .ui-brand2,.u-resetSpectrum  .ui-captionStrong {color: rgba(0, 0, 0, 0.8) !important; fill: rgba(0, 0, 0, 0.8) !important;}
.u-resetSpectrum  .ui-body,.u-resetSpectrum  .ui-caps {color: rgba(0, 0, 0, 0.6) !important; fill: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum  .ui-summary,.u-resetSpectrum  .ui-caption {color: rgba(0, 0, 0, 0.2980392156862745) !important; fill: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-accentColor--borderLight {border-color: rgba(2, 184, 117, 1) !important;}
.u-resetSpectrum .u-accentColor--borderNormal {border-color: rgba(2, 184, 117, 1) !important;}
.u-resetSpectrum .u-accentColor--borderDark {border-color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--iconLight .svgIcon,.u-resetSpectrum .u-accentColor--iconLight.svgIcon {fill: rgba(2, 184, 117, 1) !important;}
.u-resetSpectrum .u-accentColor--iconNormal .svgIcon,.u-resetSpectrum .u-accentColor--iconNormal.svgIcon {fill: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--iconDark .svgIcon,.u-resetSpectrum .u-accentColor--iconDark.svgIcon {fill: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--textNormal {color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--hoverTextNormal:hover {color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--textNormal.u-accentColor--textDarken:hover {color: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--textDark {color: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--backgroundLight {background-color: rgba(2, 184, 117, 1) !important;}
.u-resetSpectrum .u-accentColor--backgroundNormal {background-color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--backgroundDark {background-color: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonDark {border-color: rgba(0, 171, 107, 1) !important; color: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonDark:hover {border-color: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonDark .icon:before,.u-resetSpectrum .u-accentColor--buttonDark .svgIcon{color: rgba(28, 153, 99, 1) !important; fill: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonNormal:not(.clapButton--largePill) {border-color: rgba(2, 184, 117, 1) !important; color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonNormal:hover {border-color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonNormal .icon:before,.u-resetSpectrum .u-accentColor--buttonNormal .svgIcon{color: rgba(0, 171, 107, 1) !important; fill: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonNormal.button--filled .icon:before,.u-resetSpectrum .u-accentColor--buttonNormal.button--filled .svgIcon{color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonDark.button--filled,.u-resetSpectrum .u-accentColor--buttonDark.button--withChrome.is-active,.u-resetSpectrum .u-accentColor--fillWhenActive.is-active {background-color: rgba(28, 153, 99, 1) !important; border-color: rgba(28, 153, 99, 1) !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonNormal.button--filled:not(.clapButton--largePill),.u-resetSpectrum .u-accentColor--buttonNormal.button--withChrome.is-active:not(.clapButton--largePill) {background-color: rgba(0, 171, 107, 1) !important; border-color: rgba(0, 171, 107, 1) !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-resetSpectrum .postArticle.is-withAccentColors .markup--user,.u-resetSpectrum .postArticle.is-withAccentColors .markup--query {color: rgba(0, 171, 107, 1) !important;}</style><div class="highlightMenu" data-action-scope="_actionscope_3"><div class="highlightMenu-inner"><div class="buttonSet"><a class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--chromeless button--highlightMenu js-highlightMenuTwitterShare" href="https://medium.com/p/30285c779450/share/twitter" title="Share on Twitter" aria-label="Share on Twitter" target="_blank" data-action="twitter"><span class="button-defaultState"><span class="svgIcon svgIcon--twitterFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M21.725 5.338c-.744.47-1.605.804-2.513 1.006a3.978 3.978 0 0 0-2.942-1.293c-2.22 0-4.02 1.81-4.02 4.02 0 .32.034.63.07.94-3.31-.18-6.27-1.78-8.255-4.23a4.544 4.544 0 0 0-.574 2.01c.04 1.43.74 2.66 1.8 3.38-.63-.01-1.25-.19-1.79-.5v.08c0 1.93 1.38 3.56 3.23 3.95-.34.07-.7.12-1.07.14-.25-.02-.5-.04-.72-.07.49 1.58 1.97 2.74 3.74 2.8a8.49 8.49 0 0 1-5.02 1.72c-.3-.03-.62-.04-.93-.07A11.447 11.447 0 0 0 8.88 21c7.386 0 11.43-6.13 11.414-11.414.015-.21.01-.38 0-.578a7.604 7.604 0 0 0 2.01-2.08 7.27 7.27 0 0 1-2.297.645 3.856 3.856 0 0 0 1.72-2.23"></path></svg></span></span></a><div class="buttonSet-separator"></div><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--highlightMenu" data-action="sign-up-prompt" data-sign-in-action="highlight" data-redirect="https://ai-alignment.com/the-reward-engineering-problem-30285c779450" data-skip-onboarding="true" data-action-source="quote_menu--------------------------privatenote_text"><span class="svgIcon svgIcon--privatenoteFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M17.662 4.552H7.346A4.36 4.36 0 0 0 3 8.898v5.685c0 2.168 1.614 3.962 3.697 4.28v2.77c0 .303.35.476.59.29l3.904-2.994h6.48c2.39 0 4.35-1.96 4.35-4.35V8.9c0-2.39-1.95-4.346-4.34-4.346zM16 14.31a.99.99 0 0 1-1.003.99h-4.994C9.45 15.3 9 14.85 9 14.31v-3.02a.99.99 0 0 1 1-.99v-.782a2.5 2.5 0 0 1 2.5-2.51c1.38 0 2.5 1.13 2.5 2.51v.782c.552.002 1 .452 1 .99v3.02z"></path><path d="M14 9.81c0-.832-.674-1.68-1.5-1.68-.833 0-1.5.84-1.5 1.68v.49h3v-.49z"></path></g></svg></span></button></div></div><div class="highlightMenu-arrowClip"><span class="highlightMenu-arrow"></span></div></div></div></div></div><div class="loadingBar"></div><script>// <![CDATA[
window["obvInit"] = function (opt_embedded) {window["obvInit"]["embedded"] = opt_embedded; window["obvInit"]["ready"] = true;}
// ]]></script><script>// <![CDATA[
var GLOBALS = {"audioUrl":"https://d1fcbxp97j4nb2.cloudfront.net","baseUrl":"https://ai-alignment.com","buildLabel":"37496-7f20643","currentUser":{"userId":"lo_JuU2p2EvGepj","isVerified":false,"subscriberEmail":"","hasPastMemberships":false,"isEnrolledInHightower":false,"isEligibleForHightower":false,"hightowerLastLockedAt":0,"isWriterProgramEnrolled":true,"isWriterProgramInvited":false,"isWriterProgramOptedOut":false,"writerProgramVersion":0,"writerProgramEnrolledAt":0,"friendLinkOnboarding":0,"hasAdditionalUnlocks":false,"hasApiAccess":false,"isQuarantined":false,"writerProgramDistributionSettingOptedIn":false},"currentUserHasUnverifiedEmail":false,"isAuthenticated":false,"isCurrentUserVerified":false,"miroUrl":"https://cdn-images-1.medium.com","moduleUrls":{"base":"https://cdn-static-1.medium.com/_/fp/gen-js/main-base.bundle.h-S66qYGELCwGMjo-I5sGg.js","common-async":"https://cdn-static-1.medium.com/_/fp/gen-js/main-common-async.bundle.qFZkgzLZ5TYXIerh_w9awQ.js","hightower":"https://cdn-static-1.medium.com/_/fp/gen-js/main-hightower.bundle.YYDLiHqz4VuEAfIKbpgHlA.js","home-screens":"https://cdn-static-1.medium.com/_/fp/gen-js/main-home-screens.bundle.KOsn4BMHvTHwO7kChpWnwQ.js","misc-screens":"https://cdn-static-1.medium.com/_/fp/gen-js/main-misc-screens.bundle.9HQt5flvjhqNbC82Kz7w3A.js","notes":"https://cdn-static-1.medium.com/_/fp/gen-js/main-notes.bundle.V05mXLtyLz2Mj5DzEML26A.js","payments":"https://cdn-static-1.medium.com/_/fp/gen-js/main-payments.bundle.4s7BX_pcnrqTR9pXdg44lw.js","posters":"https://cdn-static-1.medium.com/_/fp/gen-js/main-posters.bundle.oAF5QtbeXBsEy2D-ZeKzOA.js","power-readers":"https://cdn-static-1.medium.com/_/fp/gen-js/main-power-readers.bundle.242jbfrxhns9kmBC8hYbGA.js","pubs":"https://cdn-static-1.medium.com/_/fp/gen-js/main-pubs.bundle.OVIBk1ifJgWYBiuHy2mNlA.js","stats":"https://cdn-static-1.medium.com/_/fp/gen-js/main-stats.bundle.FRAzB3YCXktr7d19iN9skg.js"},"previewConfig":{"weightThreshold":1,"weightImageParagraph":0.51,"weightIframeParagraph":0.8,"weightTextParagraph":0.08,"weightEmptyParagraph":0,"weightP":0.003,"weightH":0.005,"weightBq":0.003,"minPTextLength":60,"truncateBoundaryChars":20,"detectTitle":true,"detectTitleLevThreshold":0.15},"productName":"Medium","supportsEdit":false,"termsUrl":"//medium.com/policy/9db0094a1e0f","textshotHost":"textshot.medium.com","transactionId":"1557467436332:1911242263f9","useragent":{"browser":"headlesschrome","family":"chrome","os":"mac","version":0,"supportsDesktopEdit":false,"supportsInteract":false,"supportsView":true,"isMobile":false,"isTablet":false,"isNative":false,"supportsFileAPI":false,"isTier1":false,"clientVersion":"","unknownParagraphsBad":false,"clientChannel":"","supportsRealScrollEvents":false,"supportsVhUnits":false,"ruinsViewportSections":false,"supportsHtml5Video":false,"supportsMagicUnderlines":false,"isWebView":false,"isFacebookWebView":false,"supportsProgressiveMedia":false,"supportsPromotedPosts":true,"isBot":false,"isNativeIphone":false,"supportsCssVariables":false,"supportsVideoSections":true,"emojiSupportLevel":5,"isSearchBot":false,"isSyndicationBot":false,"isNativeAndroid":false,"isNativeIos":false,"supportsScrollableMetabar":false},"variants":{"allow_access":true,"allow_signup":true,"allow_test_auth":"disallow","signin_services":"twitter,facebook,google,email,google-fastidv,google-one-tap","signup_services":"twitter,facebook,google,email,google-fastidv,google-one-tap","google_sign_in_android":true,"reengagement_notification_duration":3,"browsable_stream_config_bucket":"curated-topics","enable_dedicated_series_tab_api_ios":true,"enable_post_import":true,"available_monthly_plan":"60e220181034","available_annual_plan":"2c754bcc2995","disable_ios_resume_reading_toast":true,"is_not_medium_subscriber":true,"glyph_font_set":"m2","enable_branding":true,"enable_branding_fonts":true,"max_premium_content_per_user_under_metering":3,"enable_automated_mission_control_triggers":true,"enable_lite_profile":true,"enable_marketing_emails":true,"enable_topic_lifecycle_email":true,"enable_parsely":true,"enable_branch_io":true,"enable_ios_post_stats":true,"enable_lite_topics":true,"enable_lite_stories":true,"redis_read_write_splitting":true,"enable_tipalti_onboarding":true,"enable_annual_renewal_reminder_email":true,"enable_janky_spam_rules":"users,posts","enable_new_collaborative_filtering_data":true,"android_rating_prompt_stories_read_threshold":2,"stripe_v3":true,"enable_google_one_tap":true,"enable_email_sign_in_captcha":true,"enable_rito_with_viewer_query":true,"enable_rito_with_flag_query":true,"enable_rito_post_handler":true,"enable_rito_sequence_post_recirc_query":true,"enable_rito_post_recirc_query":true,"enable_rito_topic_handler":true,"enable_rito_stats_post_handler":true,"enable_rito_stats_post_chart":true,"enable_rito_lifetime_earnings_tooltip":true,"enable_rito_stats_post_referrers_container":true,"enable_rito_post_feature_mutation":true,"enable_rito_post_unfeature_mutation":true,"enable_rito_quote_delete_mutation":true,"enable_rito_user_block_mutation":true,"enable_rito_user_unblock_mutation":true,"enable_rito_report_user_link":true,"enable_rito_bookmark_post_default":true,"enable_rito_unbookmark_post_default":true,"enable_rito_archive_post_default":true,"enable_rito_unarchive_post_default":true,"enable_rito_clap":true,"enable_rito_subscribe_series":true,"enable_rito_unsubscribe_series":true,"enable_rito_follow_topic":true,"enable_rito_unfollow_topic":true,"enable_rito_follow_user":true,"enable_rito_unfollow_user":true,"enable_rito_your_story_delete_mutation":true,"enable_rito_update_last_read_section":true,"editorial_push_notifications":true,"enable_primary_topic_for_mobile":true,"enable_rito_sequence_post_handler":true,"enable_todays_highlights_ios":true,"enable_logged_out_homepage_signup":true,"use_new_admin_topic_backend":true,"enable_quarantine_rules":true,"enable_lite_privacy_banner":true,"enable_patronus_on_kubernetes":true,"pub_sidebar":true,"disable_mobile_featured_chunk":true,"enable_rito_user_profile_overview_handler":true,"enable_rito_user_stream_overview":true,"enable_rito_user_profile_latest_handler":true,"enable_rito_user_stream_latest":true,"enable_rito_user_profile_actions":true,"enable_rito_post_actions":true,"enable_rito_user_profile_highlights_handler":true,"enable_rito_user_stream_highlights":true,"enable_rito_user_profile_series_handler":true,"enable_rito_user_stream_series":true,"enable_rito_user_profile_claps_handler":true,"enable_rito_user_stream_claps":true,"enable_rito_user_profile_responses_handler":true,"enable_rito_user_stream_responses":true,"enable_rito_billing_history_handler":true,"enable_rito_your_stories_handler":true,"enable_rito_sequence_library_handler":true,"enable_rito_series_handler":true,"enable_rito_amppost_handler":true,"enable_rito_follow_collection_mutation":true,"enable_rito_unfollow_collection_mutation":true,"enable_pub_newsletters":true,"enable_may_meter_email_test":true,"enable_rex_app_highlights":true,"enable_new_user_avatar_dropdown_menu":true,"enable_mobile_pubcrawl_home_feed":true,"enable_draft_in_post_cotent":true},"xsrfToken":"","iosAppId":"828256236","supportEmail":"yourfriends@medium.com","fp":{"/icons/monogram-mask.svg":"https://cdn-static-1.medium.com/_/fp/icons/monogram-mask.KPLCSFEZviQN0jQ7veN2RQ.svg","/icons/favicon-dev-editor.ico":"https://cdn-static-1.medium.com/_/fp/icons/favicon-dev-editor.YKKRxBO8EMvIqhyCwIiJeQ.ico","/icons/favicon-hatch-editor.ico":"https://cdn-static-1.medium.com/_/fp/icons/favicon-hatch-editor.BuEyHIqlyh2s_XEk4Rl32Q.ico","/icons/favicon-medium-editor.ico":"https://cdn-static-1.medium.com/_/fp/icons/favicon-medium-editor.PiakrZWB7Yb80quUVQWM6g.ico"},"authBaseUrl":"https://medium.com","imageUploadSizeMb":25,"isAuthDomainRequest":false,"domainCollectionSlug":"ai-control","algoliaApiEndpoint":"https://MQ57UUUQZ2-dsn.algolia.net","algoliaAppId":"MQ57UUUQZ2","algoliaSearchOnlyApiKey":"394474ced050e3911ae2249ecc774921","iosAppStoreUrl":"https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8","iosAppLinkBaseUrl":"medium:","algoliaIndexPrefix":"medium_","androidPlayStoreUrl":"https://play.google.com/store/apps/details?id=com.medium.reader","googleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","androidPackage":"com.medium.reader","androidPlayStoreMarketScheme":"market://details?id=com.medium.reader","googleAuthUri":"https://accounts.google.com/o/oauth2/auth","androidScheme":"medium","layoutData":{"useDynamicScripts":false,"googleAnalyticsTrackingCode":"UA-24232453-2","jsShivUrl":"https://cdn-static-1.medium.com/_/fp/js/shiv.RI2ePTZ5gFmMgLzG5bEVAA.js","useDynamicCss":false,"faviconUrl":"https://cdn-static-1.medium.com/_/fp/icons/favicon-rebrand-medium.3Y6xpZ-0FSdWDnPM3hSBIA.ico","faviconImageId":"1*8I-HPL0bfoIzGied-dzOvA.png","fontSets":[{"id":8,"url":"https://glyph.medium.com/css/e/sr/latin/e/ssr/latin/e/ssb/latin/m2.css"},{"id":11,"url":"https://glyph.medium.com/css/m2.css"},{"id":9,"url":"https://glyph.medium.com/css/mkt.css"}],"editorFaviconUrl":"https://cdn-static-1.medium.com/_/fp/icons/favicon-rebrand-medium-editor.3Y6xpZ-0FSdWDnPM3hSBIA.ico","glyphUrl":"https://glyph.medium.com"},"authBaseUrlRev":"moc.muidem//:sptth","isDnt":false,"stripePublishableKey":"pk_live_7FReX44VnNIInZwrIIx6ghjl","archiveUploadSizeMb":100,"paymentData":{"currencies":{"1":{"label":"US Dollar","external":"usd"}},"countries":{"1":{"label":"United States of America","external":"US"}},"accountTypes":{"1":{"label":"Individual","external":"individual"},"2":{"label":"Company","external":"company"}}},"previewConfig2":{"weightThreshold":1,"weightImageParagraph":0.05,"raiseImage":true,"enforceHeaderHierarchy":true,"isImageInsetRight":true},"isAmp":false,"iosScheme":"medium","isSwBoot":false,"lightstep":{"accessToken":"ce5be895bef60919541332990ac9fef2","carrier":"{\"ot-tracer-spanid\":\"0c2965125ef431cb\",\"ot-tracer-traceid\":\"3b37652732dadfef\",\"ot-tracer-sampled\":\"true\"}","host":"collector-medium.lightstep.com"},"facebook":{"key":"542599432471018","namespace":"medium-com","scope":{"default":["public_profile","email"],"connect":["public_profile","email"],"login":["public_profile","email"],"share":["public_profile","email"]}},"editorsPicksTopicId":"3985d2a191c5","popularOnMediumTopicId":"9d34e48ecf94","memberContentTopicId":"13d7efd82fb2","audioContentTopicId":"3792abbd134","brandedSequenceId":"7d337ddf1941","isDoNotAuth":false,"buggle":{"url":"https://buggle.medium.com","videoUrl":"https://cdn-videos-1.medium.com","audioUrl":"https://cdn-audio-1.medium.com"},"referrerType":5,"isMeteredOut":false,"meterConfig":{"maxUnlockCount":3,"windowLength":"MONTHLY"},"partnerProgramEmail":"partnerprogram@medium.com","userResearchPrompts":[{"promptId":"lo_post_page_4","type":0,"url":"www.calendly.com"},{"promptId":"lo_home_page","type":1,"url":"www.calendly.com"},{"promptId":"lo_profile_page","type":2,"url":"www.calendly.com"}],"recaptchaKey":"6LdAokEUAAAAAC7seICd4vtC8chDb3jIXDQulyUJ","signinWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"countryCode":"US","bypassMeter":false,"branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","paypal":{"clientMode":"production","oneYearGift":{"name":"Medium Membership (1 Year, Digital Gift Code)","description":"Unlimited access to the best and brightest stories on Medium. Gift codes can be redeemed at medium.com/redeem.","price":"50.00","currency":"USD","sku":"membership-gift-1-yr"}},"collectionConfig":{"mediumOwnedAndOperatedCollectionIds":["544c7006046e // Human Parts","bcc38c8f6edf // Matter","444d13b52878 // OneZero","8d6b8a439e32 // Elemental","92d2092dc598 // Gay Mag","1285ba81cada // Heated"]}}
// ]]></script><script charset="UTF-8" src="https://cdn-static-1.medium.com/_/fp/gen-js/main-base.bundle.h-S66qYGELCwGMjo-I5sGg.js" async=""></script><script>// <![CDATA[
window["obvInit"]({"value":{"id":"30285c779450","versionId":"c8b5f4a5d7e3","creatorId":"57f1a655a613","creator":{"userId":"57f1a655a613","name":"Paul Christiano","username":"paulfchristiano","createdAt":1417286353352,"imageId":"1*BNjZCuQuRfIgcXCBMipuBw.jpeg","backgroundImageId":"","bio":"OpenAI","twitterScreenName":"","socialStats":{"userId":"57f1a655a613","usersFollowedCount":93,"usersFollowedByCount":821,"type":"SocialStats"},"social":{"userId":"lo_JuU2p2EvGepj","targetUserId":"57f1a655a613","type":"Social"},"facebookAccountId":"1167284919","allowNotes":1,"mediumMemberAt":0,"isNsfw":false,"isWriterProgramEnrolled":true,"isQuarantined":false,"type":"User"},"homeCollection":{"id":"624d886c4aa4","name":"AI Alignment","slug":"ai-control","tags":[],"creatorId":"57f1a655a613","description":"Aligning AI systems with human interests.","shortDescription":"Aligning AI systems with human interests.","image":{"imageId":"1*N56Qc5-aHTcfGff0scntKQ.png","filter":"","backgroundSize":"","originalWidth":512,"originalHeight":512,"strategy":"resample","height":0,"width":0},"metadata":{"followerCount":2834,"activeAt":1548040822588},"virtuals":{"permissions":{"canPublish":false,"canPublishAll":false,"canRepublish":false,"canRemove":false,"canManageAll":false,"canSubmit":false,"canEditPosts":false,"canAddWriters":false,"canViewStats":false,"canSendNewsletter":false,"canViewLockedPosts":false,"canViewCloaked":false,"canEditOwnPosts":false,"canBeAssignedAuthor":false,"canEnrollInHightower":false,"canLockPostsForMediumMembers":false,"canLockOwnPostsForMediumMembers":false},"isSubscribed":false,"isNewsletterSubscribed":false,"isEnrolledInHightower":false,"isEligibleForHightower":false},"logo":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"collectionMastheadId":"29f3dcc2e4","domain":"ai-alignment.com","sections":[{"type":2,"collectionHeaderMetadata":{"title":"AI Alignment","backgroundImage":{},"logoImage":{},"alignment":2,"layout":4}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":3,"postIds":["157debfd1616","b49ad992940b","b959644d79c2"]}},{"type":1,"postListMetadata":{"source":1,"layout":4,"number":24,"postIds":[],"sectionHeader":"Latest"}}],"favicon":{"imageId":"1*cciPf4CUXd_Zyux0Jg0yBQ.png","filter":"","backgroundSize":"","originalWidth":400,"originalHeight":400,"strategy":"resample","height":0,"width":0},"colorPalette":{"defaultBackgroundSpectrum":{"colorPoints":[{"color":"#FF02B875","point":0},{"color":"#FF00AB6B","point":0.1},{"color":"#FF1C9963","point":0.2},{"color":"#FF092E20","point":1}],"backgroundColor":"#FFFFFFFF"},"highlightSpectrum":{"colorPoints":[{"color":"#FFFFFFFF","point":0},{"color":"#FFE9FDF0","point":0.1},{"color":"#FFE2FAEE","point":0.2},{"color":"#FFADFFCF","point":0.6},{"color":"#FF7DFFB3","point":1}],"backgroundColor":"#FFFFFFFF"}},"navItems":[],"colorBehavior":1,"instantArticlesState":0,"acceleratedMobilePagesState":0,"ampLogo":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"header":{"title":"AI Alignment","backgroundImage":{},"logoImage":{},"alignment":2,"layout":4},"paidForDomainAt":1490733089988,"type":"Collection"},"homeCollectionId":"624d886c4aa4","title":"The reward engineering problem","detectedLanguage":"en","latestVersion":"c8b5f4a5d7e3","latestPublishedVersion":"c8b5f4a5d7e3","hasUnpublishedEdits":false,"latestRev":1635,"createdAt":1464496434469,"updatedAt":1523555307578,"acceptedAt":0,"firstPublishedAt":1464651070254,"latestPublishedAt":1476379165590,"vote":false,"experimentalCss":"","displayAuthor":"","content":{"subtitle":"How can we define rewards which incentivize weak RL agents to behave in a desirable way?","bodyModel":{"paragraphs":[{"name":"4104","type":3,"text":"The reward engineering problem","markups":[]},{"name":"67a5","type":1,"text":"Today we usually train reinforcement learning agents to perform narrow tasks with simple goals. We may eventually want to train RL agents to behave “well” in open-ended environments where there is no simple goal.","markups":[]},{"name":"7255","type":1,"text":"Suppose that we are trying to train an RL agent A. In each episode, A interacts with an environment, producing a transcript τ. We then evaluate that transcript, producing a reward r ∈ [0, 1]. A is trained is to maximize its reward.","markups":[{"type":1,"start":48,"end":49},{"type":1,"start":68,"end":69},{"type":1,"start":192,"end":193},{"type":2,"start":135,"end":143},{"type":2,"start":180,"end":181}]},{"name":"26d0","type":1,"text":"We would like to set up the rewards so that A will learn to behave well — that is, such that if A learns to receive a high reward, then we will be happy with A’s behavior.","markups":[{"type":1,"start":44,"end":45},{"type":1,"start":96,"end":97},{"type":1,"start":158,"end":159},{"type":2,"start":93,"end":95},{"type":2,"start":131,"end":135}]},{"name":"c11c","type":1,"text":"To make the problem feasible, we assume that we have access to another agent H which","markups":[{"type":1,"start":77,"end":78}]},{"name":"700f","type":10,"text":"is “smarter” than A, and","markups":[{"type":1,"start":18,"end":19}]},{"name":"dcdf","type":10,"text":"makes “good” decisions.","markups":[]},{"name":"90d6","type":1,"text":"In order to evaluate transcript τ, we allow ourselves to make any number of calls to H, and to use any other tools that are available. The question is: how do we carry out the evaluation, so that the optimal strategy for A is to also make “good” decisions?","markups":[{"type":1,"start":85,"end":86},{"type":1,"start":221,"end":222}]},{"name":"9925","type":1,"text":"Following Daniel Dewey, I’ll call this the reward engineering problem.","markups":[{"type":3,"start":0,"end":22,"href":"https://medium.com/@paulfchristiano/30285c779450","title":"","rel":"","anchorType":0},{"type":2,"start":43,"end":69}]},{"name":"3d71","type":1,"text":"Note that our evaluation process may be quite expensive, and actually implementing it may be infeasible. To build a working system, we would need to combine this evaluation with semi-supervised RL and learning with catastrophes.","markups":[{"type":3,"start":178,"end":196,"href":"https://medium.com/ai-control/semi-supervised-reinforcement-learning-cf7d5375197f#.rm5dypm4a","title":"","rel":"","anchorType":0},{"type":3,"start":201,"end":227,"href":"https://medium.com/ai-control/learning-with-catastrophes-59387b55cc30#.vctnbxafg","title":"","rel":"","anchorType":0}]},{"name":"1ebd","type":13,"text":"Possible approaches and remaining problems","markups":[]},{"name":"a589","type":1,"text":"I know of 3 basic approaches to reward engineering:","markups":[]},{"name":"e1a0","type":10,"text":"Direct supervision. Use H to evaluate A’s behavior, and train A to maximize H’s evaluations. In some contexts we could compare two behaviors instead of evaluating one in isolation.","markups":[{"type":3,"start":119,"end":140,"href":"https://medium.com/ai-control/optimizing-with-comparisons-c02b8c0d7877#.jx6i2cxxu","title":"","rel":"","anchorType":0},{"type":1,"start":0,"end":18},{"type":1,"start":24,"end":25},{"type":1,"start":38,"end":39},{"type":1,"start":62,"end":63},{"type":1,"start":76,"end":77}]},{"name":"1095","type":10,"text":"Imitation learning. Use H to generate a bunch of transcripts, and train A to produce similar-looking transcripts. For example, we could train a model to distinguish A’s behavior from H’s behavior, and reward A when it fools the distinguisher.","markups":[{"type":1,"start":0,"end":18},{"type":1,"start":24,"end":25},{"type":1,"start":72,"end":73},{"type":1,"start":165,"end":166},{"type":1,"start":183,"end":184},{"type":1,"start":208,"end":209}]},{"name":"ca47","type":10,"text":"Inverse reinforcement learning. Use H to generate a bunch of transcripts, and then infer a reward function which is being approximately optimized by H. Use this reward function to evaluate A’s behavior.","markups":[{"type":1,"start":0,"end":30},{"type":1,"start":36,"end":37},{"type":1,"start":149,"end":150},{"type":1,"start":189,"end":190}]},{"name":"66a8","type":1,"text":"All of these approaches are promising but face significant challenges. I’ll describe some of these problems in the next 3 sections.","markups":[]},{"name":"8bcc","type":3,"text":"1. Direct supervision","markups":[]},{"name":"98e4","type":1,"text":"In direct supervision, H looks at a transcript of A’s behavior, and estimates how good that transcript is.","markups":[{"type":1,"start":23,"end":24},{"type":1,"start":50,"end":51}]},{"name":"e67e","type":1,"text":"To see the problem with this scheme, suppose that A has been asked to draw a picture, and A does it by copying an existing picture with some modifications. If originality is especially important, then this may be a very “bad” policy. But even if H is much smarter than A, it may be hard to tell that the picture is not original — creating a derivative work only requires looking at a single existing picture, while checking if a work is derivative requires considering every picture.","markups":[{"type":1,"start":50,"end":51},{"type":1,"start":90,"end":91},{"type":1,"start":246,"end":247},{"type":1,"start":269,"end":270},{"type":2,"start":469,"end":475}]},{"name":"c2c5","type":1,"text":"More formally: in order for direct supervision to be effective, H needs to be better-informed than A about what is “good.” If this condition is satisfied, then from A’s perspective, estimating H’s estimate of goodness is equivalent to estimating actual goodness. This condition is superficially plausible — after all, we did assume that H is smarter than A.","markups":[{"type":3,"start":64,"end":122,"href":"https://medium.com/ai-control/adequate-oversight-25fadf1edce9#.1aj4sfjiu","title":"","rel":"","anchorType":0},{"type":1,"start":64,"end":65},{"type":1,"start":99,"end":100},{"type":1,"start":165,"end":166},{"type":1,"start":193,"end":194},{"type":1,"start":337,"end":338},{"type":1,"start":355,"end":356}]},{"name":"cb40","type":1,"text":"The problem is that when A picks an action, A is especially well-informed about that action — the computation which produced the action provides evidence about it, and H may not have access to that evidence.","markups":[{"type":1,"start":25,"end":26},{"type":1,"start":44,"end":45},{"type":1,"start":168,"end":170}]},{"name":"12df","type":13,"text":"Transparency","markups":[]},{"name":"4e13","type":1,"text":"One response is to let H see how A computed its action. If H can understand that process, then H may be able to effectively evaluate the action.","markups":[{"type":1,"start":23,"end":24},{"type":1,"start":33,"end":34},{"type":1,"start":59,"end":60},{"type":1,"start":95,"end":96},{"type":2,"start":29,"end":32}]},{"name":"73ab","type":1,"text":"Sometimes this is straightforward: for example, if A uses an attention mechanism to look at a particular painting and copy it, we can simply tell H what A looked at.","markups":[{"type":1,"start":51,"end":52},{"type":1,"start":146,"end":148},{"type":1,"start":153,"end":154}]},{"name":"d1cc","type":1,"text":"In other contexts it might be much more challenging. For example, A may copy an image by “memorizing” the image in its weights, rather than by “looking at” the image at test time.","markups":[{"type":1,"start":66,"end":67}]},{"name":"e187","type":1,"text":"One approach to these challenging cases is to train A to produce actions and to produce explanations that are maximally helpful for evaluating those actions. For example, we may train A to produce images and to point out similarities between its output and training images.","markups":[{"type":1,"start":52,"end":53},{"type":1,"start":184,"end":185},{"type":2,"start":73,"end":76},{"type":2,"start":204,"end":207}]},{"name":"bf1e","type":1,"text":"This is a challenging problem for several reasons. One issue is that producing these explanations involves a huge “action space” and a very complex objective. A more subtle problem is that there are two conflicting objectives: A wants to produce actions that H evaluates as “good,” but providing useful information will sometimes lead H to produce a lower evaluation. Training A to do both tasks requires a new approach.","markups":[{"type":1,"start":227,"end":228},{"type":1,"start":259,"end":260},{"type":1,"start":335,"end":336},{"type":1,"start":377,"end":378}]},{"name":"2d0e","type":13,"text":"Other problems","markups":[]},{"name":"7262","type":1,"text":"We can imagine other failure modes of direct supervision. For example, A may find an action that exploits one of H’s biases or blind spots in order to receive a high rating.","markups":[{"type":1,"start":71,"end":72},{"type":1,"start":113,"end":114}]},{"name":"ab80","type":1,"text":"We hope that these “attacks” can only succeed if H is ignorant about the process that produced a given action, and so can be resolved by whatever form of transparency allows H to accurately evaluate A’s actions in general.","markups":[{"type":1,"start":49,"end":50},{"type":1,"start":174,"end":175},{"type":1,"start":199,"end":200}]},{"name":"3b91","type":1,"text":"That is, if A carefully explains to H how an action was chosen to exploit H’s biases, then H can hopefully avoid being exploited. This seems especially plausible given that H is smarter than A.","markups":[{"type":1,"start":12,"end":13},{"type":1,"start":36,"end":37},{"type":1,"start":74,"end":75},{"type":1,"start":91,"end":92},{"type":1,"start":173,"end":174},{"type":1,"start":191,"end":192}]},{"name":"2c89","type":3,"text":"2. Imitation learning","markups":[]},{"name":"6d37","type":1,"text":"Imitation learning has two conceptual problems:","markups":[]},{"name":"a929","type":9,"text":"If H is more competent than A, then A will generally be unable to imitate H’s behavior.","markups":[{"type":1,"start":3,"end":4},{"type":1,"start":28,"end":29},{"type":1,"start":36,"end":37},{"type":1,"start":74,"end":75}]},{"name":"8ae8","type":9,"text":"We don’t have a totally satisfactory framework for reducing imitation learning to an optimization problem.","markups":[]},{"name":"53ec","type":13,"text":"What if A can’t imitate H?","markups":[]},{"name":"12ab","type":1,"text":"Suppose that A has been asked to build a block tower. H can quickly stack the blocks, and 99% of the time the tower stays standing; 1% of the time H messes up and the tower falls down. A is not as capable as H, and so if it tries to stack the blocks quickly the tower falls down 100% of the time.","markups":[{"type":1,"start":13,"end":14},{"type":1,"start":54,"end":55},{"type":1,"start":147,"end":148},{"type":1,"start":185,"end":186},{"type":1,"start":208,"end":209}]},{"name":"1708","type":1,"text":"The “best” behavior for A may be to stack the blocks more slowly, so that the tower can stay standing. But this behavior is hard to induce with imitation learning, because H never stacks the blocks slowly. Instead, an imitation learner is more likely to try to stack the blocks quickly and fail (since at least H does this 1% of the time).","markups":[{"type":1,"start":24,"end":26},{"type":1,"start":172,"end":173},{"type":1,"start":311,"end":313},{"type":2,"start":174,"end":179}]},{"name":"232e","type":1,"text":"One response to this problem is to have H “dumb down” its behavior so that it can be copied by A.","markups":[{"type":1,"start":40,"end":41},{"type":1,"start":95,"end":96}]},{"name":"f4f9","type":1,"text":"However, this process may be challenging for H. Finding a way to do a task which is within A’s abilities may be much harder than simply doing the task — for example, it may require a deep understanding of A’s limitations and capabilities.","markups":[{"type":1,"start":45,"end":46},{"type":1,"start":91,"end":92},{"type":1,"start":205,"end":206}]},{"name":"9c6d","type":1,"text":"I’ve proposed a procedure, “meeting halfway,” for addressing this problem. The idea is that we train a discriminator to distinguish H’s behavior from A’s behavior, and use the discriminator’s output to help H behave in an “A-like” way. This proposal faces many challenges, and it’s not at all clear if it can work.","markups":[{"type":3,"start":28,"end":43,"href":"https://medium.com/ai-control/mimicry-maximization-and-meeting-halfway-c149dd23fc17#.l513cw5l0","title":"","rel":"","anchorType":0},{"type":1,"start":132,"end":133},{"type":1,"start":150,"end":151},{"type":1,"start":207,"end":208},{"type":1,"start":223,"end":224}]},{"name":"5211","type":13,"text":"How do you train an imitator?","markups":[]},{"name":"02cc","type":1,"text":"The plagiarism example from the last section is also a challenge for imitation learning. Suppose that A has been asked to draw a picture. H would draw a completely original picture. How can we train A to draw an original picture?","markups":[{"type":1,"start":102,"end":104},{"type":1,"start":138,"end":140},{"type":1,"start":199,"end":200}]},{"name":"758b","type":1,"text":"The most plausible existing approach is probably generative adversarial networks. In this approach, a discriminator is trained to distinguish A’s behavior from H’s behavior, and A is trained to fool the discriminator.","markups":[{"type":1,"start":142,"end":143},{"type":1,"start":160,"end":161},{"type":1,"start":178,"end":179}]},{"name":"f634","type":1,"text":"But suppose that A draws a picture by copying an existing image. It may be hard for the discriminator to learn to distinguish “original image” from “derivative of existing image,” for exactly the same reasons discussed before. And so A may receive just as high a reward by copying an existing image as by drawing a novel picture.","markups":[{"type":1,"start":17,"end":19},{"type":1,"start":234,"end":235}]},{"name":"c8df","type":1,"text":"Unfortunately, solving this problem seems even more difficult for reinforcement learning. We can’t give the discriminator any access to A’s internal state, since the discriminator isn’t supposed to know whether it is looking at data that came from A or from H.","markups":[{"type":1,"start":136,"end":137},{"type":1,"start":248,"end":249},{"type":1,"start":258,"end":259}]},{"name":"a87a","type":1,"text":"Instead, it might be easier to use an alternative to the generative adversarial networks framework. There are some plausible contenders, but nothing is currently known that could plausibly scale to general behavior in complex environments. (Though the obstacles are not always obvious.)","markups":[]},{"name":"a48a","type":3,"text":"3. Inverse reinforcement learning","markups":[]},{"name":"6255","type":1,"text":"In IRL, we try to infer a reward function that H is approximately maximizing. We can then use that reward function to train A.","markups":[{"type":1,"start":47,"end":49},{"type":1,"start":124,"end":125}]},{"name":"5495","type":1,"text":"This approach is closely connected to imitation learning, and faces exactly analogous difficulties:","markups":[]},{"name":"7b7d","type":9,"text":"H’s behavior does not give much information about the reward function in regions far from H’s trajectory.","markups":[{"type":1,"start":0,"end":1},{"type":1,"start":90,"end":91}]},{"name":"0182","type":9,"text":"If we first learn a reward function and then use it to train A, then the reward function is essentially a direct supervisor and faces exactly the same difficulties.","markups":[{"type":1,"start":61,"end":63}]},{"name":"85dc","type":1,"text":"The second problem seems to be the most serious: unless we find a resolution to that problem, then direct supervision seems more promising than IRL. (Though IRL may still be a useful technique for the resulting RL problem — understanding the supervisor’s values is a critical subtask of solving an RL problem defined by direct supervision.)","markups":[{"type":3,"start":161,"end":221,"href":"https://medium.com/ai-control/learn-policies-or-goals-348add76b8eb#.rvsv6syfl","title":"","rel":"","anchorType":0}]},{"name":"1dc3","type":13,"text":"H’s behavior is not sufficiently informative","markups":[{"type":1,"start":0,"end":44}]},{"name":"bf9c","type":1,"text":"Consider the block tower example from the last section. If H always quickly builds a perfect block tower, then H’s behavior does not give any evidence about tradeoffs between different imperfections: how much should A be willing to compromise on quality to get the job done faster? If the tower can only be tall or stable, which is preferred?","markups":[{"type":1,"start":59,"end":60},{"type":1,"start":111,"end":112},{"type":1,"start":216,"end":217},{"type":2,"start":312,"end":314}]},{"name":"7ad0","type":1,"text":"To get around this difficulty, we would like to elicit information from H other than trajectories. For example, we might ask H questions, and use those questions as evidence about H’s reward function.","markups":[{"type":1,"start":72,"end":74},{"type":1,"start":125,"end":127},{"type":1,"start":180,"end":181}]},{"name":"82aa","type":1,"text":"Incorporating this information is much less straightforward than incorporating information from H’s behavior. For example, updating on H’s statements require an explicit model of how H believes its statements relate to its goals, even though we can’t directly observe that relationship. This is much more complex than existing approaches like MaxEnt IRL, which fit a simple model directly to H’s behavior.","markups":[{"type":1,"start":96,"end":97},{"type":1,"start":135,"end":136},{"type":1,"start":183,"end":184},{"type":1,"start":392,"end":393}]},{"name":"4e1e","type":1,"text":"These issues are central in “cooperative IRL.” For now there are many open problems.","markups":[]},{"name":"7207","type":13,"text":"The major difficulties of direct supervision still apply","markups":[]},{"name":"c192","type":1,"text":"The bigger problem for IRL is how to represent the reward function:","markups":[]},{"name":"00ef","type":9,"text":"If the reward function is represented by a concrete, learned function from trajectories to rewards, then we are back in the situation of direct supervision.","markups":[]},{"name":"0783","type":9,"text":"Instead the reward function may act on an abstract space of “possible worlds.” This approach potentially avoids the difficulties of direct supervision, but it seems to require a particular form of model-based RL. It’s not clear if this constraint will be compatible with the most effective approaches to reinforcement learning.","markups":[]},{"name":"139b","type":1,"text":"Ideally we would find a better representation that incorporates the best of both worlds — avoiding the difficulties of direct supervision, without seriously restricting the form of A.","markups":[{"type":1,"start":181,"end":182}]},{"name":"d60b","type":1,"text":"Alternatively, we could hope that powerful RL agents have an appropriate model-based architecture. Or we could do research on appropriate forms of model-based RL to increase the probability that they are competitive.","markups":[]},{"name":"5939","type":3,"text":"Research directions","markups":[]},{"name":"80ad","type":1,"text":"Each of the problems discussed in this post is a possible direction for research. I think that three problems are especially promising:","markups":[]},{"name":"da43","type":9,"text":"Training ML systems to produce the kind of auxiliary information that could make direct supervision reliable. There are open theoretical questions about how this training should be done — and huge practical obstacles to actually making it work.","markups":[]},{"name":"80f1","type":9,"text":"Developing alternative objectives for imitation learning or generative modeling. There has been a lot of recent progress in this area, and it is probably worth doing more conceptual work to see if we can find new frameworks.","markups":[]},{"name":"2492","type":9,"text":"Experimenting with “meeting halfway,” or with other practical approaches for producing imitable demonstrations.","markups":[]},{"name":"ff7c","type":3,"text":"Conclusion","markups":[]},{"name":"19d1","type":1,"text":"If we cannot solve the reward engineering problem in practice, it seems unlikely that we will be able to train robustly beneficial RL agents.","markups":[]},{"name":"7866","type":1,"text":"Conversely, if we can solve the reward engineering problem, then I believe that solution could be leveraged into an attack on the whole value alignment problem (along these lines — I will discuss this in more detail over my next few posts).","markups":[{"type":3,"start":167,"end":178,"href":"https://medium.com/ai-control/alba-an-explicit-proposal-for-aligned-ai-17a55f60bbcf","title":"","rel":"","anchorType":0}]},{"name":"66b4","type":1,"text":"Reward engineering is not only an important question for AI control, but also appears to be tractable today; there are both theoretical and experimental lines of attack. I’m optimistic that we will understand this problem much better over the coming years, and I think that will be very good news for AI control.","markups":[]},{"name":"b84c","type":1,"text":"(This research was supported as part of the Future of Life Institute FLI-RFP-AI1 program, grant #2015–143898.)","markups":[{"type":3,"start":44,"end":68,"href":"http://futureoflife.org","title":"","rel":"nofollow","anchorType":0},{"type":2,"start":0,"end":110}]}],"sections":[{"name":"9bd7","startIndex":0}]},"postDisplay":{"coverless":true}},"virtuals":{"statusForCollection":"APPROVED","allowNotes":true,"previewImage":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"wordCount":2128,"imageCount":0,"readingTime":8.030188679245283,"subtitle":"How can we define rewards which incentivize weak RL agents to behave in a desirable way?","publishedInCount":1,"usersBySocialRecommends":[],"noIndex":false,"recommends":22,"socialRecommends":[],"isBookmarked":false,"tags":[{"slug":"machine-learning","name":"Machine Learning","postCount":69725,"metadata":{"postCount":69725,"coverImage":{"id":"1*LzExc8ocuimzZdJTP58g7w.png","originalWidth":4800,"originalHeight":3000,"isFeatured":true}},"type":"Tag"},{"slug":"artificial-intelligence","name":"Artificial Intelligence","postCount":82761,"metadata":{"postCount":82761,"coverImage":{"id":"1*gAn_BSffVBcwCIR6bDgK1g.jpeg"}},"type":"Tag"}],"socialRecommendsCount":0,"responsesCreatedCount":0,"links":{"entries":[{"url":"https://medium.com/ai-control/alba-an-explicit-proposal-for-aligned-ai-17a55f60bbcf","alts":[{"type":2,"url":"medium://p/17a55f60bbcf"},{"type":3,"url":"medium://p/17a55f60bbcf"}]},{"url":"https://medium.com/ai-control/semi-supervised-reinforcement-learning-cf7d5375197f#.rm5dypm4a","alts":[{"type":2,"url":"medium://p/cf7d5375197f"},{"type":3,"url":"medium://p/cf7d5375197f"}]},{"url":"https://medium.com/ai-control/learn-policies-or-goals-348add76b8eb#.rvsv6syfl","alts":[{"type":2,"url":"medium://p/348add76b8eb"},{"type":3,"url":"medium://p/348add76b8eb"}]},{"url":"https://medium.com/ai-control/learning-with-catastrophes-59387b55cc30#.vctnbxafg","alts":[{"type":3,"url":"medium://p/59387b55cc30"},{"type":2,"url":"medium://p/59387b55cc30"}]},{"url":"https://medium.com/ai-control/adequate-oversight-25fadf1edce9#.1aj4sfjiu","alts":[{"type":2,"url":"medium://p/25fadf1edce9"},{"type":3,"url":"medium://p/25fadf1edce9"}]},{"url":"https://medium.com/ai-control/optimizing-with-comparisons-c02b8c0d7877#.jx6i2cxxu","alts":[{"type":2,"url":"medium://p/c02b8c0d7877"},{"type":3,"url":"medium://p/c02b8c0d7877"}]},{"url":"https://medium.com/ai-control/mimicry-maximization-and-meeting-halfway-c149dd23fc17#.l513cw5l0","alts":[{"type":2,"url":"medium://p/c149dd23fc17"},{"type":3,"url":"medium://p/c149dd23fc17"}]},{"url":"https://medium.com/@paulfchristiano/30285c779450","alts":[{"type":3,"url":"medium://p/30285c779450"},{"type":2,"url":"medium://p/30285c779450"}]}],"version":"0.3","generatedAt":1476379166674},"isLockedPreviewOnly":false,"metaDescription":"","totalClapCount":121,"sectionCount":1,"readingList":0,"topics":[]},"coverless":true,"slug":"the-reward-engineering-problem","translationSourcePostId":"","translationSourceCreatorId":"","isApprovedTranslation":false,"inResponseToPostId":"","inResponseToRemovedAt":0,"isTitleSynthesized":false,"allowResponses":true,"importedUrl":"","importedPublishedAt":0,"visibility":0,"uniqueSlug":"the-reward-engineering-problem-30285c779450","previewContent":{"bodyModel":{"paragraphs":[{"name":"previewTitle","type":3,"text":"The reward engineering problem","alignment":1},{"name":"previewSubtitle","type":13,"text":"How can we define rewards which incentivize weak RL agents to behave in a desirable way?","alignment":1},{"name":"previewSnippet0","type":1,"text":"Today we usually train reinforcement learning agents to perform narrow tasks with simple goals. We may…","alignment":1}],"sections":[{"startIndex":0}]},"isFullContent":false,"subtitle":"How can we define rewards which incentivize weak RL agents to behave in a desirable way?"},"license":0,"inResponseToMediaResourceId":"","canonicalUrl":"https://ai-alignment.com/the-reward-engineering-problem-30285c779450","approvedHomeCollectionId":"624d886c4aa4","approvedHomeCollection":{"id":"624d886c4aa4","name":"AI Alignment","slug":"ai-control","tags":[],"creatorId":"57f1a655a613","description":"Aligning AI systems with human interests.","shortDescription":"Aligning AI systems with human interests.","image":{"imageId":"1*N56Qc5-aHTcfGff0scntKQ.png","filter":"","backgroundSize":"","originalWidth":512,"originalHeight":512,"strategy":"resample","height":0,"width":0},"metadata":{"followerCount":2834,"activeAt":1548040822588},"virtuals":{"permissions":{"canPublish":false,"canPublishAll":false,"canRepublish":false,"canRemove":false,"canManageAll":false,"canSubmit":false,"canEditPosts":false,"canAddWriters":false,"canViewStats":false,"canSendNewsletter":false,"canViewLockedPosts":false,"canViewCloaked":false,"canEditOwnPosts":false,"canBeAssignedAuthor":false,"canEnrollInHightower":false,"canLockPostsForMediumMembers":false,"canLockOwnPostsForMediumMembers":false},"isSubscribed":false,"isNewsletterSubscribed":false,"isEnrolledInHightower":false,"isEligibleForHightower":false},"logo":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"collectionMastheadId":"29f3dcc2e4","domain":"ai-alignment.com","sections":[{"type":2,"collectionHeaderMetadata":{"title":"AI Alignment","backgroundImage":{},"logoImage":{},"alignment":2,"layout":4}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":3,"postIds":["157debfd1616","b49ad992940b","b959644d79c2"]}},{"type":1,"postListMetadata":{"source":1,"layout":4,"number":24,"postIds":[],"sectionHeader":"Latest"}}],"favicon":{"imageId":"1*cciPf4CUXd_Zyux0Jg0yBQ.png","filter":"","backgroundSize":"","originalWidth":400,"originalHeight":400,"strategy":"resample","height":0,"width":0},"colorPalette":{"defaultBackgroundSpectrum":{"colorPoints":[{"color":"#FF02B875","point":0},{"color":"#FF00AB6B","point":0.1},{"color":"#FF1C9963","point":0.2},{"color":"#FF092E20","point":1}],"backgroundColor":"#FFFFFFFF"},"highlightSpectrum":{"colorPoints":[{"color":"#FFFFFFFF","point":0},{"color":"#FFE9FDF0","point":0.1},{"color":"#FFE2FAEE","point":0.2},{"color":"#FFADFFCF","point":0.6},{"color":"#FF7DFFB3","point":1}],"backgroundColor":"#FFFFFFFF"}},"navItems":[],"colorBehavior":1,"instantArticlesState":0,"acceleratedMobilePagesState":0,"ampLogo":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"header":{"title":"AI Alignment","backgroundImage":{},"logoImage":{},"alignment":2,"layout":4},"paidForDomainAt":1490733089988,"type":"Collection"},"newsletterId":"","webCanonicalUrl":"https://ai-alignment.com/the-reward-engineering-problem-30285c779450","mediumUrl":"https://ai-alignment.com/the-reward-engineering-problem-30285c779450","migrationId":"","notifyFollowers":true,"notifyTwitter":false,"notifyFacebook":false,"responseHiddenOnParentPostAt":0,"isSeries":false,"isSubscriptionLocked":false,"seriesLastAppendedAt":0,"audioVersionDurationSec":0,"sequenceId":"","isNsfw":false,"isEligibleForRevenue":false,"isBlockedFromHightower":false,"deletedAt":0,"lockedPostSource":0,"hightowerMinimumGuaranteeStartsAt":0,"hightowerMinimumGuaranteeEndsAt":0,"featureLockRequestAcceptedAt":0,"mongerRequestType":1,"layerCake":0,"socialTitle":"","socialDek":"","editorialPreviewTitle":"","editorialPreviewDek":"","curationEligibleAt":0,"type":"Post"},"mentionedUsers":[],"collaborators":[],"hideMeter":false,"collectionUserRelations":[],"mode":null,"references":{"User":{"57f1a655a613":{"userId":"57f1a655a613","name":"Paul Christiano","username":"paulfchristiano","createdAt":1417286353352,"imageId":"1*BNjZCuQuRfIgcXCBMipuBw.jpeg","backgroundImageId":"","bio":"OpenAI","twitterScreenName":"","socialStats":{"userId":"57f1a655a613","usersFollowedCount":93,"usersFollowedByCount":821,"type":"SocialStats"},"social":{"userId":"lo_JuU2p2EvGepj","targetUserId":"57f1a655a613","type":"Social"},"facebookAccountId":"1167284919","allowNotes":1,"mediumMemberAt":0,"isNsfw":false,"isWriterProgramEnrolled":true,"isQuarantined":false,"type":"User"}},"Collection":{"624d886c4aa4":{"id":"624d886c4aa4","name":"AI Alignment","slug":"ai-control","tags":[],"creatorId":"57f1a655a613","description":"Aligning AI systems with human interests.","shortDescription":"Aligning AI systems with human interests.","image":{"imageId":"1*N56Qc5-aHTcfGff0scntKQ.png","filter":"","backgroundSize":"","originalWidth":512,"originalHeight":512,"strategy":"resample","height":0,"width":0},"metadata":{"followerCount":2834,"activeAt":1548040822588},"virtuals":{"permissions":{"canPublish":false,"canPublishAll":false,"canRepublish":false,"canRemove":false,"canManageAll":false,"canSubmit":false,"canEditPosts":false,"canAddWriters":false,"canViewStats":false,"canSendNewsletter":false,"canViewLockedPosts":false,"canViewCloaked":false,"canEditOwnPosts":false,"canBeAssignedAuthor":false,"canEnrollInHightower":false,"canLockPostsForMediumMembers":false,"canLockOwnPostsForMediumMembers":false},"isSubscribed":false,"isNewsletterSubscribed":false,"isEnrolledInHightower":false,"isEligibleForHightower":false},"logo":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"collectionMastheadId":"29f3dcc2e4","domain":"ai-alignment.com","sections":[{"type":2,"collectionHeaderMetadata":{"title":"AI Alignment","backgroundImage":{},"logoImage":{},"alignment":2,"layout":4}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":3,"postIds":["157debfd1616","b49ad992940b","b959644d79c2"]}},{"type":1,"postListMetadata":{"source":1,"layout":4,"number":24,"postIds":[],"sectionHeader":"Latest"}}],"favicon":{"imageId":"1*cciPf4CUXd_Zyux0Jg0yBQ.png","filter":"","backgroundSize":"","originalWidth":400,"originalHeight":400,"strategy":"resample","height":0,"width":0},"colorPalette":{"defaultBackgroundSpectrum":{"colorPoints":[{"color":"#FF02B875","point":0},{"color":"#FF00AB6B","point":0.1},{"color":"#FF1C9963","point":0.2},{"color":"#FF092E20","point":1}],"backgroundColor":"#FFFFFFFF"},"highlightSpectrum":{"colorPoints":[{"color":"#FFFFFFFF","point":0},{"color":"#FFE9FDF0","point":0.1},{"color":"#FFE2FAEE","point":0.2},{"color":"#FFADFFCF","point":0.6},{"color":"#FF7DFFB3","point":1}],"backgroundColor":"#FFFFFFFF"}},"navItems":[],"colorBehavior":1,"instantArticlesState":0,"acceleratedMobilePagesState":0,"ampLogo":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"header":{"title":"AI Alignment","backgroundImage":{},"logoImage":{},"alignment":2,"layout":4},"paidForDomainAt":1490733089988,"type":"Collection"}},"Social":{"57f1a655a613":{"userId":"lo_JuU2p2EvGepj","targetUserId":"57f1a655a613","type":"Social"}},"SocialStats":{"57f1a655a613":{"userId":"57f1a655a613","usersFollowedCount":93,"usersFollowedByCount":821,"type":"SocialStats"}}}})
// ]]></script><script id="parsely-cfg" src="//d1z2jf7jlzjs58.cloudfront.net/keys/medium.com/p.js"></script><script type="text/javascript">(function(b,r,a,n,c,h,_,s,d,k){if(!b[n]||!b[n]._q){for(;s<_.length;)c(h,_[s++]);d=r.createElement(a);d.async=1;d.src="https://cdn.branch.io/branch-latest.min.js";k=r.getElementsByTagName(a)[0];k.parentNode.insertBefore(d,k);b[n]=h}})(window,document,"script","branch",function(b,r){b[r]=function(){b._q.push([r,arguments])}},{_q:[],_v:1},"addListener applyCode autoAppIndex banner closeBanner closeJourney creditHistory credits data deepview deepviewCta first getCode init link logout redeem referrals removeListener sendSMS setBranchViewData setIdentity track validateCode trackCommerceEvent logEvent".split(" "), 0); branch.init('key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm', {'no_journeys': true, 'disable_exit_animation': true, 'disable_entry_animation': true, 'tracking_disabled':  false }, function(err, data) {});</script><div class="surface-scrollOverlay"></div><script charset="UTF-8" src="https://cdn-static-1.medium.com/_/fp/gen-js/main-common-async.bundle.qFZkgzLZ5TYXIerh_w9awQ.js"></script><script charset="UTF-8" src="https://cdn-static-1.medium.com/_/fp/gen-js/main-notes.bundle.V05mXLtyLz2Mj5DzEML26A.js"></script></body></html>